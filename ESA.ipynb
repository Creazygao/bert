{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuzhiHan/lol/blob/master/ESA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDx5W1qfreZ9"
      },
      "source": [
        "# 一、概述：多特征融合的中文隐式情感分析实验\n",
        "  实验共分为六组，15个实验模型：\n",
        "\n",
        "\n",
        "\n",
        "1.   第一组实验，共4个。评估预训练语言模型在隐式情感数据上的处理能力（ernie-gram,ernie-tiny,bert-zh-12-768-12，chinese-robert-wwm-ext，作为基准模型）\n",
        "\n",
        "2.   第二组实验，共2个。分别评估RNN、CNN对隐式情感数据的处理能力，对照组为基准模型。\n",
        "\n",
        "3.   第三组实验，共3个。分别测试RNN+上下文、CNN+上下文的处理效果，RNN+CNN+上下文的处理效果，对照组为第二组实验。\n",
        "4.   第四组实验，共2。共分别测试RNN+attention+CNN+上下文，RNN+attention+CNN+attention+上下文效果，对照组为不加attention实验\n",
        "5.   第五组实验，共2个。测试多路卷积网络对特征融合的效果，分别测试多特征+CNN,和多特征+全连接的方式，组内对照\n",
        "6.   第六组实验，共2个。测试bert参数可训练模型与本模型的对比。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udcq7UP1FEs2"
      },
      "source": [
        "##1.1安装tensoflow2.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfpFbGd-FCPX",
        "outputId": "b7c11e20-e1ba-4fd3-da98-13a93bf8340f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (13.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.14.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.44.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.21.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.24.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.2.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.1\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot) (3.0.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow_hub\n",
        "!pip install tensorflow_text\n",
        "!pip install tensorflow_addons\n",
        "!pip install matplotlib\n",
        "!pip install pydot\n",
        "!pip install pandas\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2加载谷歌硬盘"
      ],
      "metadata": {
        "id": "pccyLIhbx6Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmw4qgPox_HR",
        "outputId": "3c5c9e73-1d62-448c-de9e-f9e54027c7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6XnPJ2QxzL6"
      },
      "source": [
        "# 二、第一组实验--评估预训练语言模型\n",
        "评估ernie,bet,robert,robert-wwm对隐式情感分析数据集的处理能力\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwIL-orryQ6Y"
      },
      "source": [
        "## 2.1  ERNIE-Gram微调_0.8180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jzEx7rYzm7i"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle-gpu\n",
        "!pip install paddlenlp\n",
        "!pip install paddlehub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEtGsVy58wwI"
      },
      "source": [
        "###2.1.1数据处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_FEKTPL3-nR"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "从原始xml文件生成ERNIE-Gram所需的实验数据格式\n",
        "'''\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_xml(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        xml_data = f.read()\n",
        "    # 读取目标句和标签\n",
        "    labeled_data = re.findall('<Sentence ID=\"\\d+\" label=\"(\\d)\">(.*?)</Sentence>', xml_data)\n",
        "    text = []\n",
        "    labels = []\n",
        "    for tempdata in labeled_data:\n",
        "        if (data_clean(tempdata[1]) != ''):\n",
        "            text.append(data_clean(tempdata[1]))\n",
        "            labels.append(int(tempdata[0]))\n",
        "\n",
        "    content = []\n",
        "    # 读取上下文句,一个上下文句包含多个目标句\n",
        "    for index in re.findall('<Doc ID=\"\\d+\">(.*?)</Doc>', xml_data.replace('\\n', '')):\n",
        "        temp_str = ''\n",
        "        count = 0\n",
        "        for num, temp_data in re.findall(r'<Sentence ID=\"\\d+\"[ label=\"]*(\\d)*[\"]*>(.*?)</Sentence>', index):\n",
        "            # 提取出所有句子\n",
        "            if (num != '' and data_clean(temp_data) == ''):\n",
        "                count = count + 1\n",
        "            temp_data = data_clean(temp_data)\n",
        "            temp_str = temp_str + temp_data + '\\t'\n",
        "        times = str(index).count('label=\"1\"') + str(index).count('label=\"2\"') + str(index).count('label=\"0\"') - count\n",
        "        # 为每个目标句，分配一个上下文句\n",
        "        for i in range(0, times):\n",
        "            content.append(temp_str)\n",
        "    print(len(content))\n",
        "    return text, labels, content\n",
        "\n",
        "\n",
        "def data_clean(text_for_clean):\n",
        "   \n",
        "\n",
        "    res_text = re.sub(r\"(\\\\\\\\)?(回复)?(/)?\\s*@\\S*?\\s*:\", \"@ \", text_for_clean)\n",
        "    res_text1 = re.sub(r\"@\\S*\", \"@\", res_text)\n",
        "    res_text2 = re.sub(r\"http://+[\\w.\\\\\\\\]*\", '', res_text1)\n",
        "    res_text3 = re.sub(r\"http:\\\\+[\\w.\\\\\\\\]*\", '', res_text2)\n",
        "    res_text4 = re.sub(r\"[\\s/\\\\\\\\]\", '', res_text3)\n",
        "    return res_text4\n",
        "\n",
        "\n",
        "def get_data(filename):\n",
        "   \n",
        "    temp_text, temp_labels, temp_content = read_xml(filename)\n",
        "    # temp_text = [data_clean(each) for each in temp_text]\n",
        "    # temp_content = [data_clean(each) for each in temp_content]\n",
        "    return temp_text, temp_labels, temp_content\n",
        "\n",
        "\n",
        "def save_data(datadir, save_path):\n",
        "  \n",
        "    temp_text, temp_labels, temp_content = get_data(datadir)\n",
        "    data_final = pd.concat([pd.DataFrame(temp_text), pd.DataFrame(temp_labels)], axis=1)\n",
        "    data_final.to_csv(save_path,  mode=\"w\", header=['text', 'label'], index=False,index_label='index',sep='\\t')\n",
        "    return 0\n",
        "\n",
        "\n",
        "def save_dev_test(datadir, save_path1, save_path2):\n",
        "    \n",
        "    temp_text, temp_labels, temp_content = get_data(datadir)\n",
        "    num = len(temp_text) // 2\n",
        "    dev_data = temp_text[0:num]\n",
        "    dev_label = temp_labels[0:num]\n",
        "    test_data = temp_text[num + 1:]\n",
        "    test_label = temp_labels[num + 1:]\n",
        "    dev_final = pd.concat([pd.DataFrame(dev_data), pd.DataFrame(dev_label)], axis=1)\n",
        "    test_final = pd.concat([pd.DataFrame(test_data), pd.DataFrame(test_label)], axis=1)\n",
        "    dev_final.to_csv(save_path1,  header=['text', 'label'], index=False, index_label='index', mode=\"w\",sep='\\t')\n",
        "    test_final.to_csv(save_path2, header=['text', 'label'], index=False, index_label='index',mode=\"w\",sep='\\t')\n",
        "    return 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    save_data('/content/drive/MyDrive/ESA/raw_data/SMP2019_ECISA_Train.xml', '/content/drive/MyDrive/ESA/cleaned_data/train.csv')\n",
        "\n",
        "    save_dev_test('/content/drive/MyDrive/ESA/raw_data/SMP2019_ECISA_Dev.xml', '/content/drive/MyDrive/ESA/cleaned_data/dev.csv',\n",
        "                  '/content/drive/MyDrive/ESA/cleaned_data/test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAGG-Qwv85pk"
      },
      "source": [
        "###2.1.2ERNIE-Gram微调"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7C3P7OMysMK"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "ERNIE-Gram微调处理隐式情感分析任务：\n",
        "eval loss: 0.47137, accu: 0.81797\n",
        "'''\n",
        "import paddle\n",
        "import paddle.nn.functional as F\n",
        "from functools import partial\n",
        "from paddlenlp.data import Stack, Tuple, Pad\n",
        "import numpy as np\n",
        "from paddlenlp.datasets import load_dataset\n",
        "from paddlenlp.transformers import  ErnieGramTokenizer,  ErnieGramForSequenceClassification\n",
        "from paddlenlp.transformers import LinearDecayWithWarmup\n",
        "from paddlenlp.data import Stack, Tuple, Pad\n",
        "import paddle.nn as nn\n",
        "from paddlenlp.transformers import ErnieGramTokenizer, ErnieGramForSequenceClassification\n",
        "\n",
        "def predict(model, data, tokenizer, label_map, batch_size=1):\n",
        "    examples = []\n",
        "    for text in data:\n",
        "        input_ids, segment_ids = convert_example(\n",
        "            text,\n",
        "            tokenizer,\n",
        "            max_seq_length=128,\n",
        "            is_test=True)\n",
        "        examples.append((input_ids, segment_ids))\n",
        "\n",
        "    batchify_fn = lambda samples, fn=Tuple(\n",
        "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input id\n",
        "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # segment id\n",
        "    ): fn(samples)\n",
        "\n",
        "    # Seperates data into some batches.\n",
        "    batches = []\n",
        "    one_batch = []\n",
        "    for example in examples:\n",
        "        one_batch.append(example)\n",
        "        if len(one_batch) == batch_size:\n",
        "            batches.append(one_batch)\n",
        "            one_batch = []\n",
        "    if one_batch:\n",
        "        # The last batch whose size is less than the config batch_size setting.\n",
        "        batches.append(one_batch)\n",
        "\n",
        "    results = []\n",
        "    model.eval()\n",
        "    for batch in batches:\n",
        "        input_ids, segment_ids = batchify_fn(batch)\n",
        "        input_ids = paddle.to_tensor(input_ids)\n",
        "        segment_ids = paddle.to_tensor(segment_ids)\n",
        "        logits = model(input_ids, segment_ids)\n",
        "        probs = F.softmax(logits, axis=1)\n",
        "        idx = paddle.argmax(probs, axis=1).numpy()\n",
        "        idx = idx.tolist()\n",
        "        labels = [label_map[i] for i in idx]\n",
        "        results.extend(labels)\n",
        "    return results\n",
        "\n",
        "\n",
        "@paddle.no_grad()\n",
        "def evaluate(model, criterion, metric, data_loader):\n",
        "    model.eval()\n",
        "    metric.reset()\n",
        "    losses = []\n",
        "    for batch in data_loader:\n",
        "        input_ids, token_type_ids, labels = batch\n",
        "        logits = model(input_ids, token_type_ids)\n",
        "        loss = criterion(logits, labels)\n",
        "        losses.append(loss.numpy())\n",
        "        correct = metric.compute(logits, labels)\n",
        "        metric.update(correct)\n",
        "        accu = metric.accumulate()\n",
        "    print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))\n",
        "    model.train()\n",
        "    metric.reset()\n",
        "\n",
        "\n",
        "def convert_example(example, tokenizer, max_seq_length=128, is_test=False):\n",
        "    encoded_inputs = tokenizer(text=example[\"text\"], max_seq_len=max_seq_length)\n",
        "    input_ids = encoded_inputs[\"input_ids\"]\n",
        "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
        "\n",
        "    if not is_test:\n",
        "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
        "        return input_ids, token_type_ids, label\n",
        "    else:\n",
        "        return input_ids, token_type_ids\n",
        "\n",
        "\n",
        "def create_dataloader(dataset,\n",
        "                      mode='train',\n",
        "                      batch_size=32,\n",
        "                      batchify_fn=None,\n",
        "                      trans_fn=None):\n",
        "    if trans_fn:\n",
        "        dataset = dataset.map(trans_fn)\n",
        "\n",
        "    shuffle = True if mode == 'train' else False\n",
        "    if mode == 'train':\n",
        "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
        "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "    else:\n",
        "        batch_sampler = paddle.io.BatchSampler(\n",
        "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "    return paddle.io.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_sampler=batch_sampler,\n",
        "        collate_fn=batchify_fn,\n",
        "        return_list=True)\n",
        "\n",
        "\n",
        "class mymodel(ErnieGramForSequenceClassification):\n",
        "\n",
        "    def __init__(self, ernie_gram, num_classes=3, dropout=None):\n",
        "        super(mymodel, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.ernie_gram = ernie_gram  # allow ernie gram to be config\n",
        "        self.dropout = nn.Dropout(dropout if dropout is not None else\n",
        "                                  self.ernie_gram.config[\"hidden_dropout_prob\"])\n",
        "        self.classifier = nn.Linear(self.ernie_gram.config[\"hidden_size\"],\n",
        "                                    num_classes)\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids,\n",
        "                token_type_ids=None,\n",
        "                position_ids=None,\n",
        "                attention_mask=None):\n",
        "        _, pooled_output = self.ernie_gram(\n",
        "            input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            attention_mask=attention_mask)\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "def read(data_path):\n",
        "    with open(data_path, 'r', encoding='utf-8') as f:\n",
        "        next(f)\n",
        "        for line in f:\n",
        "            words, labels = line.strip('\\n').split('\\t')\n",
        "            yield {'text': words, 'label': labels}\n",
        "\n",
        "\n",
        "train_ds = load_dataset(read, data_path='/content/drive/MyDrive/ESA/cleaned_data/train.csv', lazy=False)\n",
        "dev_ds = load_dataset(read, data_path='/content/drive/MyDrive/ESA/cleaned_data/dev.csv', lazy=False)\n",
        "test_ds = load_dataset(read, data_path='/content/drive/MyDrive/ESA/cleaned_data/test.csv', lazy=False)\n",
        "print(len(train_ds))\n",
        "\n",
        "tokenizer = ErnieGramTokenizer.from_pretrained('ernie-gram-zh')\n",
        "model = ErnieGramForSequenceClassification.from_pretrained('ernie-gram-zh', num_classes=3)\n",
        "# 模型运行批处理大小\n",
        "batch_size = 64\n",
        "max_seq_length = 32\n",
        "\n",
        "trans_func = partial(\n",
        "    convert_example,\n",
        "    tokenizer=tokenizer,\n",
        "    max_seq_length=max_seq_length)\n",
        "batchify_fn = lambda samples, fn=Tuple(\n",
        "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
        "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
        "    Stack(dtype=\"int64\")  # label\n",
        "): [data for data in fn(samples)]\n",
        "train_data_loader = create_dataloader(\n",
        "    dataset=train_ds.map(trans_func),\n",
        "    mode='train',\n",
        "    batch_size=batch_size,\n",
        "    batchify_fn=batchify_fn,\n",
        ")\n",
        "dev_data_loader = create_dataloader(\n",
        "    dataset=dev_ds.map(trans_func),\n",
        "    mode='dev',\n",
        "    batch_size=batch_size,\n",
        "    batchify_fn=batchify_fn,\n",
        ")\n",
        "test_data_loader = create_dataloader(\n",
        "    dataset=test_ds.map(trans_func),\n",
        "    mode='test',\n",
        "    batch_size=batch_size,\n",
        "    batchify_fn=batchify_fn,\n",
        ")\n",
        "# 训练过程中的最大学习率\n",
        "learning_rate = 5e-5\n",
        "# 训练轮次\n",
        "epochs = 3\n",
        "# 学习率预热比例\n",
        "warmup_proportion = 0.1\n",
        "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\n",
        "weight_decay = 0.01\n",
        "\n",
        "num_training_steps = len(train_data_loader) * epochs\n",
        "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\n",
        "optimizer = paddle.optimizer.AdamW(\n",
        "    learning_rate=lr_scheduler,\n",
        "    parameters=model.parameters(),\n",
        "    weight_decay=weight_decay,\n",
        "    apply_decay_param_fun=lambda x: x in [\n",
        "        p.name for n, p in model.named_parameters()\n",
        "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
        "    ])\n",
        "\n",
        "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
        "metric = paddle.metric.Accuracy()\n",
        "global_step = 0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    for step, batch in enumerate(train_data_loader, start=1):\n",
        "        input_ids, segment_ids, labels = batch\n",
        "        logits = model(input_ids, segment_ids)\n",
        "        loss = criterion(logits, labels)\n",
        "        probs = F.softmax(logits, axis=1)\n",
        "        correct = metric.compute(probs, labels)\n",
        "        metric.update(correct)\n",
        "        acc = metric.accumulate()\n",
        "\n",
        "        global_step += 1\n",
        "        if global_step % 10 == 0:\n",
        "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f\" % (global_step, epoch, step, loss, acc))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.clear_grad()\n",
        "    evaluate(model, criterion, metric, dev_data_loader)\n",
        "evaluate(model, criterion, metric, test_data_loader)\n",
        "model.save_pretrained('/content/drive/MyDrive/ESA/checkpoint/ERNIE-Gram')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/ESA/checkpoint/ERNIE-Gram')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LymA6fO64ohS"
      },
      "source": [
        "## 2.2 ERNIE-Tiny微调_0.8102"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuzkEMUb5l8i"
      },
      "outputs": [],
      "source": [
        "!pip install jieba\n",
        "!pip install paddlepaddle-gpu\n",
        "!pip install paddlenlp\n",
        "!pip install paddlehub\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiuESUvu9E3O"
      },
      "source": [
        "###2.2.1数据处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP3MrGGh4zL_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "从原始xml文件生成ERNIE-Tiny所需的数据\n",
        "'''\n",
        "import re\n",
        "import pandas as pd\n",
        "import jieba\n",
        "\n",
        "def read_xml(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        xml_data = f.read()\n",
        "    # 读取目标句和标签\n",
        "    labeled_data = re.findall('<Sentence ID=\"\\d+\" label=\"(\\d)\">(.*?)</Sentence>', xml_data)\n",
        "    text = []\n",
        "    labels = []\n",
        "    for tempdata in labeled_data:\n",
        "        if (data_clean(tempdata[1]) != ''):\n",
        "            text.append(data_clean(tempdata[1]))\n",
        "            labels.append(int(tempdata[0]))\n",
        "\n",
        "    content = []\n",
        "    # 读取上下文句,一个上下文句包含多个目标句\n",
        "    for index in re.findall('<Doc ID=\"\\d+\">(.*?)</Doc>', xml_data.replace('\\n', '')):\n",
        "        temp_str = ''\n",
        "        count = 0\n",
        "        for num, temp_data in re.findall(r'<Sentence ID=\"\\d+\"[ label=\"]*(\\d)*[\"]*>(.*?)</Sentence>', index):\n",
        "            # 提取出所有句子\n",
        "            if (num != '' and data_clean(temp_data) == ''):\n",
        "                count = count + 1\n",
        "            temp_data = data_clean(temp_data)\n",
        "            temp_str = temp_str + temp_data + '\\t'\n",
        "        times = str(index).count('label=\"1\"') + str(index).count('label=\"2\"') + str(index).count('label=\"0\"') - count\n",
        "        # 为每个目标句，分配一个上下文句\n",
        "        for i in range(0, times):\n",
        "            content.append(temp_str)\n",
        "    \n",
        "    return text, labels, content\n",
        "\n",
        "\n",
        "def data_clean(text_for_clean):\n",
        "    res_text = re.sub(r\"(\\\\\\\\)?(回复)?(/)?\\s*@\\S*?\\s*:\", \"@ \", text_for_clean)\n",
        "    res_text1 = re.sub(r\"@\\S*\", \"@\", res_text)\n",
        "    res_text2 = re.sub(r\"http://+[\\w.\\\\\\\\]*\", '', res_text1)\n",
        "    res_text3 = re.sub(r\"http:\\\\+[\\w.\\\\\\\\]*\", '', res_text2)\n",
        "    res_text4 = re.sub(r\"[/\\\\\\\\]\", '', res_text3)\n",
        "    re_data=jieba.cut(res_text4,cut_all=False)\n",
        "    f_data=\" \".join(re_data)\n",
        "    return f_data\n",
        "\n",
        "\n",
        "def get_data(filename):\n",
        "\n",
        "    temp_text, temp_labels, temp_content = read_xml(filename)\n",
        "    # temp_text = [data_clean(each) for each in temp_text]\n",
        "    # temp_content = [data_clean(each) for each in temp_content]\n",
        "    return temp_text, temp_labels, temp_content\n",
        "\n",
        "\n",
        "def save_data(datadir, save_path):\n",
        "\n",
        "    temp_text, temp_labels, temp_content = get_data(datadir)\n",
        "    data_final = pd.concat([pd.DataFrame(temp_labels), pd.DataFrame(temp_text)], axis=1)\n",
        "    data_final.to_csv(save_path, sep='\\t', mode=\"w\", header=['text', 'label'], index=False)\n",
        "    return 0\n",
        "\n",
        "\n",
        "def save_dev_test(datadir, save_path1, save_path2):\n",
        "\n",
        "    temp_text, temp_labels, temp_content = get_data(datadir)\n",
        "    num = len(temp_text) // 2\n",
        "    dev_data = temp_text[0:num]\n",
        "    dev_label = temp_labels[0:num]\n",
        "    test_data = temp_text[num + 1:]\n",
        "    test_label = temp_labels[num + 1:]\n",
        "    dev_final = pd.concat([pd.DataFrame(dev_label), pd.DataFrame(dev_data)], axis=1)\n",
        "    test_final = pd.concat([pd.DataFrame(test_label), pd.DataFrame(test_data)], axis=1)\n",
        "    dev_final.to_csv(save_path1, sep='\\t', header=['text', 'label'], index=False, mode=\"w\")\n",
        "    test_final.to_csv(save_path2, sep='\\t', header=['text', 'label'], index=False, mode=\"w\")\n",
        "    return 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    save_data('/content/drive/MyDrive/ESA/raw_data/SMP2019_ECISA_Train.xml', '../data_set/text_label_train.csv')\n",
        "\n",
        "    save_dev_test('/content/drive/MyDrive/ESA/raw_data/SMP2019_ECISA_Dev.xml', '../data_set/text_label_dev.csv',\n",
        "                  '../data_set/text_label_test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-lj_-tu9Hn5"
      },
      "source": [
        "###2.2.2ERNIE-Tiny微调"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGEU7W6M60L5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "ERNIE-Tiny微调处理隐式情感分析任务：\n",
        "best_acc=0.8102\n",
        "'''\n",
        "import pandas as pd\n",
        "import paddle\n",
        "import paddlehub as hub\n",
        "import ast\n",
        "import argparse\n",
        "from paddlehub.datasets.base_nlp_dataset import TextClassificationDataset\n",
        "\n",
        "class MyDataset(TextClassificationDataset):\n",
        "    # 数据集存放目录\n",
        "    base_path = '/content/drive/MyDrive/ESA/cleaned_data'\n",
        "    # 数据集的标签列表，多分类标签格式为['0', '1', '2', '3',...]\n",
        "    label_list = ['0', '1', '2']\n",
        "\n",
        "    def __init__(self, tokenizer, max_seq_len: int = 64, mode: str = 'train'):\n",
        "        if mode == 'train':\n",
        "            data_file = 'text_label_train.tsv'\n",
        "        elif mode == 'test':\n",
        "            data_file = 'text_label_test.tsv'\n",
        "        else:\n",
        "            data_file = 'text_label_dev.tsv'\n",
        "        super().__init__(\n",
        "            base_path=self.base_path,\n",
        "            tokenizer=tokenizer,\n",
        "            max_seq_len=max_seq_len,\n",
        "            mode=mode,\n",
        "            data_file=data_file,\n",
        "            label_list=self.label_list,\n",
        "            is_file_with_header=True)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # 选择模型、任务和类别数\n",
        "    model = hub.Module(name='ernie_tiny', task='seq-cls', num_classes=len(MyDataset.label_list))\n",
        "\n",
        "    train_dataset = MyDataset(tokenizer=model.get_tokenizer(), max_seq_len=64, mode='train')\n",
        "    dev_dataset = MyDataset(tokenizer=model.get_tokenizer(), max_seq_len=64, mode='dev')\n",
        "    test_dataset = MyDataset(tokenizer=model.get_tokenizer(), max_seq_len=64, mode='test')\n",
        "\n",
        "    optimizer = paddle.optimizer.Adam(learning_rate=5e-5, parameters=model.parameters())\n",
        "    trainer = hub.Trainer(model, optimizer, checkpoint_dir='/content/drive/MyDrive/ESA/checkpoint/ERNIE-Tiny', use_gpu=True)\n",
        "    trainer.train(train_dataset, epochs=2, batch_size=64, eval_dataset=dev_dataset,save_interval=1)\n",
        "    # 在测试集上评估当前训练模型\n",
        "    trainer.evaluate(test_dataset, batch_size=64)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yx2OZV19vT0"
      },
      "source": [
        "##2.3 chinese-roberta-wwm-ext微调_0.8196"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smJZygF_-fJ4"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqyfO2ve-tC7"
      },
      "source": [
        "###2.3.1数据处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pSZMvYr-w6e"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_xml(filename):\n",
        "    with open(filename, 'r',encoding='utf-8') as f:\n",
        "        xml_data = f.read()\n",
        "    # 读取目标句和标签\n",
        "    labeled_data = re.findall('<Sentence ID=\"\\d+\" label=\"(\\d)\">(.*?)</Sentence>', xml_data)\n",
        "    text = []\n",
        "    labels = []\n",
        "    for tempdata in labeled_data:\n",
        "        if (data_clean(tempdata[1]) != ''):\n",
        "            text.append(data_clean(tempdata[1]))\n",
        "            labels.append(int(tempdata[0]))\n",
        "\n",
        "    content = []\n",
        "    # 读取上下文句,一个上下文句包含多个目标句\n",
        "    for index in re.findall('<Doc ID=\"\\d+\">(.*?)</Doc>', xml_data.replace('\\n', '')):\n",
        "        temp_str = ''\n",
        "        count = 0\n",
        "        for num, temp_data in re.findall(r'<Sentence ID=\"\\d+\"[ label=\"]*(\\d)*[\"]*>(.*?)</Sentence>', index):\n",
        "            # 提取出所有句子\n",
        "            if (num != '' and data_clean(temp_data) == ''):\n",
        "                count = count + 1\n",
        "            temp_data = data_clean(temp_data)\n",
        "            temp_str = temp_str + temp_data + '\\t'\n",
        "        times = str(index).count('label=\"1\"') + str(index).count('label=\"2\"') + str(index).count('label=\"0\"')-count\n",
        "        # 为每个目标句，分配一个上下文句\n",
        "        for i in range(0, times):\n",
        "            content.append(temp_str)\n",
        "    print(len(content))\n",
        "    return text, labels, content\n",
        "\n",
        "\n",
        "def data_clean(text_for_clean):\n",
        "\n",
        "    res_text = re.sub(r\"(\\\\\\\\)?(回复)?(/)?\\s*@\\S*?\\s*:\", \"@ \", text_for_clean)\n",
        "    res_text1 = re.sub(r\"@\\S*\", \"@\", res_text)\n",
        "    res_text2 = re.sub(r\"http://+[\\w.\\\\\\\\]*\", '', res_text1)\n",
        "    res_text3 = re.sub(r\"http:\\\\+[\\w.\\\\\\\\]*\", '', res_text2)\n",
        "    res_text4=re.sub(r\"[\\s/\\\\\\\\]\",'',res_text3)\n",
        "    return res_text4\n",
        "\n",
        "\n",
        "def get_data(filename):\n",
        "\n",
        "    temp_text, temp_labels, temp_content = read_xml(filename)\n",
        "    return temp_text, temp_labels, temp_content\n",
        "\n",
        "\n",
        "def save_cleaned_data(temp_text, temp_labels, temp_content, filepath):\n",
        "    data_final = pd.concat([pd.DataFrame(temp_text), pd.DataFrame(temp_labels), pd.DataFrame(temp_content)], axis=1)\n",
        "    data_final.to_csv(filepath, encoding='utf_8_sig', header=['text', 'label', 'content'], index=False)\n",
        "    return 0\n",
        "if __name__ == '__main__':\n",
        "    text, labels, content = get_data('/content/drive/MyDrive/ESA/raw_data/SMP2019_ECISA_Train.xml')\n",
        "    save_cleaned_data(text, labels, content, '/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv')\n",
        "    text2, labels2, content2 = get_data('/content/drive/MyDrive/ESA/raw_data/SMP2019_ECISA_Dev.xml')\n",
        "    save_cleaned_data(text2, labels2, content2, '/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-_QudAY_Knn"
      },
      "source": [
        "###2.3.2微调处理隐式情感分析任务"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLn4s7SV_QEw"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "loss: 0.4451 - accuracy: 0.8196\n",
        "'''\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, BertTokenizer\n",
        "import tensorflow as tf\n",
        "a=transformers.models.bert.tokenization_bert\n",
        "tokenizer = BertTokenizer.from_pretrained('hfl/chinese-roberta-wwm-ext')\n",
        "# 读取data.csv数据，并将第一列作为data,第二列作为label，数据总量14774作为训练集\n",
        "print(\"读取data.csv\")\n",
        "raw_train_data = load_dataset('csv', data_files='/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv', split='train')\n",
        "raw_test_data_set = load_dataset('csv', data_files='/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv', split='train')\n",
        "data_for_dev_test = raw_test_data_set.train_test_split(test_size=0.5, train_size=0.5)\n",
        "raw_dev_data = data_for_dev_test[\"train\"]\n",
        "raw_test_data = data_for_dev_test[\"test\"]\n",
        "max_length = 64\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], max_length=max_length, padding=\"max_length\", truncation=True,)\n",
        "\n",
        "\n",
        "def get_encode_data(raw_data):\n",
        "    tokenized_train_data = raw_data.map(tokenize_function, batched=True)\n",
        "    tf_train_dataset = tokenized_train_data.with_format(\"tensorflow\")\n",
        "    train_features = {x: tf_train_dataset[x] for x in tokenizer.model_input_names}\n",
        "    train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_train_dataset[\"label\"]))\n",
        "    encode_train_tf_dataset = train_tf_dataset.shuffle(len(train_tf_dataset)).batch(128)\n",
        "    return encode_train_tf_dataset\n",
        "\n",
        "\n",
        "encode_train_dataset = get_encode_data(raw_train_data)\n",
        "encode_dev_dataset = get_encode_data(raw_dev_data)\n",
        "encode_test_dataset = get_encode_data(raw_test_data)\n",
        "\n",
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "lr = 5e-5\n",
        "epoch = 2\n",
        "print(\"加载模型\")\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"hfl/chinese-roberta-wwm-ext\", num_labels=3)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr, epsilon=1e-08, clipnorm=1)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "acc = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n",
        "print(\"模型训练\")\n",
        "model.fit(encode_train_dataset, epochs=epoch, validation_data=encode_dev_dataset)\n",
        "print(\"模型评估\")\n",
        "model.evaluate(encode_test_dataset)\n",
        "model.save(\"/content/drive/MyDrive/ESA/checkpoint/wwm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwdlum6IBSoU"
      },
      "source": [
        "##2.4 bert_base_chinese微调_0.8145"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4M37MNr_E71a"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9YW48r8DkEO"
      },
      "source": [
        "###2.4.1 **数据处理**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hd6cMhV_q3p"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_xml(filename):\n",
        "    with open(filename, 'r',encoding='utf-8') as f:\n",
        "        xml_data = f.read()\n",
        "    # 读取目标句和标签\n",
        "    labeled_data = re.findall('<Sentence ID=\"\\d+\" label=\"(\\d)\">(.*?)</Sentence>', xml_data)\n",
        "    text = []\n",
        "    labels = []\n",
        "    for tempdata in labeled_data:\n",
        "        if (data_clean(tempdata[1]) != ''):\n",
        "            text.append(data_clean(tempdata[1]))\n",
        "            labels.append(int(tempdata[0]))\n",
        "\n",
        "    content = []\n",
        "    # 读取上下文句,一个上下文句包含多个目标句\n",
        "    for index in re.findall('<Doc ID=\"\\d+\">(.*?)</Doc>', xml_data.replace('\\n', '')):\n",
        "        temp_str = ''\n",
        "        count = 0\n",
        "        for num, temp_data in re.findall(r'<Sentence ID=\"\\d+\"[ label=\"]*(\\d)*[\"]*>(.*?)</Sentence>', index):\n",
        "            # 提取出所有句子\n",
        "            if (num != '' and data_clean(temp_data) == ''):\n",
        "                count = count + 1\n",
        "            temp_data = data_clean(temp_data)\n",
        "            temp_str = temp_str + temp_data + '\\t'\n",
        "        times = str(index).count('label=\"1\"') + str(index).count('label=\"2\"') + str(index).count('label=\"0\"')-count\n",
        "        # 为每个目标句，分配一个上下文句\n",
        "        for i in range(0, times):\n",
        "            content.append(temp_str)\n",
        "    print(len(content))\n",
        "    return text, labels, content\n",
        "\n",
        "\n",
        "def data_clean(text_for_clean):\n",
        "\n",
        "    res_text = re.sub(r\"(\\\\\\\\)?(回复)?(/)?\\s*@\\S*?\\s*:\", \"@ \", text_for_clean)\n",
        "    res_text1 = re.sub(r\"@\\S*\", \"@\", res_text)\n",
        "    res_text2 = re.sub(r\"http://+[\\w.\\\\\\\\]*\", '', res_text1)\n",
        "    res_text3 = re.sub(r\"http:\\\\+[\\w.\\\\\\\\]*\", '', res_text2)\n",
        "    res_text4=re.sub(r\"[\\s/\\\\\\\\]\",'',res_text3)\n",
        "    return res_text4\n",
        "\n",
        "\n",
        "def get_data(filename):\n",
        "\n",
        "    temp_text, temp_labels, temp_content = read_xml(filename)\n",
        "    return temp_text, temp_labels, temp_content\n",
        "\n",
        "\n",
        "def save_cleaned_data(temp_text, temp_labels, temp_content, filepath):\n",
        "    data_final = pd.concat([pd.DataFrame(temp_text), pd.DataFrame(temp_labels), pd.DataFrame(temp_content)], axis=1)\n",
        "    data_final.to_csv(filepath, encoding='utf_8_sig', header=['text', 'label', 'content'], index=False)\n",
        "    return 0\n",
        "if __name__ == '__main__':\n",
        "    text, labels, content = get_data('/content/drive/MyDrive/ESA/raw_data/SMP2019_ECISA_Train.xml')\n",
        "    save_cleaned_data(text, labels, content, '/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv')\n",
        "    text2, labels2, content2 = get_data('/content/drive/MyDrive/ESA/raw_data/SMP2019_ECISA_Dev.xml')\n",
        "    save_cleaned_data(text2, labels2, content2, '/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FejtOlXsDwYz"
      },
      "source": [
        "###2.4.2微调处理隐式情感分析任务"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479,
          "referenced_widgets": [
            "ab0c1c875ac04a78baea746b1e2d4755",
            "1c6031278adc40d4ae4e8e16726612c7",
            "90a32c5ad93f4e0e845aaa206c3f65f7",
            "6e16bfaa73e84144bc94cb7e408116eb",
            "3db3eaaeb54444a8889800bb39ec819b",
            "1c49e243efd841069a36c79d10776659",
            "f53bd07cdff34bce99b7345873d0edeb",
            "3ee54a0765604b4ebf289a3632a17090",
            "2e6f505c6d9d4ecfba31738c69c0cdc4",
            "4515af4050404a258934349d801845b2",
            "bcb17ac1848e4b769837240d03106a3a",
            "7deb4fb86d1d4e5b93eb9dd0b4df862b",
            "f2d671735ad74a3a97f1daf4f73bb3b2",
            "e3044c5d807b4e8396ae74333ad17792",
            "d50186dc76ad452abd847f0cfa145c83",
            "11123fe7aef146c9ba2971371b9e753e",
            "baa3e7c63c144bcf82889652a4d71e8e",
            "bf70920ed5b646d6a69c96d2a640ece0",
            "c60853807dc3476e9d70bb4c774144d7",
            "c5576a1ac8f54157ad9a6561df3142b3",
            "d450684eace14415baf24d51adb3117c",
            "8cbea263bdd64a31b6db57e8b5a56b33"
          ]
        },
        "id": "4PIo86kSD1VS",
        "outputId": "b3dfd57b-6fe0-445e-c5b3-e7efcee0c1b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "读取data.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-7da0a910dbf0bc66\n",
            "WARNING:datasets.builder:Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-7da0a910dbf0bc66/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
            "WARNING:datasets.builder:Using custom data configuration default-1d9970d956e8b265\n",
            "WARNING:datasets.builder:Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-1d9970d956e8b265/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-7da0a910dbf0bc66/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-aea830e9c7fbc88f.arrow\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab0c1c875ac04a78baea746b1e2d4755",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7deb4fb86d1d4e5b93eb9dd0b4df862b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "加载模型\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "模型训练\n",
            "Epoch 1/2\n",
            "231/231 [==============================] - 210s 822ms/step - loss: 0.5705 - accuracy: 0.7671 - val_loss: 0.4165 - val_accuracy: 0.8327\n",
            "Epoch 2/2\n",
            "231/231 [==============================] - 186s 807ms/step - loss: 0.3586 - accuracy: 0.8664 - val_loss: 0.4544 - val_accuracy: 0.8215\n",
            "模型评估\n",
            "41/41 [==============================] - 11s 259ms/step - loss: 0.5009 - accuracy: 0.8145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ESA/checkpoint/bert_base/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ESA/checkpoint/bert_base/assets\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "bert-base-chinese处理隐式情感分析：\n",
        "loss: 0.5009 - accuracy: 0.8145\n",
        "'''\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, BertTokenizer\n",
        "import tensorflow as tf\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "\n",
        "print(\"读取data.csv\")\n",
        "raw_train_data = load_dataset('csv', data_files='/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv', split='train')\n",
        "raw_test_data_set = load_dataset('csv', data_files='/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv', split='train')\n",
        "data_for_dev_test = raw_test_data_set.train_test_split(test_size=0.5, train_size=0.5)\n",
        "raw_dev_data = data_for_dev_test[\"train\"]\n",
        "raw_test_data = data_for_dev_test[\"test\"]\n",
        "max_length = 64\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], max_length=max_length, padding=\"max_length\", truncation=True)\n",
        "\n",
        "\n",
        "def get_encode_data(raw_data):\n",
        "    tokenized_train_data = raw_data.map(tokenize_function, batched=True)\n",
        "    tf_train_dataset = tokenized_train_data.with_format(\"tensorflow\")\n",
        "    train_features = {x: tf_train_dataset[x] for x in tokenizer.model_input_names}\n",
        "    train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_train_dataset[\"label\"]))\n",
        "    encode_train_tf_dataset = train_tf_dataset.shuffle(len(train_tf_dataset)).batch(64)\n",
        "    return encode_train_tf_dataset\n",
        "\n",
        "\n",
        "encode_train_dataset = get_encode_data(raw_train_data)\n",
        "encode_dev_dataset = get_encode_data(raw_dev_data)\n",
        "encode_test_dataset = get_encode_data(raw_test_data)\n",
        "\n",
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "lr = 5e-5\n",
        "epoch = 2\n",
        "print(\"加载模型\")\n",
        "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-chinese\", num_labels=3)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr, epsilon=1e-08, clipnorm=1)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "acc = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n",
        "print(\"模型训练\")\n",
        "model.fit(encode_train_dataset, epochs=epoch, validation_data=encode_dev_dataset)\n",
        "print(\"模型评估\")\n",
        "model.evaluate(encode_test_dataset)\n",
        "model.save(\"/content/drive/MyDrive/ESA/checkpoint/bert_base\")\n",
        "# model.evaluate(test_data_encode)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFX1Tsj0GHxG"
      },
      "source": [
        "#三、第二组实验-分别测试bert_embeddings接CNN、GRU效果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcgf3rLPGq5t"
      },
      "source": [
        "##3.1bert_embeddings+GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09t4TdkKZPy9"
      },
      "source": [
        "###3.1.1 GRU_32*32_512-256_0.7700"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RBWSMYiINGmM",
        "outputId": "4c07f9d4-f4b4-41c7-abce-707f1ff0aba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  102267649   ['model[0][0]',                  \n",
            "                                None, 768),                       'model[0][1]',                  \n",
            "                                 'sequence_output':               'model[0][2]']                  \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 32, 512)      1969152     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 256)          591360      ['gru[0][0]']                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 256)          0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            771         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 104,828,932\n",
            "Trainable params: 2,561,283\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "462/462 [==============================] - 86s 154ms/step - loss: 0.6968 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.5919 - val_sparse_categorical_accuracy: 0.7636\n",
            "Epoch 2/10\n",
            "462/462 [==============================] - 71s 154ms/step - loss: 0.5585 - sparse_categorical_accuracy: 0.7740 - val_loss: 0.5545 - val_sparse_categorical_accuracy: 0.7688\n",
            "Epoch 3/10\n",
            "462/462 [==============================] - 71s 153ms/step - loss: 0.5244 - sparse_categorical_accuracy: 0.7885 - val_loss: 0.5601 - val_sparse_categorical_accuracy: 0.7668\n",
            "Epoch 4/10\n",
            "462/462 [==============================] - 74s 161ms/step - loss: 0.4987 - sparse_categorical_accuracy: 0.7994 - val_loss: 0.5324 - val_sparse_categorical_accuracy: 0.7748\n",
            "Epoch 5/10\n",
            "462/462 [==============================] - 73s 158ms/step - loss: 0.4805 - sparse_categorical_accuracy: 0.8063 - val_loss: 0.5397 - val_sparse_categorical_accuracy: 0.7708\n",
            "Epoch 6/10\n",
            "462/462 [==============================] - 72s 155ms/step - loss: 0.4683 - sparse_categorical_accuracy: 0.8121 - val_loss: 0.5298 - val_sparse_categorical_accuracy: 0.7776\n",
            "Epoch 7/10\n",
            "462/462 [==============================] - 70s 152ms/step - loss: 0.4495 - sparse_categorical_accuracy: 0.8195 - val_loss: 0.5426 - val_sparse_categorical_accuracy: 0.7724\n",
            "Epoch 8/10\n",
            "462/462 [==============================] - 80s 173ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.5211 - val_sparse_categorical_accuracy: 0.7904\n",
            "Epoch 9/10\n",
            "462/462 [==============================] - 75s 161ms/step - loss: 0.4115 - sparse_categorical_accuracy: 0.8399 - val_loss: 0.5478 - val_sparse_categorical_accuracy: 0.7760\n",
            "Epoch 10/10\n",
            "462/462 [==============================] - 68s 147ms/step - loss: 0.3966 - sparse_categorical_accuracy: 0.8436 - val_loss: 0.5556 - val_sparse_categorical_accuracy: 0.7700\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  102267649   ['model[0][0]',                  \n",
            "                                None, 768),                       'model[0][1]',                  \n",
            "                                 'sequence_output':               'model[0][2]']                  \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 32, 512)      1969152     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 256)          591360      ['gru[0][0]']                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 256)          0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            771         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 104,828,932\n",
            "Trainable params: 2,561,283\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "'''\n",
        "loss: 0.5009 - accuracy: 0.8145\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net3 = outputs['sequence_output']\n",
        "    net3 = keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.GRU(256, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    net3=keras.layers.Flatten()(net3)\n",
        "    net3=keras.layers.Dropout(0.2)(net3)\n",
        "    net3=keras.layers.Dense(3,activation=\"softmax\")(net3)\n",
        "    return keras.Model(text_input,net3)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "plot_model(model,to_file=\"/content/drive/MyDrive/ESA/checkpoint/gru/model.png\",show_shapes=True)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "model_history = model.fit(x_train, y=y_train, epochs=10, batch_size=32,\n",
        "                          validation_data=(x_dev, y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback],shuffle=True)\n",
        "model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "model.evaluate(x=x_test,y=y_test)\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KbcUeh3uBdj"
      },
      "source": [
        "###3.1.2 GRU_64*32_512-256_0.7836"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zJ-rKgQxRDaW",
        "outputId": "24b9e213-b1d4-40b0-f8c1-ea22f51ba2f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_2 (Functional)           {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'encoder_outputs':  102267649   ['model_2[0][0]',                \n",
            "                                 [(None, 32, 768),                'model_2[0][1]',                \n",
            "                                 (None, 32, 768),                 'model_2[0][2]']                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768)}                                                 \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    (None, 32, 512)      1969152     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " gru_3 (GRU)                    (None, 256)          591360      ['gru_2[0][0]']                  \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 256)          0           ['gru_3[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 256)          0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 3)            771         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 104,828,932\n",
            "Trainable params: 2,561,283\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "231/231 [==============================] - 96s 371ms/step - loss: 0.7464 - sparse_categorical_accuracy: 0.6784 - val_loss: 0.6059 - val_sparse_categorical_accuracy: 0.7568\n",
            "Epoch 2/10\n",
            "231/231 [==============================] - 85s 368ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.7619 - val_loss: 0.5679 - val_sparse_categorical_accuracy: 0.7632\n",
            "Epoch 3/10\n",
            "231/231 [==============================] - 85s 367ms/step - loss: 0.5398 - sparse_categorical_accuracy: 0.7799 - val_loss: 0.5581 - val_sparse_categorical_accuracy: 0.7708\n",
            "Epoch 4/10\n",
            "231/231 [==============================] - 84s 363ms/step - loss: 0.5198 - sparse_categorical_accuracy: 0.7875 - val_loss: 0.5476 - val_sparse_categorical_accuracy: 0.7740\n",
            "Epoch 5/10\n",
            "231/231 [==============================] - 84s 362ms/step - loss: 0.4979 - sparse_categorical_accuracy: 0.7993 - val_loss: 0.5331 - val_sparse_categorical_accuracy: 0.7812\n",
            "Epoch 6/10\n",
            "231/231 [==============================] - 83s 359ms/step - loss: 0.4818 - sparse_categorical_accuracy: 0.8070 - val_loss: 0.5296 - val_sparse_categorical_accuracy: 0.7824\n",
            "Epoch 7/10\n",
            "231/231 [==============================] - 81s 352ms/step - loss: 0.4654 - sparse_categorical_accuracy: 0.8131 - val_loss: 0.5669 - val_sparse_categorical_accuracy: 0.7640\n",
            "Epoch 8/10\n",
            "231/231 [==============================] - 81s 350ms/step - loss: 0.4554 - sparse_categorical_accuracy: 0.8157 - val_loss: 0.5310 - val_sparse_categorical_accuracy: 0.7812\n",
            "Epoch 9/10\n",
            "231/231 [==============================] - 81s 349ms/step - loss: 0.4394 - sparse_categorical_accuracy: 0.8264 - val_loss: 0.5340 - val_sparse_categorical_accuracy: 0.7784\n",
            "Epoch 10/10\n",
            "231/231 [==============================] - 83s 360ms/step - loss: 0.4269 - sparse_categorical_accuracy: 0.8306 - val_loss: 0.5217 - val_sparse_categorical_accuracy: 0.7836\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_2 (Functional)           {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'encoder_outputs':  102267649   ['model_2[0][0]',                \n",
            "                                 [(None, 32, 768),                'model_2[0][1]',                \n",
            "                                 (None, 32, 768),                 'model_2[0][2]']                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768)}                                                 \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    (None, 32, 512)      1969152     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " gru_3 (GRU)                    (None, 256)          591360      ['gru_2[0][0]']                  \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 256)          0           ['gru_3[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 256)          0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 3)            771         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 104,828,932\n",
            "Trainable params: 2,561,283\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net3 = outputs['sequence_output']\n",
        "    net3 = keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.GRU(256, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    net3=keras.layers.Flatten()(net3)\n",
        "    net3=keras.layers.Dropout(0.2)(net3)\n",
        "    net3=keras.layers.Dense(3,activation=\"softmax\")(net3)\n",
        "    return keras.Model(text_input,net3)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "plot_model(model,to_file=\"/content/drive/MyDrive/ESA/checkpoint/gru2/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru2/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "model_history = model.fit(x_train, y=y_train, epochs=10, batch_size=64,\n",
        "                          validation_data=(x_dev, y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback],shuffle=True)\n",
        "model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "model.evaluate(x=x_test,y=y_test)\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyqUf3kCvDx3"
      },
      "source": [
        "###3.1.3 GRU_64*32_768_0.7836"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-mJ6vMUNvLez",
        "outputId": "8b703d56-f4e4-46f2-af43-5336cce657e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_2 (Functional)           {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  102267649   ['model_2[0][0]',                \n",
            "                                None, 768),                       'model_2[0][1]',                \n",
            "                                 'sequence_output':               'model_2[0][2]']                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)]}                                                \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    (None, 768)          3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 768)          0           ['gru_2[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 768)          0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 3)            2307        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 105,813,508\n",
            "Trainable params: 3,545,859\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_2 (Functional)           {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  102267649   ['model_2[0][0]',                \n",
            "                                None, 768),                       'model_2[0][1]',                \n",
            "                                 'sequence_output':               'model_2[0][2]']                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)]}                                                \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    (None, 768)          3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 768)          0           ['gru_2[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 768)          0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 3)            2307        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 105,813,508\n",
            "Trainable params: 3,545,859\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n",
            "79/79 [==============================] - 22s 257ms/step - loss: 0.5280 - sparse_categorical_accuracy: 0.7836\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-39952b4d07a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m# 画出acc和loss曲线\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sparse_categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_sparse_categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sparse_categorical_accuracy'"
          ]
        }
      ],
      "source": [
        "'''\n",
        "0.7836\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net3 = outputs['sequence_output']\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    #net3 = keras.layers.GRU(256, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    net3=keras.layers.Flatten()(net3)\n",
        "    net3=keras.layers.Dropout(0.2)(net3)\n",
        "    net3=keras.layers.Dense(3,activation=\"softmax\")(net3)\n",
        "    return keras.Model(text_input,net3)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "plot_model(model,to_file=\"/content/drive/MyDrive/ESA/checkpoint/gru3/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=3e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru3/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "model_history = model.fit(x_train, y=y_train, epochs=0, batch_size=64,\n",
        "                          validation_data=(x_dev, y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback],shuffle=True)\n",
        "model.summary()\n",
        "model.evaluate(x=x_test,y=y_test)\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZUQeUxp_cxY"
      },
      "source": [
        "###3.1.4 GRU-64*32_768-768-0.7912"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vy6LkX8LEX7O",
        "outputId": "80057a27-3f41-40c0-fa46-0259af2d88bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  102267649   ['model[0][0]',                  \n",
            "                                None, 768),                       'model[0][1]',                  \n",
            "                                 'encoder_outputs':               'model[0][2]']                  \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768)}                                                 \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 32, 768)      3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 768)          3543552     ['gru[0][0]']                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 768)          0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            2307        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,357,060\n",
            "Trainable params: 7,089,411\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "231/231 [==============================] - 218s 844ms/step - loss: 0.6850 - sparse_categorical_accuracy: 0.7129 - val_loss: 0.5804 - val_sparse_categorical_accuracy: 0.7572\n",
            "Epoch 2/10\n",
            "231/231 [==============================] - 174s 752ms/step - loss: 0.5550 - sparse_categorical_accuracy: 0.7772 - val_loss: 0.5426 - val_sparse_categorical_accuracy: 0.7732\n",
            "Epoch 3/10\n",
            "231/231 [==============================] - 173s 747ms/step - loss: 0.5223 - sparse_categorical_accuracy: 0.7874 - val_loss: 0.5277 - val_sparse_categorical_accuracy: 0.7828\n",
            "Epoch 4/10\n",
            "231/231 [==============================] - 170s 736ms/step - loss: 0.4964 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.5285 - val_sparse_categorical_accuracy: 0.7744\n",
            "Epoch 5/10\n",
            "231/231 [==============================] - 173s 748ms/step - loss: 0.4813 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.5162 - val_sparse_categorical_accuracy: 0.7796\n",
            "Epoch 6/10\n",
            "231/231 [==============================] - 170s 734ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.8145 - val_loss: 0.5229 - val_sparse_categorical_accuracy: 0.7832\n",
            "Epoch 7/10\n",
            "231/231 [==============================] - 172s 744ms/step - loss: 0.4442 - sparse_categorical_accuracy: 0.8208 - val_loss: 0.5116 - val_sparse_categorical_accuracy: 0.7860\n",
            "Epoch 8/10\n",
            "231/231 [==============================] - 171s 743ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.8281 - val_loss: 0.5076 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 9/10\n",
            "231/231 [==============================] - 171s 740ms/step - loss: 0.4144 - sparse_categorical_accuracy: 0.8361 - val_loss: 0.5386 - val_sparse_categorical_accuracy: 0.7800\n",
            "Epoch 10/10\n",
            "231/231 [==============================] - 169s 732ms/step - loss: 0.3951 - sparse_categorical_accuracy: 0.8402 - val_loss: 0.5177 - val_sparse_categorical_accuracy: 0.7872\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  102267649   ['model[0][0]',                  \n",
            "                                None, 768),                       'model[0][1]',                  \n",
            "                                 'encoder_outputs':               'model[0][2]']                  \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768)}                                                 \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 32, 768)      3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 768)          3543552     ['gru[0][0]']                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 768)          0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            2307        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,357,060\n",
            "Trainable params: 7,089,411\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n",
            "79/79 [==============================] - 21s 265ms/step - loss: 0.5279 - sparse_categorical_accuracy: 0.7912\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeViUVfvA8e/NIoigoqC4iwsoCqK4L5lZ5pJLmbmnVraY2WKWbWa91c+33cr0VTNzzyVL03JJTc0lxX1FwA03QFFBRbbz++MZbEKUAQaGGc7nurhynmXmhua558w557mPKKXQNE3THJeTrQPQNE3TCpZO9JqmaQ5OJ3pN0zQHpxO9pmmag9OJXtM0zcHpRK9pmubgdKLXNK1QicgJEbnf1nEUJzrRa5qmOTid6DVN0xycTvRFnIiMFZEoEUkUkUMi8rDZvuEicthsXxPT9moi8pOIxInIRRH5xna/gaZlT0TcRORLETlr+vlSRNxM+3xE5FcRuSwil0Rkk4g4mfa9LiJnTO/7oyLS0ba/SdHnYusAtBxFAe2A80AfYI6I1AHaAuOBXsBOoDaQKiLOwK/AOmAwkA40LfywNS1HbwEtgVBAAb8AbwPvAKOBGMDXdGxLQIlIIDASaKaUOisiNQHnwg3b/ugWfRGnlFqklDqrlMpQSv0IHAOaA08BHyuldihDpFLqpGlfZWCMUuqaUipZKbXZhr+Cpt3JQOB9pVSsUioOeA+jcQKQClQCaiilUpVSm5RRmCsdcAOCRMRVKXVCKRVlk+jtiE70RZyIPC4ie0xfYS8DDQEfoBpGaz+rasBJpVRaYcapaXlQGThp9vikaRvAJ0AksFpEokVkLIBSKhJ4CePbbKyILBCRymh3pRN9ESYiNYBpGF9VyyulygIHAAFOY3TXZHUaqC4iultOK+rOAjXMHlc3bUMplaiUGq2UqgX0AF7J7ItXSs1TSrU1nauA/xZu2PZHJ/qirRTGGzkOQESGYbToAaYDr4pImBjqmD4Y/gbOARNEpJSIuItIG1sEr2k5mA+8LSK+IuIDjAPmAIjIQ6b3tABXMLpsMkQkUETuMw3aJgM3gAwbxW83dKIvwpRSh4DPgK3ABSAY+Mu0bxHwITAPSAR+BsoppdKB7kAd4BTGgFbfQg9e03L2AcZEgn3AfmCXaRtAXWAtkITx/v9WKbUeo39+AhCPMUGhAvBG4YZtf0QvPKJpmubYdIte0zTNwelEr2ma5uB0otc0TXNwOtFrmqY5uCI319rHx0fVrFnT1mFoDiw8PDxeKeWb85HWpd/bWkG62/u6yCX6mjVrsnPnTluHoTkwETmZ81HWp9/bWkG62/tad91omqY5OJ3oNU3THJxO9JqmaQ6uyPXRZyc1NZWYmBiSk5NtHYrdcXd3p2rVqri6uto6FE3T17IV5OWatotEHxMTg5eXFzVr1sSocaRZQinFxYsXiYmJwd/f39bhaJq+lvMpr9e0RV03ItLZtGRXZGZd6Cz7q4vIehHZLSL7RKRrNvuTRORViyMzk5ycTPny5fUbI5dEhPLly+vWk1Zk6Gs5f/J6TeeY6E1L000CugBBQH8RCcpy2NvAQqVUY6Af8G2W/Z8Dv+UqstvjyM/pxZb+u2lFjX5P5k9e/n6WtOibA5FKqWilVAqwAOiZ5RgFlDb9uwymxQNMQfUCjgMHcx2dpuVSXOJNvv7jGPtjrtg6FIst3HGahTtP2zoMzYFZkuirYKxalCnGtM3ceGCQiMQAK4EXAETEE3gdYy1Iu3X58mW+/TbrlxTLdO3alcuXL1s5Is2cUoodJy7xwvzdtJ7wB5+tiWBzZLytw7LYL3vPMGebTe7hKnYK81oeP348n376aZ5ey9qsNb2yPzBTKVUV6ArMFhEnjA+AL5RSSXc7WUSeFpGdIrIzLi7OSiFZz93eHGlpd1+adeXKlZQtW7Ygwir2rqekMW/7KbpM3ESfKVvZcDSWQS1r8Mfo9jx3b3arLBZNARW9iLiQSEaGXhuioBXXa9mSRH8GY8HpTFVN28w9CSwEUEptBdwxFrBuAXwsIicwFvR9U0RGZn0BpdRUpVRTpVRTX99CL0GSo7FjxxIVFUVoaChjxoxhw4YNtGvXjh49ehAUZAxX9OrVi7CwMBo0aMDUqVNvnVuzZk3i4+M5ceIE9evXZ/jw4TRo0IBOnTpx48aN215r+fLltGjRgsaNG3P//fdz4cIFAJKSkhg2bBjBwcGEhISwZMkSAH7//XeaNGlCo0aN6NixYyH8NWwvKi6J8csO0uLDP3hz6X4APno4mO1vduTd7g2o7etp4whzp56fF8mpGZxOuG7rUBxeYV7L5vbs2UPLli0JCQnh4YcfJiEhAYCvvvqKoKAgQkJC6NevHwB//vknoaGhhIaG0rhxYxITE/P9e1syvXIHUFdE/DESfD9gQJZjTgEdgZkiUh8j0ccppdplHiAi44EkpdQ3+Qn4veUHOXT2an6e4jZBlUvzbvcGd9w/YcIEDhw4wJ49ewDYsGEDu3bt4sCBA7emOM2YMYNy5cpx48YNmjVrRu/evSlfvvy/nufYsWPMnz+fadOm8dhjj7FkyRIGDRr0r2Patm3Ltm3bEBGmT5/Oxx9/zGeffcZ//vMfypQpw/79RmJLSEggLi6O4cOHs3HjRvz9/bl06ZI1/yxFSlp6BmsPxzJn20k2R8bj6ix0aViJx1vVIKyGt10P8AVU9ALgyPlEapQvZeNoCo+jX8vmHn/8cb7++mvat2/PuHHjeO+99/jyyy+ZMGECx48fx83N7Va30KeffsqkSZNo06YNSUlJuLu75/fPknOiV0qlmVrhqwBnYIZS6qCIvA/sVEotA0YD00TkZYyB2aHKwdcobN68+b/msX711VcsXboUgNOnT3Ps2LHb3hz+/v6EhoYCEBYWxokTJ2573piYGPr27cu5c+dISUm59Rpr165lwYIFt47z9vZm+fLl3HPPPbeOKVeunFV/x6IgLvEmP+44xbztpzh7JZlKZdx5tVMAfZtVx9fLzdbhWUVdU6KPOJ/Igw38bBxN8VNQ13KmK1eucPnyZdq3bw/AkCFD6NOnDwAhISEMHDiQXr160atXLwDatGnDK6+8wsCBA3nkkUeoWrVqvn9Hi26YUkqtxBhkNd82zuzfh4A2OTzH+DzEd5u7fVoXplKl/ml5bdiwgbVr17J161Y8PDy49957s53n6ub2T2JydnbO9uveCy+8wCuvvEKPHj3YsGED48ePL5D4izKlFLtOJTBr60lW7j9HarqibR0fxnVvwP31K+Di7FiVOzzdXKhWriRHLuT/K7o9cfRr2RIrVqxg48aNLF++nA8//JD9+/czduxYunXrxsqVK2nTpg2rVq2iXr16eXr+TI51xRQQLy+vu/aTXblyBW9vbzw8PDhy5Ajbtm3L82tduXKFKlWMSU0//PDDre0PPPAAkyZNuvU4ISGBli1bsnHjRo4fPw7gEF03yanpjF64l96Tt7LucCwDW9Rg7SvtmfNUCzo39HO4JJ8psKIXEeeLV6K3hcK8ljOVKVMGb29vNm3aBMDs2bNp3749GRkZnD59mg4dOvDf//6XK1eukJSURFRUFMHBwbz++us0a9aMI0eO5DsGx7xqrKx8+fK0adOGhg0bMmbMmNv2d+7cmbS0NOrXr8/YsWNp2bJlnl9r/Pjx9OnTh7CwMHx8fG5tf/vtt0lISKBhw4Y0atSI9evX4+vry9SpU3nkkUdo1KgRffv2zfPrFgVnL9+gz5St/LT7DKM61mXbmx0Z36MBdSrY1+BqXgT6eXE8/ho309JtHYpDK8xr2dwPP/zAmDFjCAkJYc+ePYwbN4709HQGDRpEcHAwjRs3ZtSoUZQtW5Yvv/yShg0bEhISgqurK126dMn360tR60pv2rSpyro4w+HDh6lfv76NIrJ/9vD3+/v4JUbMDSc5NYMv+obyQFDFAnstEQlXSjUtsBe4g+ze25l+2XOGFxfs4bcX21G/Uulsj3EE9vBetAfZ/R3v9r7WLXrNppRSzNl2kgHTtuHl7srPz7cu0CRfVAX6mQZki1k/vVY47KJ6peaYbqalM37ZQeb/fZoOgb582a8xZUoWz3LKtXw8cXESjpxPvK2+iKbll070mk3EXk3mubm7CD+ZwIh7azO6UyDOTvY7Fz6/Srg4Ucu3lB6Q1QqETvRaodtz+jLPzN7J1RtpfDOgMQ+FVLZ1SEVCoF9pdp9KsHUYmgPSffRaoVq08zSPTdmKq7MTS55rrZO8mcCKnsQk3CDp5t1rrmhabukWvVYoUtMz+HDFYWZuOUHr2uWZNKAJ3qVK2DqsIiWzFELEhUSaVPe2cTSaI9GJXitwF5NuMnLebrZGX+TJtv680aWew974lB/1/IxplRHndaLXrEtfbQXE09Pxb/KxxMGzV+jxzV+En0rgsz6NeOehIJ3k76Cqd0k8SjhzRA/IFil3u5ZPnDhBw4YNCzGavNEteq3ALNt7ltcW78XbowSLn21FSFX7rOVdWJychLqm2vSaZk32l+h/Gwvn91v3Of2CocuEux4yduxYqlWrxvPPPw8YpQpcXFxYv349CQkJpKam8sEHH9CzZ86zoJOSkujZs2e2582aNYtPP/0UESEkJITZs2dz4cIFnn32WaKjowGYPHkyrVu3zucvXXBS0zP4ZNVRpm6MpllNb74dGOYwlSYLWmBFT/44HGvrMAqHA1zL5pKTk3nuuefYuXMnLi4ufP7553To0IGDBw8ybNgwUlJSyMjIYMmSJVSuXJnHHnuMmJgY0tPTeeeddwq0hIn9JXob6du3Ly+99NKtN8fChQtZtWoVo0aNonTp0sTHx9OyZUt69OiRY210d3d3li5dett5hw4d4oMPPmDLli34+PjcKlI2atQo2rdvz9KlS0lPTycp6a4LdtnU6UvXGbVgN7tPXWZQy+qMe6gBJVx0V42lAip6sXBnDPFJN/Hx1B+OBcGa17K5SZMmISLs37+fI0eO0KlTJyIiIpgyZQovvvgiAwcOJCUlhfT0dFauXEnlypVZsWIFYBRTK0j2l+hz+LQuKI0bNyY2NpazZ88SFxeHt7c3fn5+vPzyy2zcuBEnJyfOnDnDhQsX8PO7e01xpRRvvvnmbeetW7eOPn363Cpmlllfft26dcyaNQswSqKWKVOmYH/ZPPr9wDleW7wPpdDz4/PIfEDWp46DJ3oHuJbNbd68mRdeeAGAevXqUaNGDSIiImjVqhUffvghMTExPPLII9StW5fg4GBGjx7N66+/zkMPPUS7du1yePb80U2tXOjTpw+LFy/mxx9/pG/fvsydO5e4uDjCw8PZs2cPFStWzLZ2dVZ5Pa+oSk5N552fD/DsnF34+5Rixah2dpHkRaSziBwVkUgRGXuHYx4TkUMiclBE5pltTxeRPaafZdaKKcDPGPjTA7IFy1rXsiUGDBjAsmXLKFmyJF27dmXdunUEBASwa9cugoODefvtt3n//fet8lp3ohN9LvTt25cFCxawePFi+vTpw5UrV6hQoQKurq6sX7+ekydPWvQ8dzrvvvvuY9GiRVy8eBH4p758x44dmTx5MgDp6ekF/jUvN6Liknj42y3M3naS4e38WfRsa6qX97B1WDkSEWdgEtAFCAL6i0hQlmPqAm8AbZRSDTDWPc50QykVavrpYa24fD3d8PZw1QOyBcxa17K5du3aMXfuXAAiIiI4deoUgYGBREdHU6tWLUaNGkXPnj3Zt28fZ8+excPDg0GDBjFmzBh27dpl7V/xX+yv68aGGjRoQGJiIlWqVKFSpUoMHDiQ7t27ExwcTNOmTS1eBeZO5zVo0IC33nqL9u3b4+zsTOPGjZk5cyYTJ07k6aef5rvvvsPZ2ZnJkyfTqlWrgvxVLbIkPIZ3fjmAm4sTM4Y25b56dlV1sjkQqZSKBhCRBUBP4JDZMcOBSUqpBAClVIGPkooIgX5eukVfwKx1LZsbMWIEzz33HMHBwbi4uDBz5kzc3NxYuHAhs2fPxtXVFT8/P95880127NjBmDFjcHJywtXV9VZDrqDoevTFgLX/ftdupvHOLwf4adcZmvuXY2K/UCqVKWm15y9oIhIOTAA6K6WeMm0bDLRQSo00O+5nIAJjmUxnYLxS6nfTvjRgD5AGTFBK/XyH13oaeBqgevXqYZa0FN/95QCLw2PYP/5BnBys0Ju+lq0jt/XodYtey5VDZ68ycv4ujsdf48WOdRnVsa4jV510AeoC9wJVgY0iEqyUugzUUEqdEZFawDoR2a+Uisr6BEqpqcBUMBoxlrxooF9prqWkc+byDaqVK/rdYFrRpxN9Adq/fz+DBw/+1zY3Nze2b99uo4jyLnOBkP+sOEzZkq7MfaoFrWv75Hxi0XUGqGb2uKppm7kYYLtSKhU4LiIRGIl/h1LqDIBSKlpENgCNgdsSfV4EmgZkj55P1Im+iLD3a9luEr1SKldzWouC4OBg9uzZY9MYrNE1d+VGKmOX7OO3A+dpH+DLZ481coQ53juAuiLij5Hg+wEDshzzM9Af+F5EfIAAIFpEvIHrSqmbpu1tgI+tFVhdU3GzoxcSud8BV9vS13L+5OWatmjWTU7T0ESkuoisF5HdIrJPRLqatj8gIuEist/03/tyHSHGDUYXL160StIqTpRSXLx4EXd39zw/x65TCXSduIk1hy7wZtd6fD+0mSMkeZRSacBIYBVwGFiolDooIu+LSOYsmlXARRE5BKwHxiilLgL1gZ0iste0fYJS6tDtr5I3pd1dqVK2pEPOvNHXcv7k9ZrOsUVvNg3tAYyvsjtEZFmWN/bbGBfKZNMUtZVATSAe6K6UOisiDTEunCq5ihCoWrUqMTExxMXF5fbUYs/d3Z2qVavm+rz0DMX0TdF8suoofmXcWfRsKxo7WEVFpdRKjPeq+bZxZv9WwCumH/NjtgDBBRlbQEVPjjrgzBt9LedfXq5pS7puLJmGpoDMpevLAGcBlFK7zY45CJQUETel1M3cBOnq6oq/v39uTtHy4dDZq7yxdD97T1+ma7Af//dISLFdy9VWAv1KszkyntT0DFwdqNqnvpZtw5JEXwU4bfY4BmiR5ZjxwGoReQEoBdyfzfP0BnblNslrhedGSjpf/hHB9E3HKVvSlYn9QunRqLLd9ac6gkA/T1LTFcfjr91akETT8spag7H9gZlKqc9EpBUwW0QaKqUyAESkAfBfoFN2J2eZa2ylkLTc+DMijrd/3s/pSzfo27Qab3StR1kPvQKUrWQm96PnE3Wi1/LNkkRvyTS0J4HOAEqprSLiDvgAsSJSFVgKPJ7dPGPTObmea6xZR1ziTf7z6yGW7T1LLd9S/Ph0S1rUKm/rsIq92r6eODuJQw7IaoXPkkRvyTS0U0BHYKaI1AfcgTgRKQusAMYqpf6yXthafmVkKBbuPM1HKw+TnJrBS/fX5bl7a+Pm4mzr0DTA3dWZmuU9dCkEzSpyTPRKqTQRyZyG5gzMyJyGBuxUSi0DRgPTRORljIHZoUopZTqvDjBORDJnM3QqjJoh2p1Fxiby5k8H+PvEJVr4l+OjR4Kp7auXPixq6vmV5sDZolPATrNfFvXRWzAN7RDGTSNZz/sA+CCfMWpWkpyazrcbopi8IRKPEi58/GgIfcKq6sHWIiqgohcrD5zjekoaHiXs5t5GrQjS755iYmvURd5aup/o+Gv0Cq3M2w8FOcSNT44s0M8TpeDYhSQaVdPr7Wp5pxO9g0u4lsJHKw+zKDyG6uU8mP1kc9rV9bV1WJoFAk2rTR29kKgTvZYvOtE7KKUUy/ae5b3lh7h6I5Xn7q3NqPvqUrKEHmy1F9XLeeDu6uSQd8hqhUsnegd09vIN3v75AOuOxBJarSwTegffWotUsx/OTkLdCl56iqWWbzrRO5CMDMX8Haf4v5VHSM9QjHsoiCGtazpyvXiHF1DRi43HdF0YLX90oncQx+OvMXbJPrYfv0SbOuX5v4dD7GLtVu3uAv08WbIrhkvXUihXSt+prOWNTvR2Li09g+82H+fzNRGUcHHi494h9Gmqp0w6iswB2YgLibTUdyxreaQTvR07fO4qry/Zx76YKzwQVJEPejWkYum8157Xip5As5o3OtFreaUTvR26mZbOpHWRfLshirIerkwa0ISuwX66Fe+AKpZ2o0xJV47qAVktH3SitzPhJxN4fck+ImOTeKRxFd55KAhv3XfrsESEwIpeROgpllo+6ERvJ66npPHJqqPM3HKCSqXd+X5YMzoEVrB1WFohCPDz5Jc9Z+1yrVWtaNCJ3g5sPhbP2J/2EZNwg8Eta/Ba50C83PWKT8VFoF9pEpNPce5KMpXLlrR1OJod0om+CEtOTee95QeZ//dp/H10rfjiynxAVid6LS90oi+iTl+6zrNzwjl49irP3FOLlx8IwN1Vly8ojm4l+guJdKinu+u03NOJvgj6MyKOFxfsJj1D8d2QpnSsX9HWIWk2VMbDFb/S7npAVsszneiLkIwMxbcbIvlsTQQBFbz43+AwavqUsnVYWhEQ4OelV5vS8kwn+iLianIqoxfuZc2hC/RoVJkJvYP1YhPaLfX8vJgZfZG09AxcnJ1sHY5mZ3QmKQKOnk/k2TnhnL50nXEPBTGsTU09jU77l4CKXqSkZXDi4nXqVNDLPmq5o5sGNvbrvrM8/O1fJCanMW94S55o66+TfCESkc4iclREIkVk7B2OeUxEDonIQRGZZ7Z9iIgcM/0MKcg46/kZA7K6ZLGWF7pFbyNp6RlM+O0I0zcfp0n1skweFKbr1BQyEXEGJgEPADHADhFZZloDOfOYusAbQBulVIKIVDBtLwe8CzQFFBBuOjehIGKtU8ETEePbX9fgSgXxEpoD04neBuKTbjJy3i62RV/i8VY1eLtbECVc9JcrG2gORCqlogFEZAHQEzhkdsxwYFJmAldKxZq2PwisUUpdMp27BugMzC+IQN1dnalZvpRebUrLE53oC9muUwmMmLOLhOspfP5YIx5pUtXWIRVnVYDTZo9jgBZZjgkAEJG/AGdgvFLq9zucWyXrC4jI08DTANWrV89XsIEV9WpTWt5Y1IzMqR9TRKqLyHoR2S0i+0Skq9m+N0znHRWRB60ZvD1RSjFn20n6/m8rri7CTyNa6yRvH1yAusC9QH9gmohYvFK3UmqqUqqpUqqpr2/+FmUP8PPixMVrJKem5+t5tOInx0Rv1o/ZBQgC+otIUJbD3gYWKqUaA/2Ab03nBpkeN8D4Wvut6fmKleTUdF5bvI+3fz5A69o+LB/ZlgaVy9g6LA3OANXMHlc1bTMXAyxTSqUqpY4DERiJ35JzraqenxcZCiJjkwryZTQHZEmL/lY/plIqBcjsxzSngMzVp8sAZ03/7gksUErdNF0kkabnKzYuJt2kz5StLAqPYdR9dZgxtBllPXRZ4SJiB1BXRPxFpARGo2RZlmN+xmjNIyI+GF050cAqoJOIeIuIN9DJtK3ABJjVvNG03LCkj96SfszxwGoReQEoBdxvdu62LOfe1o/pqNIzFKMW7CbiQiLTH2/K/UG6lEFRopRKE5GRGAnaGZihlDooIu8DO5VSy/gnoR8C0oExSqmLACLyH4wPC4D3MwdmC0rN8h6UcHHSi5BouWatwdj+wEyl1Gci0gqYLSINLT3ZmgNWRcnEtRH8FXmRj3uH6CRfRCmlVgIrs2wbZ/ZvBbxi+sl67gxgRkHHmMnF2Yk6vp66Ra/lmiVdN5b0RT4JLARQSm0F3AEfC8+16oBVUbH+aCxfrYukT1hVHmtWLecTNM0CgX565o2We5Ykekv6MU8BHQFEpD5Goo8zHddPRNxExB9jEOtvawVfVJ25fIOXf9xDPT8v3u9p8RcbTctRQEUvzl1J5sr1VFuHotmRHBO9UioNyOzHPIwxu+agiLwvIj1Mh40GhovIXowbRoYqw0GMlv4h4HfgeaWUQ88NS0nLYMTcXaSlKyYPCqNkiWI3yUgrQLdKIcTqVr1mOYv66C3oxzwEtLnDuR8CH+YjRrvy0crD7D19mckDm+CvSwxrVhZgSvRHzifSrGY5G0ej2Qt9370VLd97lplbTvBkW3+66HokWgGoXMYdLzcXvQiJlis60VtJZGwSY5fsI6yGN2O71LN1OJqDEhEC/Lz0FEstV3Sit4LrKWmMmBuOm6sz3wxojKteGELLjeuXID7S4sMDKnpx9HwixsxPTcuZzkj5pJTiraUHOBabxMR+oVQqU9LWIWn2RCn4oTsseRIyLJunUM/Piys3UolNvFnAwWmOQif6fJr/92mW7j7DSx0DaFfXMe4B0AqRCLR9Gc7tgV0/WHRKZikEvYasZimd6PNhf8wVxi87yD0BvrxwXx1bh6PZq4a9oUZb+ON9oxsnB4GZUyx1otcspBN9Hl25nsqIeeGU9yzBl31DcXLSy/9peSQCXT+B5Kvwx3s5Hl6uVAl8vdz0gKxmMZ3o8yAjQzF60R7OXU5m0sAmlCulq1Fq+VQxCFo8C+E/wJldOR4eaBqQ1TRL6ESfB1M3RbP2cCxvdatPk+retg5HcxT3jgXPCrDyVcjIuOuhgX5eHItNJD1Dz7zRcqYTfS5ti77IJ6uO0i24EkNb17R1OJojcS8ND/wHzoTD7tl3PTSwohfJqRmcvnS9kILT7JlO9LkQm5jMC/N3U6OcBxN6ByOi++WzlZEBMeFw9WzOx2r/FvIYVG8Na8ffdWA20E/PvNEspxO9hdLSMxg1fzeJyal8O6gJXu6utg6paElPg+g/YcVo+Lw+TL8PJrWEU9tyPlf7x62B2Suw7oM7Hla3oieALlmsWUQnegt9viaCbdGX+LBXMPX8Sud8QnGQdhMiVsMvI+GzAJjVA3bPhWrNoMc34OkLs3rBsTW2jtS++DWE5sNh5ww4uyfbQzxKuFC9nIcekNUsYq0VphzamkMX+HZDFP2bV6d3WFVbh2NbKdch6g84tAwifoebV6GEFwR2hvo9oE5HKGGq2hnQGeY8AvP7wcP/g+BHCyfGE5uhUiNw8yqc1ysI974BB5YYA7NPrAan29tkgbrmjWYhnehzsDXqIiPn7SK4Shne7R5k63BsI/kqHFsNh36ByLWQeh1KehuJPagH1BPyQbEAACAASURBVLoXXNxuP8/TF4b+CvP6wZKnjO6IZk8WXJzpqbD+Q9j8pXG36f3vFtxrFbSSZeGB9+Hn52DvPGg86LZDAit6se5ILDfT0nFz0eseaHemE/1d7DxxiSd/2EGN8h7MHNYMd9didDElXoDINUbLPXo9pKeAZ0Vo1N9I7jXagrMFbx/3MjD4J1g4BFa8AsmXoe0rRl+0NV06btSLORMOYUPhnjHWfX5bCOkH4TNhzbtQr5vx4Wom0M+L9AxFVOw1girr7kTtznSiv4M9py8z9Psd+JV2Z85TLSjvmU2L1ZGkp8Lpv40We+QaOL/f2F6mGjQbbiT3qs2z7ULIkWtJ6DfXaJ3+8T7cSDCmEVor2e9fDMtfMmLr8wM06GWd57U1Jyfo+ilMbQ/rPzIGac3cKoVwIVEneu2udKLPxsGzV3j8u+2UK1WCecNbUsHL3dYhFYwrMabEvtaYMXPzKogzVG8JHcdBnfvBL8Q6CdnZFR6earRKt3xtJPuHJlr2reBObibBb6/DnjlQrSX0ngZlq+c/1qKkUgg0fRJ2TIfGg43HJv4+pXB1Fj3FUsuRTvRZHD2fyKDp2/Fyd2Xe8Bb4lXGgJJ92E05tNRL7sbUQd9jYXroKNHjYSOy12hvdLQXByQm6fGwk+z//a/TZ9/4u+/79nJzbC4ufgItRcM9r0P71/H1oFGX3vQUHl8LKMfDE77c+eF2dnajt66mnWGo5ctArI28iY5MYOH0bJVycmPtUC6p6e9g6pPxLOGFMb4z8A45vhNRr4FwCarSGxgON5O5bz/p95nciAh3eBPeysOoNmNsH+s0DN0/LzlcKtk2Gte+Chw8MWQ7+7Qo2Zlsr6Q33j4dlI2HvAgjtf2tXQEUvwk8m2Cw0zT7oRG9y8uI1Bk43bu6Z+1RLapov7H3pOFyLg2rNbRRdLiVegP2LYN+Cf/ravWtC6AAjsddsa3liLSitRhgzS34ZCbN6wsBF4JHDYtdJcfDLCGMGUGA36PlNzuc4itCBpoHZcVCv661vXYF+Xizbe5bYq8lUKO1A3z41q9I3TAExCdcZMG07KWkZzH2qJXUqmCXBs7thWgf4rhP8NdFoURZFKddg30KY/Qh8Xg9WvwVOrvDg/8ELu2DUHuj2qTHf3dZJPlPoAOg72/gw+r4rXD1352Oj1sOUNsZYQtdPjcHdfCZ5EeksIkdFJFJExmazf6iIxInIHtPPU2b70s22L8tXIJZwcjL+/12Lg/X/d2tz54Z+lHBx4s2l+/XSgtodFfsW/fkryQyYtp3E5FTmDW95ayYDAKd3wJzeULIM1GhjtKbij0G3z8GlCJQmzkiHE5uMr/OHl0NKEpSpbkxfDOkLvgG2jjBn9brBoMUwvz/M6ASDf4bytf/Zn55qlAL4ayL4BMCgn4w7R/NJRJyBScADQAywQ0SWKaUOZTn0R6XUyGye4oZSKjTfgeRG5cbQdBj8PRWaDIaKDajt68lrDwbywYrDLNoZw2PNqhVqSJp9sKhFb0HL5wuz1k2EiFw22/exiBwUkcMi8pUUoUpgsYnJDJi2jUvXUvjhieY0rGI2CHlyC8zuBaXKw9CV8NhsY2727tnG3Z43bNgveuGQ8aHzRUOj2+PICmMwdegKeHEvdHzHPpJ8Jv97YMgyYxbNjM5w/oCx/dJxmPEg/PUlNHkcnl5vlSRv0hyIVEpFK6VSgAVAT2s9eYG57x2j22bFq7e+XT7Rxp+Wtcrx3vKDupqllq0cE71Zy6cLEAT0F5F/3SKqlHpZKRVqauF8DfxkOrc10AYIARoCzYD2Vv0N8ujStRQGTd/OuSvJfD+sGY3N68pHbzBa8qUrG0m+bDXjq/N9b0OvKUahrun3GzM+CkviedjyDUxpC5NbwdZJxlS7R7+HVyOM/uqabfM2z70oqBJmzChxcoGZXWHjJzClHcRHQp+Z0OOrf0orWOkVgdNmj2NM27LqLSL7RGSxiJg3l91FZKeIbBORO07cF5GnTcftjIuLy3/UHuWMO35PbTHGYQAnJ+HTPo0QEUYv3Ktr1Gu3sSQr5Lbl0x+Yb/q3AtyBEoAb4ApcyHu41nHleiqDpm/n5MXrfDekKc1qmvX1HlsDcx8Db38jyZeu9O+TQ/sbrc/rl2B6RzjxV8EFmpEBB3829bvXN/W7uxhTFEcfhQE/QsNHjBuSHIFvIDy5yphNs+4DY9Wl5zYb31ZsYzlQUykVAqwBzFfvrqGUagoMAL4UkdrZPYFSaqpSqqlSqqmvr5UWj2/8OFRuAqvfNspTAFW9PXi3exB/n7jEd5ujrfM6msOwJNFb2vJBRGoA/sA6AKXUVmA9cM70s0opdTib86zb6rmLxORUHp+xncjYJP43OIzWdXz+2XlkBSwYABXqGTVaPO9wYdZoDU+tBY/yRtfJnvnZH5dXSkHEKvjfPbBoCMRHGLVbnt8BT2+AFs9AKZ+cnsU+la0OT6425tcPXVmQN0CdAcxb6FVN225RSl1USt00PZwOhJntO2P6bzSwAWhcUIHeJnNgNinWuB/B5NGwqnQKqsinqyJ0VUvtX6z9Pb8fsFgplQ4gInWA+hgXURXgPhG5bdJzgbR6snHtZhrDvt/BwbNX+WZAY+4NrPDPzoNLYeHjxp2gjy/LeUZH+dpGsq/RCn5+1ri1P4fl3yxy4i+jn3reY8bg6iPTTf3u4+yr3z0/SvkYlS4L9gaoHUBdEfEXkRIY791/zZ4REfOvcz2Aw6bt3iLiZvq3D0b3ZNZB3IJVJcwYt9g+BWKPZMbLR48EU7qkCy/9uIeUNCu8HzWHYEmiz7HlY6Yf/3TbADwMbFNKJSmlkoDfgFZ5CTS/bqSk8+QPO9h1KoGJ/RrTqYHfPzv3/mjcZVm1GQxeaszvtkRJb2MWSJPHYdNnsHgopN7IW4BndxtdNDO7wuWT8NAXMHIHhPQBp2JUTK2QKKXSgJHAKowEvlApdVBE3heRHqbDRpkmEuwFRgFDTdvrAztN29cDE7KZrVPwOr5rlGJe+aoxOwnw8XTjo4eDOXzuKhP/iCj0kLQiSil11x+MKZjRGF0yJYC9QINsjqsHnADEbFtfYK3pOVyBP4Dud3u9sLAwZW0ZGRnqie//VjXH/qp+2nX63zvDZyn1bhmlZj6k1M2kvL6AUpsnGs8ztYNSV89bfm7sEaV+HKzUu6WVmlDDeJ6U63mLQ7MIsFPl8L4viJ+CeG+rnTON987kNkqd3Xtr86sL9yj/sb+qnScuWv81tSLpbu/rHFv0yrKWDxit+QWmF8y0GIgC9ps+IPYqpZbn5QMpP+KTUvjjSCwjO9Th4cZmC4f8Pc24rbxORxiwMO+zOkSgzSjoOwdiDxuDtJlTBO/k8in4+Xn4tqVRnqD96/DiPuN5HGVwVSt4YUOM913iBePGvvUfQVoK47oHUblsSV5ZuJdrN9NsHaVmYxb10SulViqlApRStZVSH5q2jVNKLTM7ZrxSamyW89KVUs8opeorpYKUUq9YN3zLRMclARBWw2wK5dZJxlfegC5GrRVrJNf6D8Gw3yAjzZj/HbH69mOSYo2Ki1+HGdPjWo4w+uA7vAnuutSslgf1u8Pz26Fhb2NwdloHvC4d5NM+jTh16Tofrbxt/oNmKzu+g12zCv1l7XTSde5ExV0DoLav6db/TZ/BqjchqCc8Nitv1RPvpHIoDF8H5WrB/L6w/X/G9huXjQHbiY2MbxKN+sOoXfDgh447g0YrPB7l4JGp0H8BXIuHaffR8sRknmldhbnbT7H+aKytI9QiVhuL7yx7Ada+V6jlVIpFCYTouCTcXJyoUsbd+Gr7538huI9x81NBzOwoXdlo2f80HH57DaLWGeWBk68Yra4Ob/37Nn9Ns5bALsZ6Ar+/CRs/4TXfXzld/ileX7yPVS/dg3epIlC6ozhKPG8svFOhAVRtCps/N+6u7/ZZoUy2KBYt+uj4a/iX98Bp3XtGkg8dZCxWXZDT99w8jb7TViONRbSrtYRnNsGjM3SS1wpWSW94eDIMWIhT8mW+uf4aw5JnMX7pLl34zBYyMmDpM0bhwUdnQPeJ0G40hH9vLH+ZllLgIRSLFn1UXBLjXOfCX4ug6RPQ9bPCKRXg5Gx0zdzz6m3rfWpagQt4EEZsQ1a/xXO75xARsZONGz6jfYcuto6seNnylVFWpftE42ZMMO6LKelturv5itEotG6Jj39x+Bb9zbR06l7eRMfLi4y1T7t9Xvj1YHSS12ylZFnoOYn0/oso53KTtn/2J+nXNyE12daRFQ8x4bDuP8Z4YJMh/97X+gXo8Y3xITCrl1FWpYA4fKI/dT6e8S4/cNWrNjz4UeGtpKRpRYhzYCeSntzMkoz78Nw5CfW/dsZi8FrBSb4KS54Ar0pGaz673NNksLGg/bk9MLOb0ZdfABy+68Z548dUlXgi20+mdFGoIa9pNlKzSiU2df2CwcvmMTnpBzy/6wStnofa90FasvGTmgxpN/75b9pN427vW/syjzNtK1vD6JrU407/ppQxw+byKWNixt2+1Qf1APdFMH+AscDR4z8bs/asyLET/YWD1Dj2PT+m3Uu34PtsHY2m2dygFtVZe6gj7Y8HsD5kPaW3fgNbv7nLGWLcY+Libvy4uoNLSeO/zm5w6GfYv9AY+7rntTsXAixu9i4w7pPp8JYxCyonte411j+e29uodTV4KVRsYLVwHDfRZ2TAry9zw8mT6SWH0tfNcX9VTbOUiPDxoyF0+uIyg2P7s+TZEbikXDXuJclM4Lf+624sJH+37s7E87BhgnEj0J550HqU8S2hqCxXaQvxkbBitLEqXbvRlp9XNQyG/Q6zH4bvu8CARVC9hVVCctw++t2z4fR2Zng8gY9vpZyP17RiomJpdz7o1ZC9py8z+aCr0eKs3NiYEeJdE7wqGqtYubjlPKbl5QfdvzTuzK3dATZ8BF81hh3TbxVaK1bSUox+eZcS8Mi03M+Rr1DPWIDHo7yxwl3kWquE5ZiJPikO1oxD1WjNtMSW1K5QcNOWNM0edW9UmR6NKjPxj2PsPX055xNy4lPXmCL45Bqjv37FaKOO06FfrHcH6I3LcGAJ/PQ0fFLXWFA++s9CvcM0R3+8B+f2GrNpymS7bEfOvGvAE6uMv+O8fnDgp3yH5ZiJfs07kHKNhA4fk5icTi2fYvw1UtPu4P2eDajg5cbTs3dy9nIey2tnVa25MfjYf4GxGtrCx41lN/OyEptSEH8MtnwNMx+Cj2sZ5cSPrTGWzbx0HGb1KDoJ/9haY7yj2VNG3av88KwAQ3417qJd/ATsnJGvp3O8RH98I+ydD21GEZFRGYDaFXSi17SsynqU4Pthzbl+M51h3+/garKVulpEjFIMz20xWrZXzxrrLMzrayxsfzdpKRC1Hn4bC183gW+aGjcV3UiANi/CE6thTCT0+R5G7Yaun0LCCdsn/MQLxgJEFYKg0wfWec6SZY31Lup2gl9fNmp05fF3c6wRyrSb8OsrRj/jPWOI3mUsS1jLR3fdaFp2Av28mDI4jCEz/mbEnF18P6wZrs5Wav85ORvzxIMfNVbC2vQFTGkDjQYY1VozuzaS4uDYaqNUSNR6SEk0ZvTUam8M7NZ9EMpWu/35Xd2h+XBoPNgYk9v0uZHwq7eGe8eC/z2Fc99MRoaR5G8mGjNnrFlmvIQH9Jtr1Mn5433jpqpOH+T693KsRP/XV3DxGAxcAq4l/ylmVlbXd9e0O2lTx4cJvUN4ddFe3vhpP588GoJYM0G6ljTWPG4yxGiV/j0VDiyGho9C3BE4Ew4o8KpsfCgEPGgkaUtLAtg64W/9xihc+NAXUKG+9Z/f2RUenmrMxd/xHYQNNcZEcsFxEv3FKNj4CTR4GOreDxg1bvx9SuHkpO+G1bS7eTSsKqcvXWfiH8eo5u3Bi/fnLpFYxKOcUfupxTNGFdl9C6BSqDHXPOBB8AvOX0K2RcI/E24MwNbvDmHDrPvc5pycoMvH0PwZ8KmT69MdI9ErZSwi4lwCHvy/W5uj46/RsHIZGwamafbjpfvrEpNwgy/WRlDVuyS9w6rmfFJelK0OD0+BXpMLpqVdWAn/ZiIsfhI8/aD7VwXfTSSSpyQPjjIYe/An46tTx3egtDFn/mZaOqcvXae2r+6f1zRLiAj/90gwrWuX5/Ul+9gSGV/QL1iwz5+Z8G8btO0CR1YYA6j5Gbhd8SpcPgm9pxnfVoow+2/R37gMv79hfAVs9tStzScvXidDQS1fPeNG0yxVwsWJyYPC6DNlC8/MCWfJc60JqOhl67DyJ7sW/oIBxj4PH/BrCBUzfxqAb2DOq87tXWB0Pd37BtRoXfC/Qz7Zf6Jf9wFci4MBP/7rLrTMdWJr60SvablSpqQr3w9rzsOT/mLY9ztYOqI1FUq72zqs/MtM+E0eNyp3Xjhg/Jw/YNzJm2Yq3ezkAj4B/yT+zA8Cz4rGt5CLUcYNYdVbQ7tXbfs7Wci+E31MuPE/qMUzxi3cZjLXifXXXTealmtVypZkxtBmPPa/rTzxww5+fLoVpRylXpSLG/i3M34ypafBpShT8j9oJP+TW4yCbZk8fIzEf/Ws8WHwyNSCXaXOiuwjyuykp8GvLxm1Njq8ddvuqLgkKpZ2w9NR3pyaVsgaVinDpAFNeGrWTkbO28W0x5viYq059kWNs4vRZeMbaKzrnOn6JYg9ZCT+zA+B6/HQ69vs5/YXURZlQRHpDEwEnIHpSqkJWfZ/AXQwPfQAKiilypr2VQemA9UABXRVSp3Id+Q7psH5fUbRfvfSt+2Oirumu200LZ861KvA+z0b8NbSA7y77CAf9Gpo3Tn2RZ1HOaPcQs22to4kX3L8eBYRZ2AS0AUIAvqLSJD5MUqpl5VSoUqpUOBrwLwKzyzgE6VUfaA5EJvvqK+cMfrm6zxgLNGVhVKK6LgkauluGy0HItJZRI6KSKSIjM1m/1ARiRORPaafp8z2DRGRY6afIVnPdRQDW9Tg2fa1mbv9FP/bGG3rcLQ8sKRF3xyIVEpFA4jIAqAncKeiFf2Bd03HBgEuSqk1AEqppHxHDPD7WMhIg66fZDtFKz4phcTkNN2i1+7KrBHzABAD7BCRZUqprO/tH5VSI7OcWw7jfd4U45tquOnchEIIvdC99mAgZy7fYMJvR6hStiTdG1W2dUhaLljS4VYFOG32OMa07TYiUgPwB9aZNgUAl0XkJxHZLSKfmC6urOc9LSI7RWRnXFzc3aOJWAWHl0H716Ccf7aHRJlm3OiplVoObjVilFIpQGYjxhIPAmuUUpdMyX0N0LmA4rQ5Jyfhk0dDaFbTm9EL97LjRMEtZK1Zn7VHVvoBi5VS6abHLkA74FWgGVALGJr1JKXUVKVUU6VUU1/fuyxFlnLduAPWtx60euGOh0WbZtzoYmZaDixtxPQWkX0islhEMkfgLDo3V42YIs7d1Zmpg5tS1bskw2ftvNWg0oo+SxL9GYyB1ExVTduy0w+Yb/Y4BthjajGlAT8DTfISKAAbPzYW2+32ubGCyx1E6WJmmvUsB2oqpUIwWu0/5OZkixsxdsK7VAlmDmuOswjDvt9BfNJNW4ekWcCSRL8DqCsi/iJSAiOZL8t6kIjUA7yBrVnOLSsime/w+7hz3/7dXThkLEAQOghqtrnrodG6mJlmmRwbMUqpi0qpzGw2HQiz9FxHVb28B9OHNCU2MZlB07dz9HyirUPScpBjoje1xEcCq4DDwEKl1EEReV9Eepgd2g9YoNQ/xSNMXTivAn+IyH5AgGl5ijQ+AkpXhgfez/HQqLhrerERzRI5NmJExHzB4R4Y1wAY10MnEfEWEW+gk2lbsdC4ujdTBzclLvEm3b/ezKT1kaSlZ9g6LO0OLJpHr5RaCazMsm1clsfj73DuGiAkj/H9o0EvqNfNqM18FzfT0olJuE6vUD0rQLs7pVSaiGQ2YpyBGZmNGGCnUmoZMMrUoEkDLmEaY1JKXRKR/2B8WAC8r5QqViOU9wT4svrlexj3y0E+WXWU1QfP82mfRtS199o4Dsi+bhvNIcnDP8XMdItes0ROjRil1BvAG3c4dwaQv8U87Vx5TzcmDWxCl31neefnA3T7ejOvPBDA8Ha1cNZdp0WGw93PHBVrmlqpFwTXtELzUEhlVr/cng6Bvkz47QiPTtmiZ+UUIQ6X6KPjdTEzTbMFXy83pgwKY2K/UKLjrtF14iambYwmPcMGi3Vr/+JwiT4qNgm/0u66mJmm2YCI0DO0Cmtevod2dX35cOVhHvvf1ltlwzXbcLxEH39N17jRNBurUNqdaY+H8UXfRhy7kEjXrzYxY/NxMnTr3iYcKtFnFjPTNW40zfZEhIcbV2XNK+1pXduH9389RL+p2zhh6l7VCo9DJfq4pJskJqfpFr2mFSEVS7vz3ZCmfPJoCIfPX6XLxE38sOWEbt0XIodK9Ldq3OgWvaYVKSJCn6bVWP3yPTT3L8e7yw4yYPo2zly+YevQigWHSvRRt9aJ1S16TSuKKpUpycxhzfhv72D2x1yhy5cb+W3/OVuH5fAcKtFHx13D3dWJymV0MTNNK6pEhL7NqrPyxXb4+5Tiubm7eHPpfm6kpOd8spYnDpXoo+KS8Pfx1MXMNM0O1ChfikXPtuaZ9rWYt/0UPb7ZzJHzV20dlkNyqEQfHaenVmqaPSnh4sQbXeoz+8nmJFxPpcc3fzFr6wnMaiNqVuAwiT451ShmpqdWapr9aVfXl99fakfr2uUZ98tBnp4dTsK1FFuH5TAcJtHfKmamW/SaZpd8PN2YMaQZ7zwUxIajsXSZuImtURdtHZZDcJhEn3mLtS5mpmn2y8lJeLKtP0tHtMGjhDMDpm/js9VHda37fHKYRP/PguC6Ra9p9q5hlTIsf6EtjzapytfrIuk7dRunL123dVh2y2ESfXTcNfxKu1NKFzPTNIdQys2FT/o0YmK/UCLOG/VyVuzTc+7zwmESfVT8NWpX0K15TXM0PUOrsPLFdtSp4Mnz83Yxdsk+rqek2Tosu+IQiV4pRXRsku6f1zQHVa2cBwufacXzHWrz487TdP96s16UPBccItHHJd0k8aYuZqZpjszV2YkxD9Zj7pMtSExO49EpW/j7eLFapjfPHCLRR8Uaxcz0HHpNc3yt6/iw9Pk2+Hq5Mfi77aw9dMHWIRV5DpHoo+P1jBtNK06qlC3J4mdbU8/Pi2fmhLM4PMbWIRVpFiV6EeksIkdFJFJExmaz/wsR2WP6iRCRy1n2lxaRGBH5xlqBm9PFzDSt+ClXqgRzh7ekVa3yvLpoL9M2Rts6pCIrx0QvIs7AJKALEAT0F5Eg82OUUi8rpUKVUqHA18BPWZ7mP8BG64R8O13MTNOKJ083F74b2pRuwZX4cOVhJvx2RNfJyYYlLfrmQKRSKloplQIsAHre5fj+wPzMByISBlQEVucn0LuJjrumSx9oWjHl5uLMV/0bM7BFdab8GcXYJfv1nbRZWJLoqwCnzR7HmLbdRkRqAP7AOtNjJ+Az4NW7vYCIPC0iO0VkZ1xcnCVx35Kcms7phOt6VSlNK8acnYQPejVkVMe6/LjzNCPm7iI5Vde3z2Ttwdh+wGKlVOZfeASwUil115ESpdRUpVRTpVRTX1/fXL3gyYvXUbqYmZZHOY0/mR3XW0SUiDQ1Pa4pIjfMxqamFF7UWnZEhFceCGB89yBWH7rA0O//JjE51dZhFQmW1As4A1Qze1zVtC07/YDnzR63AtqJyAjAEyghIklKqTteULn1z/KBukWv5Y7Z+NMDGN9Ud4jIMqXUoSzHeQEvAtuzPEWUaVxKK0KGtvHHu1QJRi/cS7+p25g5rDm+Xm62DsumLGnR7wDqioi/iJTASObLsh4kIvUAb2Br5jal1EClVHWlVE2M7ptZ1kzy8E/VSn8f3aLXcs3S8af/AP8FkgszOC3veoZWYfqQpkTHXaPPlC3FviBajoleKZUGjARWAYeBhUqpgyLyvoj0MDu0H7BAFfKQd3TcNSqV0cXMtDzJcfxJRJoA1ZRSK7I5319EdovInyLSLrsXyM/4k5Y/9wZWYM5TLUi4nkrvyVuK9TKFFvXRK6VWKqUClFK1lVIfmraNU0otMztm/N1a60qpmUqpkfkP+d+i4pL0jVJagTBNJvgcGJ3N7nNAdaVUY+AVYJ6IlM56UH7Gn7T8C6vhzaJnW+EkwmNTtrLzRPEsmWDXd8YqpYx1YnUxMy1vchp/8gIaAhtE5ATQElgmIk2VUjeVUhcBlFLhQBQQUChRa7kSUNGLxc+1wsfTjUHfbWfdkeJXMsGuE31colHMTM+40fLoruNPSqkrSikfpVRN0zjTNqCHUmqniPiaBnMRkVpAXUDfmllEVfX2YNGzrahbwYvhs4pfyQS7TvRRcUYxMz2HXsuLXIw/ZeceYJ+I7AEWA88qpYpnv4CdKO/pxvynW9LCvxyvLtrLEzN3cPLiNVuHVSjsegQzs5hZ7Qo60Wt5o5RaCazMsm3cHY691+zfS4AlBRqcZnWebi788ERzfthygi/WRPDAFxt5tn1tRtxbG3dXZ1uHV2Dsu0UfaxQzq1Ta3dahaJpmJ1ydnXiqXS3WvXovXRr68dUfx7j/8z9ZffC8w9bJsetEHx1vrCqli5lpmpZbFUu7M7FfY+YPb4lHCWeenh3OEzN3cCLe8bpz7DrR66mVmqblV6va5Vkxqh1vd6vPjhMJdPpiI5+vPsqNFMeplWO3iT45NZ2YhBt6IFbTtHzL7M75Y3R7ugT78dW6SO7//E9WOUh3jt0m+hMXr+liZpqmWVVmd86Cp1vi6ebCM7PDGeYA3Tl2m+ij4/Q6sZqmFYyWtcrz66i2vPNQEDtN3Tmf2XF3jh0nel3MTNO0guPq7MSTbf1ZN7o93UIq8bWpO+f3A/bXnWO3iT5KFzPTNK0QVCjtzhd9Q/nR1J3z7JxwRi3Yw1U7qnVvt4k+Ws+40TStELUwdee82imAlfvP1+qiMQAACO5JREFU0XXiJsJPJtg6LIvYZaJXShEVd033z2uaVqhcnZ0YeV9dFj3bCoDH/reVr/84RnpG0e7KsctEH5d4k6SbadTS/fOaptlAk+rerHyxHd2CK/HZmggGTNvGuSs3bB3WHdllos8sZqZr3GiaZiul3V2Z2C+UT/s0Yv+ZK3SZuIlVB8/bOqxs2WmiN2bc6JulNE2zJRHh0bCq/PpCW6p6l+SZ2eG8/fN+klOL1jRMu0z00XHXKOnqrIuZaZpWJNTy9eSn59owvJ0/c7adosc3mzl6PtHWYd1il4k+Ki4Jf59SupiZpmlFRgkXJ97qFsQPTzTn0rVUun+zmVlbTxSJOfd2meij4/XUSk3Tiqb2Ab789mI7WtUqz7hfDjJ8VjgJ11JsGpPdJfrMYmZ6aqWmaUWVr5cb3w9txtvd6vNnRCydJ25kS1S8zeKxu0SfWcxMt+g1TSvKnJyEp9rVYumINpQq4cLA6dv5ZNURUtMzCj8WSw4Skc4iclREIkVkbDb7vxCRPaafCBG5bNoeKiJbReSgiOwTkb75DVgXM9M0zZ40rFKG5S+0pU9YVSatj2LgtO2F3pWTY6I3rXQ/CegCBAH9RSTI/Bil1MtKqVClVCjwNfCTadd14HGlVAOgM/CliJTNT8BRsZlTK3WLXtM0+1DKzYWPH23El31D2RNzmYe//YvjhVj62JIWfXMgUikVrZRKARYAPe9yfH9gPoBSKkIpdcz077NALOCbn4Cj441iZh4ldDEz7f/bu//YuuoyjuPvD+sKrCDbGEbXLl2Nk2UScawZyBISnQaNOiASU8yWiAkmOnQi0YgmxuhfBoMS4wxkYMQRYKk0aWRh/gD/IVLWMYluc7oWdK0YLgbBTQEbH/+455q70q233b3fs3Pu5/VX77k/Pue2T5+ce85zzjUrlmvXdvPATZfzyqtTXLf9CUbG/54kt5FG3w0crbs9kS17A0m9QB/w2Az3rQc6gbEZ7vu0pFFJo5VK5ZQrM1Y55t02ZlZY63qXMvTZK1na1cnme0YY2j/R8sxmH4wdAAYj4oTTwiS9FfgJcGNEvOFIRETcHRH9EdF/0UUn3+CPCMYrx73bxswKrffCLoY+s4H+3qXc8tAzfPcXf2zpvH0jjX4SWFF3uydbNpMBst02NZLeBDwCfC0inpzPStbULmbmLXozK7oLFi3kx59az/XrerjzV3/ii7ue4bWp1lw6oZEd3XuBVZL6qDb4AeAT0x8kaTWwBPhN3bJOYAi4LyIGT3dlj1R8INbMyqOz4yxuv/5d9C3r4vY9h5l86d/ctWUdS7o6m5oz6xZ9REwBNwN7gEPArog4IOmbkjbVPXQAeDBO/PzxceAq4JN145fvnu/KerTSmm220eG6x31MUkjqr1t2W/a8w5KuTrPGVjaS2Pret/P9G9a2bCKnodGViNgN7J627OvTbn9jhuftBHaexvqdYKxyjHMXLuAtvpiZNUHd6PAHqA4Z7JU0HBEHpz3ufGAbMFK3bA3VjZt3AsuBX0p6x/TjU2aN+uily1m++Bxuum8f121/grs2r+Pyt13YlNcu1Jmx45XjvpiZNVOjo8PfAr4NvFq37Bqqn2Bfi4hngSPZ65nNW6smcorV6F885i8bsWaadXRY0mXAioh4ZK7PNZuPVkzkFKbR1y5m5q8PtFQknQXcAdx6Gq/R8DkiZjXNnsgpTKOvXczMW/TWRLONDp8PXAL8WtJzwBXAcHZAtqGx40bPETGbrjaR86WrL2Zo/yRbdjw172vkFKbRj71QPQrtLXprov+PDmejwAPAcO3OiHg5IpZFxMqIWAk8CWyKiNHscQOSzs5Gj1cBT6V/C1ZmM03kTLz0rzm/TmEuGLN40UI2rn6zZ+itaSJiSlJtdHgBcG9tdBgYjYjhUzz3gKRdwEFgCtjqiRtrldpEzvbHx1h23tlzfr7OhK+5qtff3x+jo6N5r4aVmKR9EdE/+yOby7VtrXSqui7MrhszM5sfN3ozs5JzozczKzk3ejOzknOjNzMrOTd6M7OSc6M3Mys5N3ozs5I7406YklQB/nySu5cBLyZcHWfnl93K3N6ISH7hGdf2GZNb1uyT1vUZ1+hPRdJoHmc0Ojt9dp7vOQ/+Gzu7lbzrxsys5NzozcxKrmiN/m5nt012nu85D/4bO7tlCrWP3szM5q5oW/RmZjZHbvRmZiVXmEYv6YOSDks6IukrCXNXSHpc0kFJByRtS5Wd5S+QtF/SzxLnLpY0KOkPkg5Jek/C7Fuy3/XvJT0g6ZxU2am1a11n69BWtZ1nXRei0UtaAPwA+BCwBrhB0ppE8VPArRGxhuqXQ29NmA2wDTiUMK/mTuDRiFgNXJpqHSR1A58H+iPiEqpf8TeQIju1Nq9raKPazruuC9HogfXAkYgYj4jXgQeBa1IER8TzEfF09vM/qRZFd4psST3Ah4EdKfLqci8ArgLuAYiI1yPiHwlXoQM4V1IHsAj4a8LslNqyrqFtazu3ui5Ko+8GjtbdniBhUdZIWgmsBUYSRX4P+DLw30R5NX1ABfhR9tF6h6Qk38oeEZPAd4C/AM8DL0fEz1Nk56Bd6xrarLbzruuiNPrcSToP+CnwhYh4JUHeR4AXImJfq7Nm0AFcBvwwItYCx4Ek+48lLaG6VdsHLAe6JG1Okd2OUtd1ltl2tZ13XRel0U8CK+pu92TLkpC0kOo/w/0R8XCi2A3AJknPUf1I/z5JOxNlTwATEVHbwhuk+s+RwvuBZyOiEhH/AR4GrkyUnVo71jW0Z23nWtdFafR7gVWS+iR1Uj2IMZwiWJKo7s87FBF3pMgEiIjbIqInIlZSfb+PRUSSLYCI+BtwVNLF2aKNwMEU2VQ/2l4haVH2u99IPgfsUmi7uoa2re1c67ojVdDpiIgpSTcDe6gerb43Ig4kit8AbAF+J+m32bKvRsTuRPl5+Rxwf9aAxoEbU4RGxIikQeBpqpMh+ynp5RBc17lJXtt517UvgWBmVnJF2XVjZmbz5EZvZlZybvRmZiXnRm9mVnJu9GZmJedGb2ZWcm70ZmYl9z8A5Cpa4vt8BQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "'''\n",
        "0.7912\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net3 = outputs['sequence_output']\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    net3=keras.layers.Flatten()(net3)\n",
        "    net3=keras.layers.Dropout(0.2)(net3)\n",
        "    net3=keras.layers.Dense(3,activation=\"softmax\")(net3)\n",
        "    return keras.Model(text_input,net3)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "plot_model(model,to_file=\"/content/drive/MyDrive/ESA/checkpoint/gru4/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru4/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "model_history = model.fit(x_train, y=y_train, epochs=10, batch_size=64,\n",
        "                          validation_data=(x_dev, y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "model.evaluate(x=x_test,y=y_test)\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G183h7ynGQBy"
      },
      "source": [
        "##3.2 bert_embeddings+CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1cQfppwGZb_"
      },
      "source": [
        "###3.2.1 TextCNN_64*32_1024-256-0.7860"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkSxqLllRqlt"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "0.7860\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net3 = outputs['sequence_output']\n",
        "    r1 = keras.layers.Conv1D(1024, 3, activation=\"relu\", padding=\"same\", strides=1)(net3)\n",
        "    r1=keras.layers.BatchNormalization()(r1)\n",
        "    r1=keras.layers.Activation('relu')(r1)\n",
        "    r1 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1 = tf.keras.layers.Dropout(0.3)(r1)\n",
        "    net3=keras.layers.Dense(3,activation=\"softmax\")(r1)\n",
        "    return keras.Model(text_input,net3)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/cnn1\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/cnn1/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "model_history = model.fit(x_train, y=y_train, epochs=10, batch_size=64,\n",
        "                          validation_data=(x_dev, y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "model.evaluate(x=x_test,y=y_test)\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6eCc1L7GybC"
      },
      "source": [
        "###3.2.2 TextCNN_64*32_1024-512-256_0.7956"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ocmvDWFQjQJi",
        "outputId": "663a3e24-d86b-4209-ce65-ab9d85dec5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_10 (Functional)          {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'default': (None,   102267649   ['model_10[0][0]',               \n",
            "                                768),                             'model_10[0][1]',               \n",
            "                                 'sequence_output':               'model_10[0][2]']               \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 32, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 1024)    4096        ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 1024)     0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 32, 512)      1573376     ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 16, 512)     0           ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 16, 256)      393472      ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPooling1D)  (None, 8, 256)      0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)            (None, 2048)         0           ['max_pooling1d_4[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 2048)         0           ['flatten_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 3)            6147        ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,605,060\n",
            "Trainable params: 4,335,363\n",
            "Non-trainable params: 102,269,697\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "231/231 [==============================] - 182s 732ms/step - loss: 0.6922 - sparse_categorical_accuracy: 0.7098 - val_loss: 0.5492 - val_sparse_categorical_accuracy: 0.7864\n",
            "Epoch 2/10\n",
            "231/231 [==============================] - 162s 703ms/step - loss: 0.3906 - sparse_categorical_accuracy: 0.8505 - val_loss: 0.5534 - val_sparse_categorical_accuracy: 0.7696\n",
            "Epoch 3/10\n",
            "231/231 [==============================] - 165s 715ms/step - loss: 0.2410 - sparse_categorical_accuracy: 0.9228 - val_loss: 0.5060 - val_sparse_categorical_accuracy: 0.7984\n",
            "Epoch 4/10\n",
            "231/231 [==============================] - 182s 789ms/step - loss: 0.1452 - sparse_categorical_accuracy: 0.9658 - val_loss: 0.5229 - val_sparse_categorical_accuracy: 0.8048\n",
            "Epoch 5/10\n",
            "231/231 [==============================] - 163s 705ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.5379 - val_sparse_categorical_accuracy: 0.7964\n",
            "Epoch 6/10\n",
            "231/231 [==============================] - 162s 701ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.5886 - val_sparse_categorical_accuracy: 0.7976\n",
            "Epoch 7/10\n",
            "231/231 [==============================] - 164s 711ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.7940\n",
            "Epoch 8/10\n",
            "231/231 [==============================] - 163s 706ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.6534 - val_sparse_categorical_accuracy: 0.8008\n",
            "Epoch 9/10\n",
            "231/231 [==============================] - 163s 705ms/step - loss: 0.0390 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.6303 - val_sparse_categorical_accuracy: 0.7932\n",
            "Epoch 10/10\n",
            "231/231 [==============================] - 162s 703ms/step - loss: 0.0380 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.6389 - val_sparse_categorical_accuracy: 0.7984\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_10 (Functional)          {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'default': (None,   102267649   ['model_10[0][0]',               \n",
            "                                768),                             'model_10[0][1]',               \n",
            "                                 'sequence_output':               'model_10[0][2]']               \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 32, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 1024)    4096        ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 1024)     0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 32, 512)      1573376     ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 16, 512)     0           ['conv1d_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 16, 256)      393472      ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPooling1D)  (None, 8, 256)      0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)            (None, 2048)         0           ['max_pooling1d_4[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 2048)         0           ['flatten_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 3)            6147        ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,605,060\n",
            "Trainable params: 4,335,363\n",
            "Non-trainable params: 102,269,697\n",
            "__________________________________________________________________________________________________\n",
            "79/79 [==============================] - 20s 251ms/step - loss: 0.6825 - sparse_categorical_accuracy: 0.7956\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "'''\n",
        "0.7956\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net3 = outputs['sequence_output']\n",
        "    r1 = keras.layers.Conv1D(1024, 3, activation=\"relu\", padding=\"same\", strides=1)(net3)\n",
        "    r1=keras.layers.BatchNormalization()(r1)\n",
        "    r1=keras.layers.Activation('relu')(r1)\n",
        "    r1 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1 = tf.keras.layers.Dropout(0.2)(r1)\n",
        "    net3=keras.layers.Dense(3,activation=\"softmax\")(r1)\n",
        "    return keras.Model(text_input,net3)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/cnn2\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/cnn2/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "model_history = model.fit(x_train, y=y_train, epochs=10, batch_size=64,\n",
        "                          validation_data=(x_dev, y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "model.evaluate(x=x_test,y=y_test)\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv1ocMPqG7Fv"
      },
      "source": [
        "###3.2.3 TextCNN_64*32_1024-bn-768-0.7744"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lJgTBbB9rGJM",
        "outputId": "bc46804c-ac41-4441-cfa2-ba2fdac95787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_12 (Functional)          {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  102267649   ['model_12[0][0]',               \n",
            "                                None, 768),                       'model_12[0][1]',               \n",
            "                                 'default': (None,                'model_12[0][2]']               \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)]}                                                \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 32, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 1024)    4096        ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 1024)     0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 32, 512)      1573376     ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPooling1D)  (None, 16, 512)     0           ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 16, 256)      393472      ['max_pooling1d_5[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling1d_6 (MaxPooling1D)  (None, 8, 256)      0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 2048)         0           ['max_pooling1d_6[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 2048)         0           ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 3)            6147        ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,605,060\n",
            "Trainable params: 4,335,363\n",
            "Non-trainable params: 102,269,697\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "231/231 [==============================] - 180s 729ms/step - loss: 0.6807 - sparse_categorical_accuracy: 0.7084 - val_loss: 0.5375 - val_sparse_categorical_accuracy: 0.7888\n",
            "Epoch 2/10\n",
            "231/231 [==============================] - 170s 737ms/step - loss: 0.4363 - sparse_categorical_accuracy: 0.8265 - val_loss: 0.5136 - val_sparse_categorical_accuracy: 0.8004\n",
            "Epoch 3/10\n",
            "231/231 [==============================] - 167s 722ms/step - loss: 0.3147 - sparse_categorical_accuracy: 0.8860 - val_loss: 0.5110 - val_sparse_categorical_accuracy: 0.8016\n",
            "Epoch 4/10\n",
            "231/231 [==============================] - 193s 834ms/step - loss: 0.2187 - sparse_categorical_accuracy: 0.9301 - val_loss: 0.5262 - val_sparse_categorical_accuracy: 0.7840\n",
            "Epoch 5/10\n",
            "231/231 [==============================] - 164s 712ms/step - loss: 0.1489 - sparse_categorical_accuracy: 0.9634 - val_loss: 0.5269 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 6/10\n",
            "231/231 [==============================] - 162s 703ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.5650 - val_sparse_categorical_accuracy: 0.7832\n",
            "Epoch 7/10\n",
            "231/231 [==============================] - 163s 705ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.5622 - val_sparse_categorical_accuracy: 0.7904\n",
            "Epoch 8/10\n",
            "231/231 [==============================] - 178s 773ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9917 - val_loss: 0.6004 - val_sparse_categorical_accuracy: 0.7804\n",
            "Epoch 9/10\n",
            "231/231 [==============================] - 163s 707ms/step - loss: 0.0482 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.5997 - val_sparse_categorical_accuracy: 0.7908\n",
            "Epoch 10/10\n",
            "231/231 [==============================] - 163s 706ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.6636 - val_sparse_categorical_accuracy: 0.7708\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_12 (Functional)          {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  102267649   ['model_12[0][0]',               \n",
            "                                None, 768),                       'model_12[0][1]',               \n",
            "                                 'default': (None,                'model_12[0][2]']               \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)]}                                                \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 32, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 1024)    4096        ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 1024)     0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 32, 512)      1573376     ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPooling1D)  (None, 16, 512)     0           ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 16, 256)      393472      ['max_pooling1d_5[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling1d_6 (MaxPooling1D)  (None, 8, 256)      0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 2048)         0           ['max_pooling1d_6[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 2048)         0           ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 3)            6147        ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,605,060\n",
            "Trainable params: 4,335,363\n",
            "Non-trainable params: 102,269,697\n",
            "__________________________________________________________________________________________________\n",
            "79/79 [==============================] - 20s 249ms/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7744\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "'''\n",
        "0.7744\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net3 = outputs['sequence_output']\n",
        "    r1 = keras.layers.Conv1D(1024, 3, padding=\"same\", strides=1)(net3)\n",
        "    r1=keras.layers.BatchNormalization()(r1)\n",
        "    r1=keras.layers.Activation('relu')(r1)\n",
        "    r1 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1 = tf.keras.layers.Dropout(0.2)(r1)\n",
        "    net3=keras.layers.Dense(3,activation=\"softmax\")(r1)\n",
        "    return keras.Model(text_input,net3)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/cnn3\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/cnn3/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "model_history = model.fit(x_train, y=y_train, epochs=10, batch_size=64,\n",
        "                          validation_data=(x_dev, y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "model.evaluate(x=x_test,y=y_test)\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmBIALgLHDhG"
      },
      "source": [
        "# 四、第三组实验，测试bert_embeddings+GRU/CNN+Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jh9Xm8mtQ-W"
      },
      "source": [
        "## 4.1 bert_embeddings+GRU+Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWk7tPwitdvk",
        "outputId": "a1471b34-85be-4373-b0b1-78e5993133bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  102267649   ['model[0][0]',                  \n",
            "                                None, 768),                       'model[0][1]',                  \n",
            "                                 'default': (None,                'model[0][2]']                  \n",
            "                                768),                                                             \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768)}                                                 \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 32, 768)      3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 32, 768)      0           ['gru[0][0]',                    \n",
            "                                                                  'gru[0][0]']                    \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 768)          3543552     ['attention[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 768)          0           ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            2307        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,357,060\n",
            "Trainable params: 7,089,411\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "231/231 [==============================] - 2398s 10s/step - loss: 0.4354 - sparse_categorical_accuracy: 0.8262 - val_loss: 0.5330 - val_sparse_categorical_accuracy: 0.7824\n",
            "Epoch 2/10\n",
            "123/231 [==============>...............] - ETA: 16:18 - loss: 0.4031 - sparse_categorical_accuracy: 0.8398"
          ]
        }
      ],
      "source": [
        "'''\n",
        "\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net3 = outputs['sequence_output']\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3=keras.layers.Attention()([net3,net3])\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    net3=keras.layers.Flatten()(net3)\n",
        "    net3=keras.layers.Dropout(0.2)(net3)\n",
        "    net3=keras.layers.Dense(3,activation=\"softmax\")(net3)\n",
        "    return keras.Model(text_input,net3)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/gru_att\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru_att/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "early_stop=keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=2)\n",
        "model_history = model.fit(x_train, y=y_train, epochs=10, batch_size=64,\n",
        "                          validation_data=(x_dev, y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback,early_stop],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(x=x_test,y=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpNTVbvIuhzn"
      },
      "source": [
        "##4.2 bert_embeddings+CNN+Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmuD3P-fyOjH",
        "outputId": "5ac413bf-9832-4ad2-f7e7-cbff683dbc81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_19\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_18 (Functional)          {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 32)}                                                           \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'default': (None,   102267649   ['model_18[0][0]',               \n",
            "                                768),                             'model_18[0][1]',               \n",
            "                                 'pooled_output': (               'model_18[0][2]']               \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 32, 768),                                                \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)]}                                                \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 32, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 1024)    4096        ['conv1d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 1024)     0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 32, 512)      1573376     ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " attention_2 (Attention)        (None, 32, 512)      0           ['conv1d_13[0][0]',              \n",
            "                                                                  'conv1d_13[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 32, 256)      393472      ['attention_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling1d_7 (MaxPooling1D)  (None, 16, 256)     0           ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " flatten_9 (Flatten)            (None, 4096)         0           ['max_pooling1d_7[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 4096)         0           ['flatten_9[0][0]']              \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 3)            12291       ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 106,611,204\n",
            "Trainable params: 4,341,507\n",
            "Non-trainable params: 102,269,697\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "231/231 [==============================] - 182s 732ms/step - loss: 0.7024 - sparse_categorical_accuracy: 0.7000 - val_loss: 0.6123 - val_sparse_categorical_accuracy: 0.7484\n",
            "Epoch 2/10\n",
            "231/231 [==============================] - 188s 814ms/step - loss: 0.3983 - sparse_categorical_accuracy: 0.8493 - val_loss: 0.5336 - val_sparse_categorical_accuracy: 0.7884\n",
            "Epoch 3/10\n",
            "231/231 [==============================] - 168s 727ms/step - loss: 0.2497 - sparse_categorical_accuracy: 0.9175 - val_loss: 0.5396 - val_sparse_categorical_accuracy: 0.7836\n",
            "Epoch 4/10\n",
            "231/231 [==============================] - 167s 722ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.5610 - val_sparse_categorical_accuracy: 0.7820\n",
            "Epoch 5/10\n",
            "231/231 [==============================] - 165s 713ms/step - loss: 0.0969 - sparse_categorical_accuracy: 0.9821 - val_loss: 0.5702 - val_sparse_categorical_accuracy: 0.7924\n",
            "Epoch 6/10\n",
            "231/231 [==============================] - 164s 712ms/step - loss: 0.0665 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.6278 - val_sparse_categorical_accuracy: 0.7724\n",
            "Epoch 7/10\n",
            "231/231 [==============================] - ETA: 0s - loss: 0.0521 - sparse_categorical_accuracy: 0.9930"
          ]
        }
      ],
      "source": [
        "'''\n",
        "0.7956\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net3 = outputs['sequence_output']\n",
        "    r1 = keras.layers.Conv1D(1024, 3, activation=\"relu\", padding=\"same\", strides=1)(net3)\n",
        "    r1=keras.layers.BatchNormalization()(r1)\n",
        "    r1=keras.layers.Activation('relu')(r1)\n",
        "    r1 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1=keras.layers.Attention()([r1,r1])\n",
        "    r1 = keras.layers.Conv1D(256, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1 = tf.keras.layers.Dropout(0.2)(r1)\n",
        "    net3=keras.layers.Dense(3,activation=\"softmax\")(r1)\n",
        "    return keras.Model(text_input,net3)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/cnn_att\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/cnn_att/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "model_history = model.fit(x_train, y=y_train, epochs=10, batch_size=64,\n",
        "                          validation_data=(x_dev, y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "model.evaluate(x=x_test,y=y_test)\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gNu5n311fT0"
      },
      "source": [
        "#五、第四组实验-测试多特征组合效果-3组"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DybBvyXC1peL"
      },
      "source": [
        "##5.1 GRU+BiGRU-attention_ 0.8196"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "x2_train = np.array(train_data['content'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "x2_data=np.array(data[\"content\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "\n",
        "x_dev = x_data[:2500]\n",
        "x2_dev = x2_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "x2_test = x2_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=128):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'])\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    text_input2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text2')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder_inputs2 = bert_preprocess_model(text_input2)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    outputs2 = encoder(encoder_inputs2)\n",
        "    net3 = outputs['sequence_output']\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    net2 = outputs2['sequence_output']\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(256, activation=\"tanh\", recurrent_activation=\"sigmoid\"))(net2)\n",
        "    net=keras.layers.Concatenate(axis=-1)([net2,net3])\n",
        "    net=keras.layers.Dropout(0.2)(net)\n",
        "    net=keras.layers.Dense(3,activation=\"softmax\")(net)\n",
        "    return keras.Model([text_input,text_input2],net)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/gru_bigru\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru_bigru/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "early_stop=keras.callbacks.EarlyStopping(monitor=\"val_sparse_categorical_accuracy\",patience=4)\n",
        "model_history = model.fit([x_train,x2_train], y=y_train, epochs=20, batch_size=64,\n",
        "                          validation_data=([x_dev,x2_dev], y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback,early_stop],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(x=[x_test,x2_test],y=y_test)"
      ],
      "metadata": {
        "id": "kjaHVwQaN0Ap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f567a356-5969-4394-f47f-e30182c1b161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_6 (Functional)           {'input_word_ids':   0           ['text[0][0]',                   \n",
            "                                (None, 128),                      'text2[0][0]']                  \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'sequence_output':  102267649   ['model_6[0][0]',                \n",
            "                                 (None, 128, 768),                'model_6[0][1]',                \n",
            "                                 'encoder_outputs':               'model_6[0][2]',                \n",
            "                                 [(None, 128, 768),               'model_6[1][0]',                \n",
            "                                 (None, 128, 768),                'model_6[1][1]',                \n",
            "                                 (None, 128, 768),                'model_6[1][2]']                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " gru_12 (GRU)                   (None, 128, 768)     3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " bidirectional_7 (Bidirectional  (None, 512)         1575936     ['BERT_encoder[1][14]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_13 (GRU)                   (None, 768)          3543552     ['gru_12[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 1280)         0           ['bidirectional_7[0][0]',        \n",
            "                                                                  'gru_13[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 1280)         0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 3)            3843        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 110,934,532\n",
            "Trainable params: 8,666,883\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "231/231 [==============================] - 291s 1s/step - loss: 0.6384 - sparse_categorical_accuracy: 0.7298 - val_loss: 0.5425 - val_sparse_categorical_accuracy: 0.7752\n",
            "Epoch 2/20\n",
            "231/231 [==============================] - 276s 1s/step - loss: 0.5051 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.4998 - val_sparse_categorical_accuracy: 0.7912\n",
            "Epoch 3/20\n",
            "231/231 [==============================] - 276s 1s/step - loss: 0.4721 - sparse_categorical_accuracy: 0.8091 - val_loss: 0.4773 - val_sparse_categorical_accuracy: 0.8036\n",
            "Epoch 4/20\n",
            "231/231 [==============================] - 272s 1s/step - loss: 0.4410 - sparse_categorical_accuracy: 0.8212 - val_loss: 0.4826 - val_sparse_categorical_accuracy: 0.8076\n",
            "Epoch 5/20\n",
            "231/231 [==============================] - 275s 1s/step - loss: 0.4299 - sparse_categorical_accuracy: 0.8227 - val_loss: 0.4640 - val_sparse_categorical_accuracy: 0.8092\n",
            "Epoch 6/20\n",
            "231/231 [==============================] - 273s 1s/step - loss: 0.4051 - sparse_categorical_accuracy: 0.8382 - val_loss: 0.4680 - val_sparse_categorical_accuracy: 0.8104\n",
            "Epoch 7/20\n",
            "231/231 [==============================] - 273s 1s/step - loss: 0.3836 - sparse_categorical_accuracy: 0.8455 - val_loss: 0.4647 - val_sparse_categorical_accuracy: 0.8104\n",
            "Epoch 8/20\n",
            "231/231 [==============================] - 273s 1s/step - loss: 0.3657 - sparse_categorical_accuracy: 0.8500 - val_loss: 0.4986 - val_sparse_categorical_accuracy: 0.7860\n",
            "Epoch 9/20\n",
            "231/231 [==============================] - 273s 1s/step - loss: 0.3489 - sparse_categorical_accuracy: 0.8602 - val_loss: 0.4738 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 10/20\n",
            "231/231 [==============================] - 272s 1s/step - loss: 0.3289 - sparse_categorical_accuracy: 0.8673 - val_loss: 0.4716 - val_sparse_categorical_accuracy: 0.8080\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_6 (Functional)           {'input_word_ids':   0           ['text[0][0]',                   \n",
            "                                (None, 128),                      'text2[0][0]']                  \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'sequence_output':  102267649   ['model_6[0][0]',                \n",
            "                                 (None, 128, 768),                'model_6[0][1]',                \n",
            "                                 'encoder_outputs':               'model_6[0][2]',                \n",
            "                                 [(None, 128, 768),               'model_6[1][0]',                \n",
            "                                 (None, 128, 768),                'model_6[1][1]',                \n",
            "                                 (None, 128, 768),                'model_6[1][2]']                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " gru_12 (GRU)                   (None, 128, 768)     3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " bidirectional_7 (Bidirectional  (None, 512)         1575936     ['BERT_encoder[1][14]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_13 (GRU)                   (None, 768)          3543552     ['gru_12[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 1280)         0           ['bidirectional_7[0][0]',        \n",
            "                                                                  'gru_13[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 1280)         0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 3)            3843        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 110,934,532\n",
            "Trainable params: 8,666,883\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 35s 448ms/step - loss: 0.4700 - sparse_categorical_accuracy: 0.8196\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4700234830379486, 0.819599986076355]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur7kIcc_1x_-"
      },
      "source": [
        "##5.2 CNN-attention+BiGRU-attention_0.79040"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "x2_train = np.array(train_data['content'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "x2_data=np.array(data[\"content\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x_dev = x_data[:2500]\n",
        "x2_dev = x2_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "x2_test = x2_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=128):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'],seq_length=40)\n",
        "bert_preprocess_model2 = make_bert_preprocess_model(['text_input'],seq_length=128)\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    text_input2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text2')\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder_inputs2 = bert_preprocess_model2(text_input2)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    outputs2 = encoder(encoder_inputs2)\n",
        "    net3 = outputs['sequence_output']\n",
        "    r1 = keras.layers.Conv1D(1024, 3, activation=\"relu\", padding=\"same\", strides=1)(net3)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1=keras.layers.LayerNormalization()(r1)\n",
        "    net2 = outputs2['sequence_output']\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(256, activation=\"tanh\", recurrent_activation=\"sigmoid\"))(net2)\n",
        "    net2= keras.layers.LayerNormalization()(net2)\n",
        "    net=keras.layers.Concatenate(axis=-1)([r1,net2])\n",
        "    net=keras.layers.Dropout(0.3)(net)\n",
        "    net=keras.layers.Dense(3,activation=\"softmax\")(net)\n",
        "    return keras.Model([text_input,text_input2],net)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/cnn_bigru\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/cnn_bigru/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "early_stop=keras.callbacks.EarlyStopping(monitor=\"val_sparse_categorical_accuracy\",patience=3)\n",
        "model_history = model.fit([x_train,x2_train], y=y_train, epochs=20, batch_size=64,\n",
        "                          validation_data=([x_dev,x2_dev], y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback,early_stop],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(x=[x_test,x2_test],y=y_test)"
      ],
      "metadata": {
        "id": "7lXQvjeZReME",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d4a853f-9778-415c-a67c-c615ac63240e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_45\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_43 (Functional)          {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 40)}                                                           \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      multiple             102267649   ['model_43[0][0]',               \n",
            "                                                                  'model_43[0][1]',               \n",
            "                                                                  'model_43[0][2]',               \n",
            "                                                                  'model_44[0][0]',               \n",
            "                                                                  'model_44[0][1]',               \n",
            "                                                                  'model_44[0][2]']               \n",
            "                                                                                                  \n",
            " conv1d_49 (Conv1D)             (None, 40, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " max_pooling1d_23 (MaxPooling1D  (None, 20, 1024)    0           ['conv1d_49[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " conv1d_50 (Conv1D)             (None, 20, 512)      1573376     ['max_pooling1d_23[0][0]']       \n",
            "                                                                                                  \n",
            " model_44 (Functional)          {'input_type_ids':   0           ['text2[0][0]']                  \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " max_pooling1d_24 (MaxPooling1D  (None, 10, 512)     0           ['conv1d_50[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_51 (Conv1D)             (None, 10, 128)      196736      ['max_pooling1d_24[0][0]']       \n",
            "                                                                                                  \n",
            " bidirectional_41 (Bidirectiona  (None, 128, 1536)   7087104     ['BERT_encoder[1][14]']          \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling1d_25 (MaxPooling1D  (None, 5, 128)      0           ['conv1d_51[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_42 (Bidirectiona  (None, 128, 1536)   10626048    ['bidirectional_41[0][0]']       \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " flatten_13 (Flatten)           (None, 640)          0           ['max_pooling1d_25[0][0]']       \n",
            "                                                                                                  \n",
            " bidirectional_43 (Bidirectiona  (None, 512)         2755584     ['bidirectional_42[0][0]']       \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " layer_normalization_27 (LayerN  (None, 640)         1280        ['flatten_13[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " layer_normalization_28 (LayerN  (None, 512)         1024        ['bidirectional_43[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 1152)         0           ['layer_normalization_27[0][0]', \n",
            "                                                                  'layer_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 1152)         0           ['concatenate_15[0][0]']         \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 3)            3459        ['dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 126,872,580\n",
            "Trainable params: 24,604,931\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "231/231 [==============================] - 273s 1s/step - loss: 0.7314 - sparse_categorical_accuracy: 0.7051 - val_loss: 0.5260 - val_sparse_categorical_accuracy: 0.7804\n",
            "Epoch 2/20\n",
            "231/231 [==============================] - 250s 1s/step - loss: 0.4989 - sparse_categorical_accuracy: 0.7984 - val_loss: 0.5603 - val_sparse_categorical_accuracy: 0.7848\n",
            "Epoch 3/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.4013 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.5274 - val_sparse_categorical_accuracy: 0.7832\n",
            "Epoch 4/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.2834 - sparse_categorical_accuracy: 0.8905 - val_loss: 0.5626 - val_sparse_categorical_accuracy: 0.7900\n",
            "Epoch 5/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.1690 - sparse_categorical_accuracy: 0.9381 - val_loss: 0.6263 - val_sparse_categorical_accuracy: 0.7876\n",
            "Epoch 6/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.0876 - sparse_categorical_accuracy: 0.9748 - val_loss: 0.6759 - val_sparse_categorical_accuracy: 0.7900\n",
            "Epoch 7/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.0524 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.7920\n",
            "Epoch 8/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.0381 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.6639 - val_sparse_categorical_accuracy: 0.7936\n",
            "Epoch 9/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.7026 - val_sparse_categorical_accuracy: 0.7908\n",
            "Epoch 10/20\n",
            "231/231 [==============================] - 250s 1s/step - loss: 0.0236 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.7210 - val_sparse_categorical_accuracy: 0.7880\n",
            "Epoch 11/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.0155 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.7972\n",
            "Epoch 12/20\n",
            "231/231 [==============================] - 250s 1s/step - loss: 0.0115 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.7553 - val_sparse_categorical_accuracy: 0.7984\n",
            "Epoch 13/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.8489 - val_sparse_categorical_accuracy: 0.7868\n",
            "Epoch 14/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.0078 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.7659 - val_sparse_categorical_accuracy: 0.7912\n",
            "Epoch 15/20\n",
            "231/231 [==============================] - 249s 1s/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.7771 - val_sparse_categorical_accuracy: 0.7936\n",
            "Model: \"model_45\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_43 (Functional)          {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 40)}                                                           \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      multiple             102267649   ['model_43[0][0]',               \n",
            "                                                                  'model_43[0][1]',               \n",
            "                                                                  'model_43[0][2]',               \n",
            "                                                                  'model_44[0][0]',               \n",
            "                                                                  'model_44[0][1]',               \n",
            "                                                                  'model_44[0][2]']               \n",
            "                                                                                                  \n",
            " conv1d_49 (Conv1D)             (None, 40, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " max_pooling1d_23 (MaxPooling1D  (None, 20, 1024)    0           ['conv1d_49[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " conv1d_50 (Conv1D)             (None, 20, 512)      1573376     ['max_pooling1d_23[0][0]']       \n",
            "                                                                                                  \n",
            " model_44 (Functional)          {'input_type_ids':   0           ['text2[0][0]']                  \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " max_pooling1d_24 (MaxPooling1D  (None, 10, 512)     0           ['conv1d_50[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv1d_51 (Conv1D)             (None, 10, 128)      196736      ['max_pooling1d_24[0][0]']       \n",
            "                                                                                                  \n",
            " bidirectional_41 (Bidirectiona  (None, 128, 1536)   7087104     ['BERT_encoder[1][14]']          \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling1d_25 (MaxPooling1D  (None, 5, 128)      0           ['conv1d_51[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_42 (Bidirectiona  (None, 128, 1536)   10626048    ['bidirectional_41[0][0]']       \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " flatten_13 (Flatten)           (None, 640)          0           ['max_pooling1d_25[0][0]']       \n",
            "                                                                                                  \n",
            " bidirectional_43 (Bidirectiona  (None, 512)         2755584     ['bidirectional_42[0][0]']       \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " layer_normalization_27 (LayerN  (None, 640)         1280        ['flatten_13[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " layer_normalization_28 (LayerN  (None, 512)         1024        ['bidirectional_43[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 1152)         0           ['layer_normalization_27[0][0]', \n",
            "                                                                  'layer_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 1152)         0           ['concatenate_15[0][0]']         \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 3)            3459        ['dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 126,872,580\n",
            "Trainable params: 24,604,931\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 30s 374ms/step - loss: 0.4939 - sparse_categorical_accuracy: 0.7904\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4939192235469818, 0.7904000282287598]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9yxMWWv18Hz"
      },
      "source": [
        "##5.3 GRU-attention+CNN-attention+BiGRU-attention_0.8020"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "x2_train = np.array(train_data['content'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x2_data = np.array(data['content'])\n",
        "x_dev = x_data[:2500]\n",
        "x2_dev = x2_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "x2_test = x2_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'],seq_length=40)\n",
        "bert_preprocess_model2 = make_bert_preprocess_model(['text_input'],seq_length=128)\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    text_input2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text2')\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder_inputs2 = bert_preprocess_model2(text_input2)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    outputs2 = encoder(encoder_inputs2)\n",
        "    net3 = outputs['sequence_output']\n",
        "    r1 = keras.layers.Conv1D(1024, 3, activation=\"relu\", padding=\"valid\", strides=1)(net3)\n",
        "    r1=keras.layers.BatchNormalization()(r1)\n",
        "    r1 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"valid\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"valid\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1=keras.layers.Attention()([r1,r1])\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1=keras.layers.LayerNormalization()(r1)\n",
        "\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    net3 = keras.layers.LayerNormalization()(net3)\n",
        "\n",
        "\n",
        "\n",
        "    net2 = outputs2['sequence_output']\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(256, activation=\"tanh\", recurrent_activation=\"sigmoid\"))(net2)\n",
        "    net2= keras.layers.LayerNormalization()(net2)\n",
        "    net=keras.layers.Concatenate(axis=-1)([r1,net2,net3])\n",
        "    net=keras.layers.Dropout(0.3)(net)\n",
        "    net=keras.layers.Dense(3,activation=\"softmax\")(net)\n",
        "    return keras.Model([text_input,text_input2],net)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "early_stop=keras.callbacks.EarlyStopping(monitor=\"val_sparse_categorical_accuracy\",patience=2)\n",
        "model_history = model.fit([x_train,x2_train], y=y_train, epochs=20, batch_size=64,\n",
        "                          validation_data=([x_dev,x2_dev], y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback,early_stop],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(x=[x_test,x2_test],y=y_test)"
      ],
      "metadata": {
        "id": "x-QpnH7rjouL",
        "outputId": "e39675a4-87d4-45ab-f19c-b373160add2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_2 (Functional)           {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 40)}                                                           \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      multiple             102267649   ['model_2[0][0]',                \n",
            "                                                                  'model_2[0][1]',                \n",
            "                                                                  'model_2[0][2]',                \n",
            "                                                                  'model_3[0][0]',                \n",
            "                                                                  'model_3[0][1]',                \n",
            "                                                                  'model_3[0][2]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 38, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 38, 1024)    4096        ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 36, 512)      1573376     ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 18, 512)      0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " model_3 (Functional)           {'input_word_ids':   0           ['text2[0][0]']                  \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 16, 128)      196736      ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 8, 128)      0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 128, 1536)    7087104     ['BERT_encoder[1][14]']          \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 40, 768)      3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 8, 128)       0           ['max_pooling1d_1[0][0]',        \n",
            "                                                                  'max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 128, 1024)   6297600     ['bidirectional[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 40, 512)      1969152     ['gru[0][0]']                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1024)         0           ['attention[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 512)         1969152     ['bidirectional_1[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    (None, 512)          1575936     ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 1024)        2048        ['flatten[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 512)         1024        ['bidirectional_2[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 512)         1024        ['gru_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 2048)         0           ['layer_normalization[0][0]',    \n",
            "                                                                  'layer_normalization_2[0][0]',  \n",
            "                                                                  'layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            6147        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 128,854,916\n",
            "Trainable params: 26,585,219\n",
            "Non-trainable params: 102,269,697\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "231/231 [==============================] - 286s 1s/step - loss: 0.7312 - sparse_categorical_accuracy: 0.7146 - val_loss: 0.5774 - val_sparse_categorical_accuracy: 0.7736\n",
            "Epoch 2/20\n",
            "231/231 [==============================] - 251s 1s/step - loss: 0.4729 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.5615 - val_sparse_categorical_accuracy: 0.7752\n",
            "Epoch 3/20\n",
            "231/231 [==============================] - 247s 1s/step - loss: 0.3251 - sparse_categorical_accuracy: 0.8713 - val_loss: 0.5736 - val_sparse_categorical_accuracy: 0.7840\n",
            "Epoch 4/20\n",
            "231/231 [==============================] - 247s 1s/step - loss: 0.2108 - sparse_categorical_accuracy: 0.9180 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.7892\n",
            "Epoch 5/20\n",
            "231/231 [==============================] - 246s 1s/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9654 - val_loss: 0.6390 - val_sparse_categorical_accuracy: 0.7872\n",
            "Epoch 6/20\n",
            "231/231 [==============================] - 247s 1s/step - loss: 0.0679 - sparse_categorical_accuracy: 0.9838 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.7908\n",
            "Epoch 7/20\n",
            "231/231 [==============================] - 246s 1s/step - loss: 0.0434 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.7940\n",
            "Epoch 8/20\n",
            "231/231 [==============================] - 246s 1s/step - loss: 0.0300 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.7094 - val_sparse_categorical_accuracy: 0.7972\n",
            "Epoch 9/20\n",
            "231/231 [==============================] - 246s 1s/step - loss: 0.0233 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.7403 - val_sparse_categorical_accuracy: 0.7788\n",
            "Epoch 10/20\n",
            "231/231 [==============================] - 246s 1s/step - loss: 0.0160 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.7732 - val_sparse_categorical_accuracy: 0.7900\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_2 (Functional)           {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 40)}                                                           \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      multiple             102267649   ['model_2[0][0]',                \n",
            "                                                                  'model_2[0][1]',                \n",
            "                                                                  'model_2[0][2]',                \n",
            "                                                                  'model_3[0][0]',                \n",
            "                                                                  'model_3[0][1]',                \n",
            "                                                                  'model_3[0][2]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 38, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 38, 1024)    4096        ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 36, 512)      1573376     ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 18, 512)      0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " model_3 (Functional)           {'input_word_ids':   0           ['text2[0][0]']                  \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 16, 128)      196736      ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 8, 128)      0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 128, 1536)    7087104     ['BERT_encoder[1][14]']          \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 40, 768)      3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 8, 128)       0           ['max_pooling1d_1[0][0]',        \n",
            "                                                                  'max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 128, 1024)   6297600     ['bidirectional[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    (None, 40, 512)      1969152     ['gru[0][0]']                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1024)         0           ['attention[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 512)         1969152     ['bidirectional_1[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    (None, 512)          1575936     ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 1024)        2048        ['flatten[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 512)         1024        ['bidirectional_2[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 512)         1024        ['gru_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 2048)         0           ['layer_normalization[0][0]',    \n",
            "                                                                  'layer_normalization_2[0][0]',  \n",
            "                                                                  'layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            6147        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 128,854,916\n",
            "Trainable params: 26,585,219\n",
            "Non-trainable params: 102,269,697\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 30s 373ms/step - loss: 0.4958 - sparse_categorical_accuracy: 0.8020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4957854151725769, 0.8019999861717224]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.3.4CNN_GRU_BIGRU_0.8048"
      ],
      "metadata": {
        "id": "qFHGIlyVRjSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "x2_train = np.array(train_data['content'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x2_data = np.array(data['content'])\n",
        "x_dev = x_data[:2500]\n",
        "x2_dev = x2_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "x2_test = x2_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'],seq_length=40)\n",
        "bert_preprocess_model2 = make_bert_preprocess_model(['text_input'],seq_length=128)\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    text_input2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text2')\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder_inputs2 = bert_preprocess_model2(text_input2)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    outputs2 = encoder(encoder_inputs2)\n",
        "    net3 = outputs['sequence_output']\n",
        "    r1 = keras.layers.Conv1D(1024, 3, activation=\"relu\", padding=\"valid\", strides=1)(net3)\n",
        "    r1=keras.layers.BatchNormalization()(r1)\n",
        "    r1 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"valid\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"valid\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1=keras.layers.Attention()([r1,r1])\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1=keras.layers.LayerNormalization()(r1)\n",
        "\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    net3 = keras.layers.LayerNormalization()(net3)\n",
        "\n",
        "\n",
        "\n",
        "    net2 = outputs2['sequence_output']\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\"))(net2)\n",
        "    net2= keras.layers.LayerNormalization()(net2)\n",
        "    net=keras.layers.Concatenate(axis=-1)([r1,net2,net3])\n",
        "    net=keras.layers.Dropout(0.3)(net)\n",
        "    net=keras.layers.Dense(3,activation=\"softmax\")(net)\n",
        "    return keras.Model([text_input,text_input2],net)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru2\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru2/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "early_stop=keras.callbacks.EarlyStopping(monitor=\"val_sparse_categorical_accuracy\",patience=4)\n",
        "model_history = model.fit([x_train,x2_train], y=y_train, epochs=20, batch_size=64,\n",
        "                          validation_data=([x_dev,x2_dev], y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback,early_stop],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(x=[x_test,x2_test],y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YFdjCtToRnJ2",
        "outputId": "6ce7b941-9678-4245-8b93-e8b8ec5af291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_11 (Functional)          {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 40)}                                                           \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      multiple             102267649   ['model_11[0][0]',               \n",
            "                                                                  'model_11[0][1]',               \n",
            "                                                                  'model_11[0][2]',               \n",
            "                                                                  'model_12[0][0]',               \n",
            "                                                                  'model_12[0][1]',               \n",
            "                                                                  'model_12[0][2]']               \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 38, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 38, 1024)    4096        ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 36, 512)      1573376     ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " max_pooling1d_6 (MaxPooling1D)  (None, 18, 512)     0           ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " model_12 (Functional)          {'input_word_ids':   0           ['text2[0][0]']                  \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 16, 64)       98368       ['max_pooling1d_6[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling1d_7 (MaxPooling1D)  (None, 8, 64)       0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_9 (Bidirectional  (None, 128, 1536)   7087104     ['BERT_encoder[1][14]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_18 (GRU)                   (None, 40, 768)      3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " attention_3 (Attention)        (None, 8, 64)        0           ['max_pooling1d_7[0][0]',        \n",
            "                                                                  'max_pooling1d_7[0][0]']        \n",
            "                                                                                                  \n",
            " bidirectional_10 (Bidirectiona  (None, 128, 1024)   6297600     ['bidirectional_9[0][0]']        \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " gru_19 (GRU)                   (None, 40, 512)      1969152     ['gru_18[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 512)          0           ['attention_3[0][0]']            \n",
            "                                                                                                  \n",
            " bidirectional_11 (Bidirectiona  (None, 1024)        4724736     ['bidirectional_10[0][0]']       \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " gru_20 (GRU)                   (None, 512)          1575936     ['gru_19[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 512)         1024        ['flatten_3[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 1024)        2048        ['bidirectional_11[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " layer_normalization_10 (LayerN  (None, 512)         1024        ['gru_20[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 2048)         0           ['layer_normalization_9[0][0]',  \n",
            "                                                                  'layer_normalization_11[0][0]', \n",
            "                                                                  'layer_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 2048)         0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 3)            6147        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 131,512,132\n",
            "Trainable params: 29,242,435\n",
            "Non-trainable params: 102,269,697\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "231/231 [==============================] - 285s 1s/step - loss: 0.7536 - sparse_categorical_accuracy: 0.7157 - val_loss: 0.5226 - val_sparse_categorical_accuracy: 0.7988\n",
            "Epoch 2/20\n",
            "231/231 [==============================] - 255s 1s/step - loss: 0.4910 - sparse_categorical_accuracy: 0.8034 - val_loss: 0.5448 - val_sparse_categorical_accuracy: 0.7816\n",
            "Epoch 3/20\n",
            "231/231 [==============================] - 258s 1s/step - loss: 0.3404 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.5118 - val_sparse_categorical_accuracy: 0.8068\n",
            "Epoch 4/20\n",
            "231/231 [==============================] - 255s 1s/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9149 - val_loss: 0.5597 - val_sparse_categorical_accuracy: 0.7960\n",
            "Epoch 5/20\n",
            "231/231 [==============================] - 255s 1s/step - loss: 0.1358 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.5535 - val_sparse_categorical_accuracy: 0.8036\n",
            "Epoch 6/20\n",
            "231/231 [==============================] - 255s 1s/step - loss: 0.0869 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.6321 - val_sparse_categorical_accuracy: 0.8012\n",
            "Epoch 7/20\n",
            "231/231 [==============================] - 255s 1s/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.6321 - val_sparse_categorical_accuracy: 0.8032\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_11 (Functional)          {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 40),                                                       \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 40)}                                                           \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      multiple             102267649   ['model_11[0][0]',               \n",
            "                                                                  'model_11[0][1]',               \n",
            "                                                                  'model_11[0][2]',               \n",
            "                                                                  'model_12[0][0]',               \n",
            "                                                                  'model_12[0][1]',               \n",
            "                                                                  'model_12[0][2]']               \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 38, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 38, 1024)    4096        ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 36, 512)      1573376     ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " max_pooling1d_6 (MaxPooling1D)  (None, 18, 512)     0           ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " model_12 (Functional)          {'input_word_ids':   0           ['text2[0][0]']                  \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 16, 64)       98368       ['max_pooling1d_6[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling1d_7 (MaxPooling1D)  (None, 8, 64)       0           ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_9 (Bidirectional  (None, 128, 1536)   7087104     ['BERT_encoder[1][14]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_18 (GRU)                   (None, 40, 768)      3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " attention_3 (Attention)        (None, 8, 64)        0           ['max_pooling1d_7[0][0]',        \n",
            "                                                                  'max_pooling1d_7[0][0]']        \n",
            "                                                                                                  \n",
            " bidirectional_10 (Bidirectiona  (None, 128, 1024)   6297600     ['bidirectional_9[0][0]']        \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " gru_19 (GRU)                   (None, 40, 512)      1969152     ['gru_18[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 512)          0           ['attention_3[0][0]']            \n",
            "                                                                                                  \n",
            " bidirectional_11 (Bidirectiona  (None, 1024)        4724736     ['bidirectional_10[0][0]']       \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " gru_20 (GRU)                   (None, 512)          1575936     ['gru_19[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 512)         1024        ['flatten_3[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 1024)        2048        ['bidirectional_11[0][0]']       \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " layer_normalization_10 (LayerN  (None, 512)         1024        ['gru_20[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 2048)         0           ['layer_normalization_9[0][0]',  \n",
            "                                                                  'layer_normalization_11[0][0]', \n",
            "                                                                  'layer_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 2048)         0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 3)            6147        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 131,512,132\n",
            "Trainable params: 29,242,435\n",
            "Non-trainable params: 102,269,697\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 30s 382ms/step - loss: 0.4924 - sparse_categorical_accuracy: 0.8048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4923635721206665, 0.8047999739646912]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "'''\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "#os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "x2_train = np.array(train_data['content'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x2_data = np.array(data['content'])\n",
        "x_dev = x_data[:2500]\n",
        "x2_dev = x2_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "x2_test = x2_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=32):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft) for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'],seq_length=64)\n",
        "bert_preprocess_model2 = make_bert_preprocess_model(['text_input'],seq_length=128)\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    text_input2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text2')\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder_inputs2 = bert_preprocess_model2(text_input2)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    outputs2 = encoder(encoder_inputs2)\n",
        "    net3 = outputs['sequence_output']\n",
        "    r1 = keras.layers.Conv1D(1024, 3, activation=\"relu\", padding=\"valid\", strides=1)(net3)\n",
        "    r1 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"valid\", strides=1)(r1)\n",
        "    r1 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"valid\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1 = keras.layers.Dropout(0.2)(r1)\n",
        "    r1 = keras.layers.Dense(512,activation=\"softmax\")(r1)\n",
        "\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\")(net3)\n",
        "    net3 = keras.layers.Dense(512, activation=\"softmax\")(net3)\n",
        "\n",
        "\n",
        "\n",
        "    net2 = outputs2['sequence_output']\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(768, activation=\"tanh\", recurrent_activation=\"sigmoid\"))(net2)\n",
        "    net2=keras.layers.Dropout(0.2)(net2)\n",
        "    net2 = keras.layers.Dense(512, activation=\"softmax\")(net2)\n",
        "    net=keras.layers.Concatenate(axis=-1)([r1,net2,net3])\n",
        "    net=keras.layers.Dropout(0.2)(net)\n",
        "    net=keras.layers.Dense(3,activation=\"softmax\")(net)\n",
        "    return keras.Model([text_input,text_input2],net)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru3\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru3/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "early_stop=keras.callbacks.EarlyStopping(monitor=\"val_sparse_categorical_accuracy\",patience=4)\n",
        "model_history = model.fit([x_train,x2_train], y=y_train, epochs=20, batch_size=64,\n",
        "                          validation_data=([x_dev,x2_dev], y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback,early_stop],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(x=[x_test,x2_test],y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PejZ3b1Rk3eG",
        "outputId": "f39ba601-4dd6-4d51-f803-3eb10bea0eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_33\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_31 (Functional)          {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 64),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 64),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 64)}                                                       \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      multiple             102267649   ['model_31[0][0]',               \n",
            "                                                                  'model_31[0][1]',               \n",
            "                                                                  'model_31[0][2]',               \n",
            "                                                                  'model_32[0][0]',               \n",
            "                                                                  'model_32[0][1]',               \n",
            "                                                                  'model_32[0][2]']               \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " conv1d_27 (Conv1D)             (None, 62, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " model_32 (Functional)          {'input_mask': (Non  0           ['text2[0][0]']                  \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " conv1d_28 (Conv1D)             (None, 60, 512)      1573376     ['conv1d_27[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_29 (Conv1D)             (None, 58, 128)      196736      ['conv1d_28[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_27 (Bidirectiona  (None, 128, 1536)   7087104     ['BERT_encoder[1][14]']          \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling1d_17 (MaxPooling1D  (None, 29, 128)     0           ['conv1d_29[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " bidirectional_28 (Bidirectiona  (None, 128, 1536)   10626048    ['bidirectional_27[0][0]']       \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " flatten_9 (Flatten)            (None, 3712)         0           ['max_pooling1d_17[0][0]']       \n",
            "                                                                                                  \n",
            " bidirectional_29 (Bidirectiona  (None, 1536)        10626048    ['bidirectional_28[0][0]']       \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " gru_53 (GRU)                   (None, 64, 768)      3543552     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 3712)         0           ['flatten_9[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 1536)         0           ['bidirectional_29[0][0]']       \n",
            "                                                                                                  \n",
            " gru_54 (GRU)                   (None, 768)          3543552     ['gru_53[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 512)          1901056     ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 512)          786944      ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 512)          393728      ['gru_54[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 1536)         0           ['dense_13[0][0]',               \n",
            "                                                                  'dense_15[0][0]',               \n",
            "                                                                  'dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 1536)         0           ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 3)            4611        ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 144,910,724\n",
            "Trainable params: 42,643,075\n",
            "Non-trainable params: 102,267,649\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            " 40/231 [====>.........................] - ETA: 3:31 - loss: 1.0798 - sparse_categorical_accuracy: 0.4594"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-690f91190ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m                           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2_dev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                           callbacks=[model_callback,early_stop],shuffle=True)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;31m#model.save_weights(checkpoint_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3PCltF32E12"
      },
      "source": [
        "#六、第五组实验-对比多路卷积神经网络和全连接层融合特征效果"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jQ38aI2qjv_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6mA6Lcf2SZ_"
      },
      "source": [
        "##6.1 GRU-attention+CNN-attention+BiGRU-attention+MulCNN_0.8208"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "# os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "\n",
        "# 读取数据\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "x2_train = np.array(train_data['content'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x2_data = np.array(data['content'])\n",
        "x_dev = x_data[:2500]\n",
        "x2_dev = x2_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "x2_test = x2_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=50):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
        "        for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'],seq_length=128)\n",
        "bert_preprocess_model2 = make_bert_preprocess_model(['text_input'],seq_length=128)\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    text_input2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text2')\n",
        "\n",
        "    # preprocessing_layer = hub.KerasLayer(preprocessor, name='preprocessing')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False,\n",
        "                             name='BERT_encoder')\n",
        "    # 输入batch*seq 输出batch*seq*768\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    # 输入batch*seq*768,输出batch*seq*512\n",
        "    net = outputs['sequence_output']\n",
        "    net = keras.layers.Conv1D(1024, 3, activation=\"relu\", padding=\"same\", strides=1)(net)\n",
        "    net = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net)\n",
        "    net = keras.layers.Attention()([net, net])\n",
        "    # 输入batch*seq*768,输出batch*seq*512\n",
        "    net3 = outputs['sequence_output']\n",
        "    net3 = keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.Attention()([net3, net3])\n",
        "\n",
        "    # 输入batch*seq*768,输出batch*seq*512\n",
        "    encoder_inputs2 = bert_preprocess_model2(text_input2)\n",
        "    encoder2 = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=False, name='BERT_encoder2')\n",
        "    outputs2 = encoder2(encoder_inputs2)\n",
        "    net2 = outputs2['sequence_output']\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(256, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Attention()([net2, net2])\n",
        "    # 输入3*batch*seq*512,输出batch*seq*1536\n",
        "    net4 = keras.layers.Concatenate(axis=-1)([net, net2, net3])\n",
        "    # 输入2*batch*seq*512,输出batch*seq*1024\n",
        "    net5 = keras.layers.Concatenate(axis=-1)([net, net2])\n",
        "    net6 = keras.layers.Concatenate(axis=-1)([net2, net3])\n",
        "    net7 = keras.layers.Concatenate(axis=-1)([net, net3])\n",
        "    # 输入batch*seq*1536输出batch*seq/2*64\n",
        "    r1 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(net)\n",
        "    r1 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1 = tf.keras.layers.Dropout(0.2)(r1)\n",
        "    r1 = keras.layers.Dense(128, activation='relu')(r1)\n",
        "\n",
        "    r2 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(net2)\n",
        "    r2 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r2)\n",
        "    r2 = keras.layers.MaxPooling1D(2)(r2)\n",
        "    r2 = keras.layers.Flatten()(r2)\n",
        "    r2 = tf.keras.layers.Dropout(0.2)(r2)\n",
        "    r2 = keras.layers.Dense(128, activation='relu')(r2)\n",
        "\n",
        "    r3 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(net3)\n",
        "    r3 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r3)\n",
        "    r3 = keras.layers.MaxPooling1D(2)(r3)\n",
        "    r3 = keras.layers.Flatten()(r3)\n",
        "    r3 = tf.keras.layers.Dropout(0.2)(r3)\n",
        "    r3 = keras.layers.Dense(128, activation='relu')(r3)\n",
        "\n",
        "    r4 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net4)\n",
        "    r4 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(r4)\n",
        "    r4 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r4)\n",
        "    r4 = keras.layers.MaxPooling1D(2)(r4)\n",
        "    r4 = keras.layers.Flatten()(r4)\n",
        "    r4 = tf.keras.layers.Dropout(0.2)(r4)\n",
        "    r4 = keras.layers.Dense(128, activation='relu')(r4)\n",
        "\n",
        "    r5 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net5)\n",
        "    r5 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(r5)\n",
        "    r5 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r5)\n",
        "    r5 = keras.layers.MaxPooling1D(2)(r5)\n",
        "    r5 = keras.layers.Flatten()(r5)\n",
        "    r5 = tf.keras.layers.Dropout(0.2)(r5)\n",
        "    r5 = keras.layers.Dense(128, activation='relu')(r5)\n",
        "\n",
        "    r6 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net6)\n",
        "    r6 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(r6)\n",
        "    r6 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r6)\n",
        "    r6 = keras.layers.MaxPooling1D(2)(r6)\n",
        "    r6 = keras.layers.Flatten()(r6)\n",
        "    r6 = tf.keras.layers.Dropout(0.2)(r6)\n",
        "    r6 = keras.layers.Dense(128, activation='relu')(r6)\n",
        "\n",
        "    r7 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net7)\n",
        "    r7 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(r7)\n",
        "    r7 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r7)\n",
        "    r7 = keras.layers.MaxPooling1D(2)(r7)\n",
        "    r7 = keras.layers.Flatten()(r7)\n",
        "    r7 = tf.keras.layers.Dropout(0.2)(r7)\n",
        "    r7 = keras.layers.Dense(128, activation='relu')(r7)\n",
        "\n",
        "    # r8 = outputs2['pooled_output']\n",
        "    # r8 = keras.layers.Dropout(0.2)(r8)\n",
        "    # r8 = keras.layers.Dense(64, activation='relu')(r8)\n",
        "\n",
        "    # r9 = outputs['pooled_output']\n",
        "    # r9 = keras.layers.Dropout(0.2)(r9)\n",
        "    # r9 = keras.layers.Dense(64, activation='relu')(r9)\n",
        "\n",
        "    res = keras.layers.Concatenate(axis=-1)([r1, r2, r3, r4, r5, r6, r7])\n",
        "    res = keras.layers.Dropout(0.2)(res)\n",
        "    res = keras.layers.Dense(3, activation='softmax')(res)\n",
        "    return keras.Model([text_input, text_input2], res)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru_CNN\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru_CNN/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "early_stop=keras.callbacks.EarlyStopping(monitor=\"val_sparse_categorical_accuracy\",patience=4)\n",
        "model_history = model.fit([x_train,x2_train], y=y_train, epochs=20, batch_size=64,\n",
        "                          validation_data=([x_dev,x2_dev], y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback,early_stop],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(x=[x_test,x2_test],y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Om2CgpOhfqsN",
        "outputId": "f7b42c2c-aa12-40af-c04c-ee521bfd889f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_42\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_40 (Functional)          {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'sequence_output':  102267649   ['model_40[0][0]',               \n",
            "                                 (None, 128, 768),                'model_40[0][1]',               \n",
            "                                 'encoder_outputs':               'model_40[0][2]']               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " model_41 (Functional)          {'input_mask': (Non  0           ['text2[0][0]']                  \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " conv1d_35 (Conv1D)             (None, 128, 1024)    2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " BERT_encoder2 (KerasLayer)     {'encoder_outputs':  102267649   ['model_41[0][0]',               \n",
            "                                 [(None, 128, 768),               'model_41[0][1]',               \n",
            "                                 (None, 128, 768),                'model_41[0][2]']               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 128, 512)     1573376     ['conv1d_35[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_32 (Bidirectiona  (None, 128, 512)    1575936     ['BERT_encoder2[0][14]']         \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " gru_62 (GRU)                   (None, 128, 512)     1969152     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " attention_13 (Attention)       (None, 128, 512)     0           ['conv1d_36[0][0]',              \n",
            "                                                                  'conv1d_36[0][0]']              \n",
            "                                                                                                  \n",
            " attention_15 (Attention)       (None, 128, 512)     0           ['bidirectional_32[0][0]',       \n",
            "                                                                  'bidirectional_32[0][0]']       \n",
            "                                                                                                  \n",
            " attention_14 (Attention)       (None, 128, 512)     0           ['gru_62[0][0]',                 \n",
            "                                                                  'gru_62[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 128, 1536)    0           ['attention_13[0][0]',           \n",
            "                                                                  'attention_15[0][0]',           \n",
            "                                                                  'attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 128, 1024)    0           ['attention_13[0][0]',           \n",
            "                                                                  'attention_15[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 128, 1024)    0           ['attention_15[0][0]',           \n",
            "                                                                  'attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 128, 1024)    0           ['attention_13[0][0]',           \n",
            "                                                                  'attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_43 (Conv1D)             (None, 128, 512)     2359808     ['concatenate_12[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_46 (Conv1D)             (None, 128, 512)     1573376     ['concatenate_13[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_49 (Conv1D)             (None, 128, 512)     1573376     ['concatenate_14[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_52 (Conv1D)             (None, 128, 512)     1573376     ['concatenate_15[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 128, 128)     196736      ['attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_39 (Conv1D)             (None, 128, 128)     196736      ['attention_15[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_41 (Conv1D)             (None, 128, 128)     196736      ['attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_44 (Conv1D)             (None, 128, 128)     196736      ['conv1d_43[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_47 (Conv1D)             (None, 128, 128)     196736      ['conv1d_46[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_50 (Conv1D)             (None, 128, 128)     196736      ['conv1d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_53 (Conv1D)             (None, 128, 128)     196736      ['conv1d_52[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_38 (Conv1D)             (None, 128, 64)      24640       ['conv1d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_40 (Conv1D)             (None, 128, 64)      24640       ['conv1d_39[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_42 (Conv1D)             (None, 128, 64)      24640       ['conv1d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_45 (Conv1D)             (None, 128, 64)      24640       ['conv1d_44[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_48 (Conv1D)             (None, 128, 64)      24640       ['conv1d_47[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_51 (Conv1D)             (None, 128, 64)      24640       ['conv1d_50[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_54 (Conv1D)             (None, 128, 64)      24640       ['conv1d_53[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_18 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_38[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_19 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_40[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_20 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_42[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_21 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_45[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_22 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_48[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_23 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_51[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_24 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_54[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_10 (Flatten)           (None, 4096)         0           ['max_pooling1d_18[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_11 (Flatten)           (None, 4096)         0           ['max_pooling1d_19[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_12 (Flatten)           (None, 4096)         0           ['max_pooling1d_20[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_13 (Flatten)           (None, 4096)         0           ['max_pooling1d_21[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_14 (Flatten)           (None, 4096)         0           ['max_pooling1d_22[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_15 (Flatten)           (None, 4096)         0           ['max_pooling1d_23[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_16 (Flatten)           (None, 4096)         0           ['max_pooling1d_24[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 4096)         0           ['flatten_10[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 4096)         0           ['flatten_11[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 4096)         0           ['flatten_12[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 4096)         0           ['flatten_13[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 4096)         0           ['flatten_14[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 4096)         0           ['flatten_15[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 4096)         0           ['flatten_16[0][0]']             \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 128)          524416      ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 128)          524416      ['dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 128)          524416      ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 128)          524416      ['dropout_17[0][0]']             \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 128)          524416      ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 128)          524416      ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 128)          524416      ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, 896)          0           ['dense_17[0][0]',               \n",
            "                                                                  'dense_18[0][0]',               \n",
            "                                                                  'dense_19[0][0]',               \n",
            "                                                                  'dense_20[0][0]',               \n",
            "                                                                  'dense_21[0][0]',               \n",
            "                                                                  'dense_22[0][0]',               \n",
            "                                                                  'dense_23[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 896)          0           ['concatenate_16[0][0]']         \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 3)            2691        ['dropout_21[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 224,317,253\n",
            "Trainable params: 19,781,955\n",
            "Non-trainable params: 204,535,298\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "231/231 [==============================] - 324s 1s/step - loss: 0.6091 - sparse_categorical_accuracy: 0.7395 - val_loss: 0.5157 - val_sparse_categorical_accuracy: 0.7896\n",
            "Epoch 2/20\n",
            "231/231 [==============================] - 302s 1s/step - loss: 0.4679 - sparse_categorical_accuracy: 0.8113 - val_loss: 0.4599 - val_sparse_categorical_accuracy: 0.8048\n",
            "Epoch 3/20\n",
            "231/231 [==============================] - 301s 1s/step - loss: 0.4098 - sparse_categorical_accuracy: 0.8365 - val_loss: 0.4437 - val_sparse_categorical_accuracy: 0.8224\n",
            "Epoch 4/20\n",
            "231/231 [==============================] - 295s 1s/step - loss: 0.3602 - sparse_categorical_accuracy: 0.8554 - val_loss: 0.4505 - val_sparse_categorical_accuracy: 0.8152\n",
            "Epoch 5/20\n",
            "231/231 [==============================] - 294s 1s/step - loss: 0.2935 - sparse_categorical_accuracy: 0.8850 - val_loss: 0.4578 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 6/20\n",
            "231/231 [==============================] - 293s 1s/step - loss: 0.2294 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.4793 - val_sparse_categorical_accuracy: 0.8212\n",
            "Epoch 7/20\n",
            "231/231 [==============================] - 293s 1s/step - loss: 0.1646 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.5083 - val_sparse_categorical_accuracy: 0.8160\n",
            "Epoch 8/20\n",
            "231/231 [==============================] - 293s 1s/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.5650 - val_sparse_categorical_accuracy: 0.8100\n",
            "Epoch 9/20\n",
            "231/231 [==============================] - 293s 1s/step - loss: 0.0595 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.5957 - val_sparse_categorical_accuracy: 0.8092\n",
            "Model: \"model_42\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_40 (Functional)          {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'sequence_output':  102267649   ['model_40[0][0]',               \n",
            "                                 (None, 128, 768),                'model_40[0][1]',               \n",
            "                                 'encoder_outputs':               'model_40[0][2]']               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " model_41 (Functional)          {'input_mask': (Non  0           ['text2[0][0]']                  \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " conv1d_35 (Conv1D)             (None, 128, 1024)    2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " BERT_encoder2 (KerasLayer)     {'encoder_outputs':  102267649   ['model_41[0][0]',               \n",
            "                                 [(None, 128, 768),               'model_41[0][1]',               \n",
            "                                 (None, 128, 768),                'model_41[0][2]']               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 128, 512)     1573376     ['conv1d_35[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_32 (Bidirectiona  (None, 128, 512)    1575936     ['BERT_encoder2[0][14]']         \n",
            " l)                                                                                               \n",
            "                                                                                                  \n",
            " gru_62 (GRU)                   (None, 128, 512)     1969152     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " attention_13 (Attention)       (None, 128, 512)     0           ['conv1d_36[0][0]',              \n",
            "                                                                  'conv1d_36[0][0]']              \n",
            "                                                                                                  \n",
            " attention_15 (Attention)       (None, 128, 512)     0           ['bidirectional_32[0][0]',       \n",
            "                                                                  'bidirectional_32[0][0]']       \n",
            "                                                                                                  \n",
            " attention_14 (Attention)       (None, 128, 512)     0           ['gru_62[0][0]',                 \n",
            "                                                                  'gru_62[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 128, 1536)    0           ['attention_13[0][0]',           \n",
            "                                                                  'attention_15[0][0]',           \n",
            "                                                                  'attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 128, 1024)    0           ['attention_13[0][0]',           \n",
            "                                                                  'attention_15[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 128, 1024)    0           ['attention_15[0][0]',           \n",
            "                                                                  'attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 128, 1024)    0           ['attention_13[0][0]',           \n",
            "                                                                  'attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_43 (Conv1D)             (None, 128, 512)     2359808     ['concatenate_12[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_46 (Conv1D)             (None, 128, 512)     1573376     ['concatenate_13[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_49 (Conv1D)             (None, 128, 512)     1573376     ['concatenate_14[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_52 (Conv1D)             (None, 128, 512)     1573376     ['concatenate_15[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 128, 128)     196736      ['attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_39 (Conv1D)             (None, 128, 128)     196736      ['attention_15[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_41 (Conv1D)             (None, 128, 128)     196736      ['attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_44 (Conv1D)             (None, 128, 128)     196736      ['conv1d_43[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_47 (Conv1D)             (None, 128, 128)     196736      ['conv1d_46[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_50 (Conv1D)             (None, 128, 128)     196736      ['conv1d_49[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_53 (Conv1D)             (None, 128, 128)     196736      ['conv1d_52[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_38 (Conv1D)             (None, 128, 64)      24640       ['conv1d_37[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_40 (Conv1D)             (None, 128, 64)      24640       ['conv1d_39[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_42 (Conv1D)             (None, 128, 64)      24640       ['conv1d_41[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_45 (Conv1D)             (None, 128, 64)      24640       ['conv1d_44[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_48 (Conv1D)             (None, 128, 64)      24640       ['conv1d_47[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_51 (Conv1D)             (None, 128, 64)      24640       ['conv1d_50[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_54 (Conv1D)             (None, 128, 64)      24640       ['conv1d_53[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_18 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_38[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_19 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_40[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_20 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_42[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_21 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_45[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_22 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_48[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_23 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_51[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_24 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_54[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_10 (Flatten)           (None, 4096)         0           ['max_pooling1d_18[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_11 (Flatten)           (None, 4096)         0           ['max_pooling1d_19[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_12 (Flatten)           (None, 4096)         0           ['max_pooling1d_20[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_13 (Flatten)           (None, 4096)         0           ['max_pooling1d_21[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_14 (Flatten)           (None, 4096)         0           ['max_pooling1d_22[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_15 (Flatten)           (None, 4096)         0           ['max_pooling1d_23[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_16 (Flatten)           (None, 4096)         0           ['max_pooling1d_24[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 4096)         0           ['flatten_10[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 4096)         0           ['flatten_11[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 4096)         0           ['flatten_12[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 4096)         0           ['flatten_13[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 4096)         0           ['flatten_14[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 4096)         0           ['flatten_15[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)           (None, 4096)         0           ['flatten_16[0][0]']             \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 128)          524416      ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 128)          524416      ['dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 128)          524416      ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 128)          524416      ['dropout_17[0][0]']             \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 128)          524416      ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 128)          524416      ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 128)          524416      ['dropout_20[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, 896)          0           ['dense_17[0][0]',               \n",
            "                                                                  'dense_18[0][0]',               \n",
            "                                                                  'dense_19[0][0]',               \n",
            "                                                                  'dense_20[0][0]',               \n",
            "                                                                  'dense_21[0][0]',               \n",
            "                                                                  'dense_22[0][0]',               \n",
            "                                                                  'dense_23[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)           (None, 896)          0           ['concatenate_16[0][0]']         \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 3)            2691        ['dropout_21[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 224,317,253\n",
            "Trainable params: 19,781,955\n",
            "Non-trainable params: 204,535,298\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 37s 468ms/step - loss: 0.4542 - sparse_categorical_accuracy: 0.8208\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4542492628097534, 0.8208000063896179]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Aab7_72ie8"
      },
      "source": [
        "#七、第六组实验 对比bert可训练和bert_embeddings效果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cXBo7ju20vY"
      },
      "source": [
        "##7.1 bert+GRU+CNN+BiGRU+MulCNN_0.8152"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf\n",
        "import typing\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import typing\n",
        "from keras.utils.vis_utils import plot_model\n",
        "if typing.TYPE_CHECKING:\n",
        "    from keras.api._v2 import keras\n",
        "# os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "# if os.environ['COLAB_TPU_ADDR']:\n",
        "#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "#   print('Using TPU')\n",
        "# elif tf.config.list_physical_devices('GPU'):\n",
        "#   strategy = tf.distribute.MirroredStrategy()\n",
        "#   print('Using GPU')\n",
        "# else:\n",
        "#   raise ValueError('Running on CPU is not recommended.')\n",
        "\n",
        "# 读取数据\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_train.csv\")\n",
        "train_data=train_data.sample(frac=1)\n",
        "x_train = np.array(train_data['text'])\n",
        "x2_train = np.array(train_data['content'])\n",
        "y_train = np.array(train_data['label'])\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ESA/cleaned_data/cleaned_dev.csv\")\n",
        "data=data.sample(frac=1)\n",
        "x_data = np.array(data[\"text\"])\n",
        "y_data = np.array(data[\"label\"])\n",
        "x2_data = np.array(data['content'])\n",
        "x_dev = x_data[:2500]\n",
        "x2_dev = x2_data[:2500]\n",
        "y_dev = y_data[:2500]\n",
        "x_test = x_data[-2500:]\n",
        "x2_test = x2_data[-2500:]\n",
        "y_test = y_data[-2500:]\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_dev = y_dev.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessor = hub.load(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_preprocess/3\")\n",
        "\n",
        "\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=50):\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
        "        for ft in sentence_features]\n",
        "    bert_preprocess = preprocessor\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "    truncated_segments = segments\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return tf.keras.Model(input_segments, model_inputs)\n",
        "\n",
        "\n",
        "bert_preprocess_model = make_bert_preprocess_model(['text_input'],seq_length=32)\n",
        "bert_preprocess_model2 = make_bert_preprocess_model(['text_input'],seq_length=128)\n",
        "\n",
        "\n",
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    text_input2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text2')\n",
        "\n",
        "    # preprocessing_layer = hub.KerasLayer(preprocessor, name='preprocessing')\n",
        "    encoder_inputs = bert_preprocess_model(text_input)\n",
        "    encoder = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=True,\n",
        "                             name='BERT_encoder')\n",
        "    # 输入batch*seq 输出batch*seq*768\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    # 输入batch*seq*768,输出batch*seq*512\n",
        "    net = outputs['sequence_output']\n",
        "    net = keras.layers.Conv1D(1024, 3, activation=\"relu\", padding=\"same\", strides=1)(net)\n",
        "    net = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net)\n",
        "    net = keras.layers.Attention()([net, net])\n",
        "    # 输入batch*seq*768,输出batch*seq*512\n",
        "    net3 = outputs['sequence_output']\n",
        "    net3 = keras.layers.GRU(512, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True)(net3)\n",
        "    net3 = keras.layers.Attention()([net3, net3])\n",
        "\n",
        "    # 输入batch*seq*768,输出batch*seq*512\n",
        "    encoder_inputs2 = bert_preprocess_model2(text_input2)\n",
        "    encoder2 = hub.KerasLayer(\"https://hub.tensorflow.google.cn/tensorflow/bert_zh_L-12_H-768_A-12/4\", trainable=True, name='BERT_encoder2')\n",
        "    outputs2 = encoder2(encoder_inputs2)\n",
        "    net2 = outputs2['sequence_output']\n",
        "    net2 = keras.layers.Bidirectional(\n",
        "        keras.layers.GRU(256, activation=\"tanh\", recurrent_activation=\"sigmoid\",return_sequences=True))(net2)\n",
        "    net2 = keras.layers.Attention()([net2, net2])\n",
        "    # 输入3*batch*seq*512,输出batch*seq*1536\n",
        "    net4 = keras.layers.Concatenate(axis=-2)([net, net2, net3])\n",
        "    # 输入2*batch*seq*512,输出batch*seq*1024\n",
        "    net5 = keras.layers.Concatenate(axis=-2)([net, net2])\n",
        "    net6 = keras.layers.Concatenate(axis=-2)([net2, net3])\n",
        "    net7 = keras.layers.Concatenate(axis=-2)([net, net3])\n",
        "    # 输入batch*seq*1536输出batch*seq/2*64\n",
        "    r1 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(net)\n",
        "    r1 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r1)\n",
        "    r1 = keras.layers.MaxPooling1D(2)(r1)\n",
        "    r1 = keras.layers.Flatten()(r1)\n",
        "    r1 = tf.keras.layers.Dropout(0.2)(r1)\n",
        "    r1 = keras.layers.Dense(128, activation='relu')(r1)\n",
        "\n",
        "    r2 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(net2)\n",
        "    r2 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r2)\n",
        "    r2 = keras.layers.MaxPooling1D(2)(r2)\n",
        "    r2 = keras.layers.Flatten()(r2)\n",
        "    r2 = tf.keras.layers.Dropout(0.2)(r2)\n",
        "    r2 = keras.layers.Dense(128, activation='relu')(r2)\n",
        "\n",
        "    r3 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(net3)\n",
        "    r3 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r3)\n",
        "    r3 = keras.layers.MaxPooling1D(2)(r3)\n",
        "    r3 = keras.layers.Flatten()(r3)\n",
        "    r3 = tf.keras.layers.Dropout(0.2)(r3)\n",
        "    r3 = keras.layers.Dense(128, activation='relu')(r3)\n",
        "\n",
        "    r4 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net4)\n",
        "    r4 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(r4)\n",
        "    r4 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r4)\n",
        "    r4 = keras.layers.MaxPooling1D(2)(r4)\n",
        "    r4 = keras.layers.Flatten()(r4)\n",
        "    r4 = tf.keras.layers.Dropout(0.2)(r4)\n",
        "    r4 = keras.layers.Dense(128, activation='relu')(r4)\n",
        "\n",
        "    r5 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net5)\n",
        "    r5 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(r5)\n",
        "    r5 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r5)\n",
        "    r5 = keras.layers.MaxPooling1D(2)(r5)\n",
        "    r5 = keras.layers.Flatten()(r5)\n",
        "    r5 = tf.keras.layers.Dropout(0.2)(r5)\n",
        "    r5 = keras.layers.Dense(128, activation='relu')(r5)\n",
        "\n",
        "    r6 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net6)\n",
        "    r6 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(r6)\n",
        "    r6 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r6)\n",
        "    r6 = keras.layers.MaxPooling1D(2)(r6)\n",
        "    r6 = keras.layers.Flatten()(r6)\n",
        "    r6 = tf.keras.layers.Dropout(0.2)(r6)\n",
        "    r6 = keras.layers.Dense(128, activation='relu')(r6)\n",
        "\n",
        "    r7 = keras.layers.Conv1D(512, 3, activation=\"relu\", padding=\"same\", strides=1)(net7)\n",
        "    r7 = keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"same\", strides=1)(r7)\n",
        "    r7 = keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", strides=1)(r7)\n",
        "    r7 = keras.layers.MaxPooling1D(2)(r7)\n",
        "    r7 = keras.layers.Flatten()(r7)\n",
        "    r7 = tf.keras.layers.Dropout(0.2)(r7)\n",
        "    r7 = keras.layers.Dense(128, activation='relu')(r7)\n",
        "\n",
        "    # r8 = outputs2['pooled_output']\n",
        "    # r8 = keras.layers.Dropout(0.2)(r8)\n",
        "    # r8 = keras.layers.Dense(64, activation='relu')(r8)\n",
        "\n",
        "    # r9 = outputs['pooled_output']\n",
        "    # r9 = keras.layers.Dropout(0.2)(r9)\n",
        "    # r9 = keras.layers.Dense(64, activation='relu')(r9)\n",
        "\n",
        "    res = keras.layers.Concatenate(axis=-1)([r1, r2, r3, r4, r5, r6, r7])\n",
        "    res = keras.layers.Dropout(0.2)(res)\n",
        "    res = keras.layers.Dense(3, activation='softmax')(res)\n",
        "    return keras.Model([text_input, text_input2], res)\n",
        "\n",
        "\n",
        "model = build_classifier_model()\n",
        "model_png=\"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru_CNN2\"\n",
        "tem_path=os.path.exists(model_png)\n",
        "if not tem_path:\n",
        "  os.makedirs(model_png)\n",
        "plot_model(model,to_file=model_png+\"/model.png\",show_shapes=True)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-05),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=[\"sparse_categorical_accuracy\"])\n",
        "checkpoint_path = \"/content/drive/MyDrive/ESA/checkpoint/gru_cnn_bigru_CNN2/model.ckpt\"\n",
        "if os.path.exists(checkpoint_path + \".index\"):\n",
        "    model.load_weights(checkpoint_path)\n",
        "model_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "early_stop=keras.callbacks.EarlyStopping(monitor=\"val_sparse_categorical_accuracy\",patience=4)\n",
        "model_history = model.fit([x_train,x2_train], y=y_train, epochs=20, batch_size=32,\n",
        "                          validation_data=([x_dev,x2_dev], y_dev),\n",
        "                          validation_freq=1,\n",
        "                          callbacks=[model_callback,early_stop],shuffle=True)\n",
        "#model.save_weights(checkpoint_path)\n",
        "model.summary()\n",
        "# 画出acc和loss曲线\n",
        "acc = model_history.history['sparse_categorical_accuracy']\n",
        "val_acc = model_history.history['val_sparse_categorical_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label=\"train acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.title(\"acc\")\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label=\"train loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.title(\"loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "model.load_weights(checkpoint_path)\n",
        "model.evaluate(x=[x_test,x2_test],y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ArL9IInzw0up",
        "outputId": "d601c0bd-0bee-4565-d142-edac26712e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_12 (Functional)          {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'encoder_outputs':  102267649   ['model_12[0][0]',               \n",
            "                                 [(None, 32, 768),                'model_12[0][1]',               \n",
            "                                 (None, 32, 768),                 'model_12[0][2]']               \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " model_13 (Functional)          {'input_mask': (Non  0           ['text2[0][0]']                  \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " conv1d_80 (Conv1D)             (None, 32, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " BERT_encoder2 (KerasLayer)     {'encoder_outputs':  102267649   ['model_13[0][0]',               \n",
            "                                 [(None, 128, 768),               'model_13[0][1]',               \n",
            "                                 (None, 128, 768),                'model_13[0][2]']               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " conv1d_81 (Conv1D)             (None, 32, 512)      1573376     ['conv1d_80[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, 128, 512)    1575936     ['BERT_encoder2[0][14]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_8 (GRU)                    (None, 32, 512)      1969152     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " attention_12 (Attention)       (None, 32, 512)      0           ['conv1d_81[0][0]',              \n",
            "                                                                  'conv1d_81[0][0]']              \n",
            "                                                                                                  \n",
            " attention_14 (Attention)       (None, 128, 512)     0           ['bidirectional_4[0][0]',        \n",
            "                                                                  'bidirectional_4[0][0]']        \n",
            "                                                                                                  \n",
            " attention_13 (Attention)       (None, 32, 512)      0           ['gru_8[0][0]',                  \n",
            "                                                                  'gru_8[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 192, 512)     0           ['attention_12[0][0]',           \n",
            "                                                                  'attention_14[0][0]',           \n",
            "                                                                  'attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenate)   (None, 160, 512)     0           ['attention_12[0][0]',           \n",
            "                                                                  'attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenate)   (None, 160, 512)     0           ['attention_14[0][0]',           \n",
            "                                                                  'attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenate)   (None, 64, 512)      0           ['attention_12[0][0]',           \n",
            "                                                                  'attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_88 (Conv1D)             (None, 192, 512)     786944      ['concatenate_20[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_91 (Conv1D)             (None, 160, 512)     786944      ['concatenate_21[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_94 (Conv1D)             (None, 160, 512)     786944      ['concatenate_22[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_97 (Conv1D)             (None, 64, 512)      786944      ['concatenate_23[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_82 (Conv1D)             (None, 32, 128)      196736      ['attention_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_84 (Conv1D)             (None, 128, 128)     196736      ['attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_86 (Conv1D)             (None, 32, 128)      196736      ['attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_89 (Conv1D)             (None, 192, 128)     196736      ['conv1d_88[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_92 (Conv1D)             (None, 160, 128)     196736      ['conv1d_91[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_95 (Conv1D)             (None, 160, 128)     196736      ['conv1d_94[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_98 (Conv1D)             (None, 64, 128)      196736      ['conv1d_97[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_83 (Conv1D)             (None, 32, 64)       24640       ['conv1d_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_85 (Conv1D)             (None, 128, 64)      24640       ['conv1d_84[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_87 (Conv1D)             (None, 32, 64)       24640       ['conv1d_86[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_90 (Conv1D)             (None, 192, 64)      24640       ['conv1d_89[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_93 (Conv1D)             (None, 160, 64)      24640       ['conv1d_92[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_96 (Conv1D)             (None, 160, 64)      24640       ['conv1d_95[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_99 (Conv1D)             (None, 64, 64)       24640       ['conv1d_98[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_28 (MaxPooling1D  (None, 16, 64)      0           ['conv1d_83[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_29 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_85[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_30 (MaxPooling1D  (None, 16, 64)      0           ['conv1d_87[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_31 (MaxPooling1D  (None, 96, 64)      0           ['conv1d_90[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_32 (MaxPooling1D  (None, 80, 64)      0           ['conv1d_93[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_33 (MaxPooling1D  (None, 80, 64)      0           ['conv1d_96[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_34 (MaxPooling1D  (None, 32, 64)      0           ['conv1d_99[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_28 (Flatten)           (None, 1024)         0           ['max_pooling1d_28[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_29 (Flatten)           (None, 4096)         0           ['max_pooling1d_29[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_30 (Flatten)           (None, 1024)         0           ['max_pooling1d_30[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_31 (Flatten)           (None, 6144)         0           ['max_pooling1d_31[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_32 (Flatten)           (None, 5120)         0           ['max_pooling1d_32[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_33 (Flatten)           (None, 5120)         0           ['max_pooling1d_33[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_34 (Flatten)           (None, 2048)         0           ['max_pooling1d_34[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_32 (Dropout)           (None, 1024)         0           ['flatten_28[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_33 (Dropout)           (None, 4096)         0           ['flatten_29[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)           (None, 1024)         0           ['flatten_30[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_35 (Dropout)           (None, 6144)         0           ['flatten_31[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_36 (Dropout)           (None, 5120)         0           ['flatten_32[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 5120)         0           ['flatten_33[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 2048)         0           ['flatten_34[0][0]']             \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 128)          131200      ['dropout_32[0][0]']             \n",
            "                                                                                                  \n",
            " dense_33 (Dense)               (None, 128)          524416      ['dropout_33[0][0]']             \n",
            "                                                                                                  \n",
            " dense_34 (Dense)               (None, 128)          131200      ['dropout_34[0][0]']             \n",
            "                                                                                                  \n",
            " dense_35 (Dense)               (None, 128)          786560      ['dropout_35[0][0]']             \n",
            "                                                                                                  \n",
            " dense_36 (Dense)               (None, 128)          655488      ['dropout_36[0][0]']             \n",
            "                                                                                                  \n",
            " dense_37 (Dense)               (None, 128)          655488      ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " dense_38 (Dense)               (None, 128)          262272      ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 896)          0           ['dense_32[0][0]',               \n",
            "                                                                  'dense_33[0][0]',               \n",
            "                                                                  'dense_34[0][0]',               \n",
            "                                                                  'dense_35[0][0]',               \n",
            "                                                                  'dense_36[0][0]',               \n",
            "                                                                  'dense_37[0][0]',               \n",
            "                                                                  'dense_38[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_39 (Dropout)           (None, 896)          0           ['concatenate_24[0][0]']         \n",
            "                                                                                                  \n",
            " dense_39 (Dense)               (None, 3)            2691        ['dropout_39[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 219,860,805\n",
            "Trainable params: 219,860,803\n",
            "Non-trainable params: 2\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "462/462 [==============================] - 476s 887ms/step - loss: 0.5894 - sparse_categorical_accuracy: 0.7628 - val_loss: 0.5197 - val_sparse_categorical_accuracy: 0.7928\n",
            "Epoch 2/20\n",
            "462/462 [==============================] - 408s 884ms/step - loss: 0.4261 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.4805 - val_sparse_categorical_accuracy: 0.8128\n",
            "Epoch 3/20\n",
            "462/462 [==============================] - 399s 864ms/step - loss: 0.3258 - sparse_categorical_accuracy: 0.8717 - val_loss: 0.5018 - val_sparse_categorical_accuracy: 0.7976\n",
            "Epoch 4/20\n",
            "462/462 [==============================] - 396s 858ms/step - loss: 0.2330 - sparse_categorical_accuracy: 0.9107 - val_loss: 0.5905 - val_sparse_categorical_accuracy: 0.8048\n",
            "Epoch 5/20\n",
            "462/462 [==============================] - 392s 850ms/step - loss: 0.2018 - sparse_categorical_accuracy: 0.9228 - val_loss: 0.6441 - val_sparse_categorical_accuracy: 0.7840\n",
            "Epoch 6/20\n",
            "462/462 [==============================] - 393s 850ms/step - loss: 0.1302 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.6243 - val_sparse_categorical_accuracy: 0.8220\n",
            "Epoch 7/20\n",
            "462/462 [==============================] - 390s 845ms/step - loss: 0.1170 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.8768 - val_sparse_categorical_accuracy: 0.8008\n",
            "Epoch 8/20\n",
            "462/462 [==============================] - 388s 841ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.8374 - val_sparse_categorical_accuracy: 0.8012\n",
            "Epoch 9/20\n",
            "462/462 [==============================] - 388s 840ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9762 - val_loss: 0.7980 - val_sparse_categorical_accuracy: 0.8188\n",
            "Epoch 10/20\n",
            "462/462 [==============================] - 388s 840ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9765 - val_loss: 0.9093 - val_sparse_categorical_accuracy: 0.7992\n",
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " model_12 (Functional)          {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 32),                                                           \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 32),                                                       \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 32)}                                                       \n",
            "                                                                                                  \n",
            " text2 (InputLayer)             [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'encoder_outputs':  102267649   ['model_12[0][0]',               \n",
            "                                 [(None, 32, 768),                'model_12[0][1]',               \n",
            "                                 (None, 32, 768),                 'model_12[0][2]']               \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 (None, 32, 768)],                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 32, 768),                                                 \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " model_13 (Functional)          {'input_mask': (Non  0           ['text2[0][0]']                  \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " conv1d_80 (Conv1D)             (None, 32, 1024)     2360320     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " BERT_encoder2 (KerasLayer)     {'encoder_outputs':  102267649   ['model_13[0][0]',               \n",
            "                                 [(None, 128, 768),               'model_13[0][1]',               \n",
            "                                 (None, 128, 768),                'model_13[0][2]']               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " conv1d_81 (Conv1D)             (None, 32, 512)      1573376     ['conv1d_80[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirectional  (None, 128, 512)    1575936     ['BERT_encoder2[0][14]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_8 (GRU)                    (None, 32, 512)      1969152     ['BERT_encoder[0][14]']          \n",
            "                                                                                                  \n",
            " attention_12 (Attention)       (None, 32, 512)      0           ['conv1d_81[0][0]',              \n",
            "                                                                  'conv1d_81[0][0]']              \n",
            "                                                                                                  \n",
            " attention_14 (Attention)       (None, 128, 512)     0           ['bidirectional_4[0][0]',        \n",
            "                                                                  'bidirectional_4[0][0]']        \n",
            "                                                                                                  \n",
            " attention_13 (Attention)       (None, 32, 512)      0           ['gru_8[0][0]',                  \n",
            "                                                                  'gru_8[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 192, 512)     0           ['attention_12[0][0]',           \n",
            "                                                                  'attention_14[0][0]',           \n",
            "                                                                  'attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenate)   (None, 160, 512)     0           ['attention_12[0][0]',           \n",
            "                                                                  'attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenate)   (None, 160, 512)     0           ['attention_14[0][0]',           \n",
            "                                                                  'attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenate)   (None, 64, 512)      0           ['attention_12[0][0]',           \n",
            "                                                                  'attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_88 (Conv1D)             (None, 192, 512)     786944      ['concatenate_20[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_91 (Conv1D)             (None, 160, 512)     786944      ['concatenate_21[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_94 (Conv1D)             (None, 160, 512)     786944      ['concatenate_22[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_97 (Conv1D)             (None, 64, 512)      786944      ['concatenate_23[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_82 (Conv1D)             (None, 32, 128)      196736      ['attention_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_84 (Conv1D)             (None, 128, 128)     196736      ['attention_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_86 (Conv1D)             (None, 32, 128)      196736      ['attention_13[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_89 (Conv1D)             (None, 192, 128)     196736      ['conv1d_88[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_92 (Conv1D)             (None, 160, 128)     196736      ['conv1d_91[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_95 (Conv1D)             (None, 160, 128)     196736      ['conv1d_94[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_98 (Conv1D)             (None, 64, 128)      196736      ['conv1d_97[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_83 (Conv1D)             (None, 32, 64)       24640       ['conv1d_82[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_85 (Conv1D)             (None, 128, 64)      24640       ['conv1d_84[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_87 (Conv1D)             (None, 32, 64)       24640       ['conv1d_86[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_90 (Conv1D)             (None, 192, 64)      24640       ['conv1d_89[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_93 (Conv1D)             (None, 160, 64)      24640       ['conv1d_92[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_96 (Conv1D)             (None, 160, 64)      24640       ['conv1d_95[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_99 (Conv1D)             (None, 64, 64)       24640       ['conv1d_98[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d_28 (MaxPooling1D  (None, 16, 64)      0           ['conv1d_83[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_29 (MaxPooling1D  (None, 64, 64)      0           ['conv1d_85[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_30 (MaxPooling1D  (None, 16, 64)      0           ['conv1d_87[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_31 (MaxPooling1D  (None, 96, 64)      0           ['conv1d_90[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_32 (MaxPooling1D  (None, 80, 64)      0           ['conv1d_93[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_33 (MaxPooling1D  (None, 80, 64)      0           ['conv1d_96[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling1d_34 (MaxPooling1D  (None, 32, 64)      0           ['conv1d_99[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " flatten_28 (Flatten)           (None, 1024)         0           ['max_pooling1d_28[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_29 (Flatten)           (None, 4096)         0           ['max_pooling1d_29[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_30 (Flatten)           (None, 1024)         0           ['max_pooling1d_30[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_31 (Flatten)           (None, 6144)         0           ['max_pooling1d_31[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_32 (Flatten)           (None, 5120)         0           ['max_pooling1d_32[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_33 (Flatten)           (None, 5120)         0           ['max_pooling1d_33[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_34 (Flatten)           (None, 2048)         0           ['max_pooling1d_34[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_32 (Dropout)           (None, 1024)         0           ['flatten_28[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_33 (Dropout)           (None, 4096)         0           ['flatten_29[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)           (None, 1024)         0           ['flatten_30[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_35 (Dropout)           (None, 6144)         0           ['flatten_31[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_36 (Dropout)           (None, 5120)         0           ['flatten_32[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 5120)         0           ['flatten_33[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 2048)         0           ['flatten_34[0][0]']             \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 128)          131200      ['dropout_32[0][0]']             \n",
            "                                                                                                  \n",
            " dense_33 (Dense)               (None, 128)          524416      ['dropout_33[0][0]']             \n",
            "                                                                                                  \n",
            " dense_34 (Dense)               (None, 128)          131200      ['dropout_34[0][0]']             \n",
            "                                                                                                  \n",
            " dense_35 (Dense)               (None, 128)          786560      ['dropout_35[0][0]']             \n",
            "                                                                                                  \n",
            " dense_36 (Dense)               (None, 128)          655488      ['dropout_36[0][0]']             \n",
            "                                                                                                  \n",
            " dense_37 (Dense)               (None, 128)          655488      ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " dense_38 (Dense)               (None, 128)          262272      ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 896)          0           ['dense_32[0][0]',               \n",
            "                                                                  'dense_33[0][0]',               \n",
            "                                                                  'dense_34[0][0]',               \n",
            "                                                                  'dense_35[0][0]',               \n",
            "                                                                  'dense_36[0][0]',               \n",
            "                                                                  'dense_37[0][0]',               \n",
            "                                                                  'dense_38[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_39 (Dropout)           (None, 896)          0           ['concatenate_24[0][0]']         \n",
            "                                                                                                  \n",
            " dense_39 (Dense)               (None, 3)            2691        ['dropout_39[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 219,860,805\n",
            "Trainable params: 219,860,803\n",
            "Non-trainable params: 2\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 26s 332ms/step - loss: 0.4772 - sparse_categorical_accuracy: 0.8152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47718197107315063, 0.8151999711990356]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ESA.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11123fe7aef146c9ba2971371b9e753e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c49e243efd841069a36c79d10776659": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6031278adc40d4ae4e8e16726612c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c49e243efd841069a36c79d10776659",
            "placeholder": "​",
            "style": "IPY_MODEL_f53bd07cdff34bce99b7345873d0edeb",
            "value": "100%"
          }
        },
        "2e6f505c6d9d4ecfba31738c69c0cdc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3db3eaaeb54444a8889800bb39ec819b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ee54a0765604b4ebf289a3632a17090": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4515af4050404a258934349d801845b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e16bfaa73e84144bc94cb7e408116eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4515af4050404a258934349d801845b2",
            "placeholder": "​",
            "style": "IPY_MODEL_bcb17ac1848e4b769837240d03106a3a",
            "value": " 3/3 [00:00&lt;00:00,  3.71ba/s]"
          }
        },
        "7deb4fb86d1d4e5b93eb9dd0b4df862b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2d671735ad74a3a97f1daf4f73bb3b2",
              "IPY_MODEL_e3044c5d807b4e8396ae74333ad17792",
              "IPY_MODEL_d50186dc76ad452abd847f0cfa145c83"
            ],
            "layout": "IPY_MODEL_11123fe7aef146c9ba2971371b9e753e"
          }
        },
        "8cbea263bdd64a31b6db57e8b5a56b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90a32c5ad93f4e0e845aaa206c3f65f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee54a0765604b4ebf289a3632a17090",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e6f505c6d9d4ecfba31738c69c0cdc4",
            "value": 3
          }
        },
        "ab0c1c875ac04a78baea746b1e2d4755": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c6031278adc40d4ae4e8e16726612c7",
              "IPY_MODEL_90a32c5ad93f4e0e845aaa206c3f65f7",
              "IPY_MODEL_6e16bfaa73e84144bc94cb7e408116eb"
            ],
            "layout": "IPY_MODEL_3db3eaaeb54444a8889800bb39ec819b"
          }
        },
        "baa3e7c63c144bcf82889652a4d71e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb17ac1848e4b769837240d03106a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf70920ed5b646d6a69c96d2a640ece0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5576a1ac8f54157ad9a6561df3142b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c60853807dc3476e9d70bb4c774144d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d450684eace14415baf24d51adb3117c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d50186dc76ad452abd847f0cfa145c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d450684eace14415baf24d51adb3117c",
            "placeholder": "​",
            "style": "IPY_MODEL_8cbea263bdd64a31b6db57e8b5a56b33",
            "value": " 3/3 [00:00&lt;00:00,  4.04ba/s]"
          }
        },
        "e3044c5d807b4e8396ae74333ad17792": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c60853807dc3476e9d70bb4c774144d7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5576a1ac8f54157ad9a6561df3142b3",
            "value": 3
          }
        },
        "f2d671735ad74a3a97f1daf4f73bb3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa3e7c63c144bcf82889652a4d71e8e",
            "placeholder": "​",
            "style": "IPY_MODEL_bf70920ed5b646d6a69c96d2a640ece0",
            "value": "100%"
          }
        },
        "f53bd07cdff34bce99b7345873d0edeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}